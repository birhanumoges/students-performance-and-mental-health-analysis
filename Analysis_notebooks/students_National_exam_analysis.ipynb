{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6d8ad119",
      "metadata": {
        "id": "6d8ad119"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from sklearn.impute import SimpleImputer\n",
        "\n",
        "# Read the saved data\n",
        "print(\"=\" * 70)\n",
        "print(\"READING SAVED DATA\")\n",
        "print(\"=\" * 70)\n",
        "\n",
        "try:\n",
        "    df = pd.read_csv('students_dataset.csv')\n",
        "    print(f\"‚úÖ Dataset loaded successfully!\")\n",
        "    print(f\" Shape: {df.shape}\")\n",
        "    print(f\" Columns: {len(df.columns)}\")\n",
        "    print(f\" Total records: {len(df)}\")\n",
        "except FileNotFoundError:\n",
        "    print(\" File 'students_dataset.csv' not found.\")\n",
        "    exit()\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 1. Check the basic structure\n",
        "print(\"=\"*60)\n",
        "print(\"DATA STRUCTURE ANALYSIS\")\n",
        "print(\"=\"*60)\n",
        "\n",
        "print(f\"Dataset Shape: {df.shape}\")\n",
        "print(f\"Number of students: {df.shape[0]}\")\n",
        "print(f\"Number of columns: {df.shape[1]}\")\n",
        "print(f\"Memory usage: {df.memory_usage(deep=True).sum() / 1024**2:.2f} MB\")\n",
        "\n",
        "# 2. View column categories\n",
        "print(\"\\n\" + \"=\"*60)\n",
        "print(\"COLUMN CATEGORIES\")\n",
        "print(\"=\"*60)\n",
        "\n",
        "# Group columns by type\n",
        "test_score_cols = [col for col in df.columns if 'Test_Score' in col]\n",
        "attendance_cols = [col for col in df.columns if 'Attendance' in col]\n",
        "homework_cols = [col for col in df.columns if 'Homework' in col]\n",
        "participation_cols = [col for col in df.columns if 'Participation' in col]\n",
        "textbook_cols = [col for col in df.columns if 'Textbook' in col]\n",
        "\n",
        "print(f\"Test Score columns: {len(test_score_cols)}\")\n",
        "print(f\"Attendance columns: {len(attendance_cols)}\")\n",
        "print(f\"Homework columns: {len(homework_cols)}\")\n",
        "print(f\"Participation columns: {len(participation_cols)}\")\n",
        "print(f\"Textbook columns: {len(textbook_cols)}\")\n",
        "\n",
        "# 3. Check subject coverage by grade\n",
        "print(\"\\n\" + \"=\"*60)\n",
        "print(\"SUBJECT COVERAGE BY GRADE\")\n",
        "print(\"=\"*60)\n",
        "\n",
        "for grade in range(1, 13):\n",
        "    grade_test_cols = [col for col in test_score_cols if f'Grade_{grade}_' in col]\n",
        "    if grade_test_cols:\n",
        "        subjects = list(set([col.split(f'Grade_{grade}_')[1].split('_Test')[0]\n",
        "                           for col in grade_test_cols]))\n",
        "        print(f\"Grade {grade}: {len(grade_test_cols)} subjects - {subjects}\")\n",
        "\n",
        "all_categorized_cols = set(test_score_cols + attendance_cols + homework_cols + participation_cols + textbook_cols)\n",
        "remaining_cols = [col for col in df.columns if col not in all_categorized_cols]\n",
        "\n",
        "print(\"\\n\" + \"=\"*60)\n",
        "print(\"REMAINING COLUMNS\")\n",
        "print(\"=\"*60)\n",
        "print(f\"Number of remaining columns: {len(remaining_cols)}\")\n",
        "print(\"Remaining columns (first 20):\\n\", remaining_cols[:20])\n",
        "print(\"Remaining columns (last 20):\\n\", remaining_cols[-20:])"
      ],
      "metadata": {
        "id": "znCaQByysCrC"
      },
      "id": "znCaQByysCrC",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Check for nulls per column\n",
        "print(\"==============================\")\n",
        "print(\"CHECKING FOR MISSING DATA\")\n",
        "print(\"==============================\")\n",
        "print(df.isnull().sum())\n",
        "\n",
        "# Check the percentage of missing data\n",
        "print(\"================================\")\n",
        "print(\"Percentage of missing data:\")\n",
        "print(\"--------------------------------\")\n",
        "print(df.isnull().mean() * 100)"
      ],
      "metadata": {
        "id": "DRgDluFtsTxQ"
      },
      "id": "DRgDluFtsTxQ",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"--------------------------------\")\n",
        "print(\"Check data types of all columns\")\n",
        "print(\"--------------------------------\")\n",
        "print(df.dtypes)\n",
        "\n",
        "# To see a count of how many columns you have for each type\n",
        "print(df.dtypes.value_counts())\n",
        "\n",
        "# Select only numeric columns (float and int)\n",
        "numeric_cols = df.select_dtypes(include=['number']).columns\n",
        "print(f\"Numeric Columns: {list(numeric_cols)}\")\n",
        "\n",
        "# Select only categorical/object columns\n",
        "categorical_cols = df.select_dtypes(include=['object', 'category']).columns\n",
        "print(f\"Categorical Columns: {list(categorical_cols)}\")\n",
        "\n",
        "#column name of one subject(maths)\n",
        "one_column= [col for col in df.columns if 'Grade_12' in col and 'Math' in col]\n",
        "#number of column is one subject (maths)\n",
        "print(\"number of column in one subject is:\",len(one_column))\n",
        "print(one_column)"
      ],
      "metadata": {
        "id": "3_zQLXyxseLx"
      },
      "id": "3_zQLXyxseLx",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 1. Get the value counts of dtypes\n",
        "dtype_counts = df.dtypes.value_counts().reset_index()\n",
        "dtype_counts.columns = ['Data Type', 'Count']\n",
        "\n",
        "# 2. Plotting with the fix\n",
        "plt.figure(figsize=(10, 6))\n",
        "\n",
        "# Fix: Assign 'Data Type' to hue and set legend=False\n",
        "sns.barplot(\n",
        "    data=dtype_counts,\n",
        "    x='Data Type',\n",
        "    y='Count',\n",
        "    hue='Data Type',\n",
        "    palette='viridis',\n",
        "    legend=False\n",
        ")\n",
        "\n",
        "plt.title('Distribution of Data Types in Student Dataset', fontsize=14)\n",
        "plt.ylabel('Number of Columns')\n",
        "plt.xlabel('Data Type')\n",
        "\n",
        "# 3. Add labels on top of bars\n",
        "for i, count in enumerate(dtype_counts['Count']):\n",
        "    plt.text(i, count + 5, str(count), ha='center', fontweight='bold')\n",
        "\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "IH_0GAI8sw6o"
      },
      "id": "IH_0GAI8sw6o",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 1. Check for inconsistent scales\n",
        "print(\"\\n\" + \"=\"*60)\n",
        "print(\"SCALE CONSISTENCY CHECK\")\n",
        "print(\"=\"*60)\n",
        "\n",
        "# Test scores should be on similar scale (0-100 typically)\n",
        "sample_test_scores = test_score_cols[:10]  # Check first 10 test score columns\n",
        "\n",
        "for col in sample_test_scores:\n",
        "    if col in df.columns:\n",
        "        min_val = df[col].min()\n",
        "        max_val = df[col].max()\n",
        "        mean_val = df[col].mean()\n",
        "        print(f\"{col:50} Min: {min_val:6.2f} Max: {max_val:6.2f} Mean: {mean_val:6.2f}\")\n",
        "\n",
        "# 2. Check for impossible values\n",
        "print(\"\\n\" + \"=\"*60)\n",
        "print(\"DATA VALIDATION CHECKS\")\n",
        "print(\"=\"*60)\n",
        "\n",
        "# Check if any test scores are outside reasonable range (0-100)\n",
        "for grade in [9, 10, 11, 12]:  # Check upper grades first\n",
        "    grade_cols = [col for col in test_score_cols if f'Grade_{grade}_' in col]\n",
        "    for col in grade_cols[:3]:  # Check first 3 subjects per grade\n",
        "        if col in df.columns:\n",
        "            invalid_count = ((df[col] < 0) | (df[col] > 100)).sum()\n",
        "            if invalid_count > 0:\n",
        "                print(f\"WARNING: {col} has {invalid_count} values outside 0-100 range\")\n",
        "\n",
        "# 3. Check attendance, homework, participation scales\n",
        "# These are likely percentages (0-100) or proportions (0-1)\n",
        "print(\"\\nChecking behavioral data scales...\")\n",
        "sample_attendance = attendance_cols[0] if attendance_cols else None\n",
        "if sample_attendance and sample_attendance in df.columns:\n",
        "    att_min = df[sample_attendance].min()\n",
        "    att_max = df[sample_attendance].max()\n",
        "    print(f\"Attendance sample ({sample_attendance}): {att_min:.2f} to {att_max:.2f}\")\n",
        "\n",
        "    # Determine scale\n",
        "    if att_max > 1:\n",
        "        print(\"Likely scale: 0-100 (percentage)\")\n",
        "        # We may need to normalize to 0-1 for consistency\n",
        "    else:\n",
        "        print(\"Likely scale: 0-1 (proportion)\")"
      ],
      "metadata": {
        "id": "7Y4vEdBvtagI"
      },
      "id": "7Y4vEdBvtagI",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ================================\n",
        "# 1Ô∏è‚É£ INITIAL CLEANING & ENCODING\n",
        "# ================================\n",
        "# Drop Student_ID (never used in ML)\n",
        "df = df.drop(columns=['Student_ID'], errors='ignore')\n",
        "\n",
        "# Encode Field_Choice (Social=0, Natural=1)\n",
        "df['Field_Choice'] = df['Field_Choice'].map({'Social': 0, 'Natural': 1})\n",
        "\n",
        "# Fill missing Career_Interest with \"Unknown\"\n",
        "df['Career_Interest'] = df['Career_Interest'].fillna('Unknown')\n",
        "\n",
        "\n",
        "# ================================\n",
        "# 2Ô∏è‚É£ DEFINE EDUCATION STAGES\n",
        "# ================================\n",
        "lower_primary = ['Grade_1', 'Grade_2', 'Grade_3', 'Grade_4']\n",
        "upper_primary = ['Grade_5', 'Grade_6', 'Grade_7', 'Grade_8']\n",
        "secondary     = ['Grade_9', 'Grade_10']\n",
        "preparatory   = ['Grade_11', 'Grade_12']\n",
        "\n",
        "stages = {\n",
        "    'Lower_Primary': lower_primary,\n",
        "    'Upper_Primary': upper_primary,\n",
        "    'Secondary': secondary,\n",
        "    'Preparatory': preparatory\n",
        "}\n",
        "\n",
        "\n",
        "# ================================\n",
        "# 3Ô∏è‚É£ HELPER FUNCTION TO AGGREGATE GRADES\n",
        "# ================================\n",
        "def stage_average(df, grades, metric_keywords):\n",
        "    \"\"\"\n",
        "    Compute average across all columns for a given stage and metric keywords.\n",
        "    Returns the average series and list of original columns used.\n",
        "    \"\"\"\n",
        "    cols = []\n",
        "    for g in grades:\n",
        "        for keyword in metric_keywords:\n",
        "            cols += [c for c in df.columns if c.startswith(g) and keyword.lower() in c.lower()]\n",
        "    cols = list(set(cols))\n",
        "    return df[cols].mean(axis=1), cols\n",
        "\n",
        "\n",
        "# ================================\n",
        "# 4Ô∏è‚É£ AGGREGATE TEST SCORE, ATTENDANCE, HW, PARTICIPATION\n",
        "# ================================\n",
        "metrics_dict = {\n",
        "    'Test_Score': ['Test_Score'],\n",
        "    'Attendance': ['Attendance'],\n",
        "    'HW_Completion': ['Homework_Completion'],\n",
        "    'Participation': ['Participation']\n",
        "}\n",
        "\n",
        "cols_to_drop = []\n",
        "\n",
        "for metric_name, keywords in metrics_dict.items():\n",
        "    for stage_name, grades in stages.items():\n",
        "        col_name = f'Avg_{metric_name}_{stage_name}'\n",
        "        df[col_name], original_cols = stage_average(df, grades, keywords)\n",
        "        cols_to_drop += original_cols\n",
        "\n",
        "# Drop original grade-level columns\n",
        "df.drop(columns=list(set(cols_to_drop)), inplace=True)\n",
        "\n",
        "# Columns list for display\n",
        "aggregated_cols = [f'Avg_{m}_{s}' for m in metrics_dict.keys() for s in stages.keys()]\n",
        "print(\"Aggregated averages per Education Stage (head):\")\n",
        "print(df[aggregated_cols].head())\n",
        "\n",
        "\n",
        "# ================================\n",
        "# 5Ô∏è‚É£ AGGREGATE TEXTBOOK ACCESS\n",
        "# ================================\n",
        "# Convert Yes/No ‚Üí 1/0 safely\n",
        "textbook_cols = [c for c in df.columns if 'Textbook' in c]\n",
        "for col in textbook_cols:\n",
        "    df[col] = df[col].replace({'Yes': 1, 'No': 0}).infer_objects(copy=False)\n",
        "\n",
        "# Helper function for textbook access per stage\n",
        "def textbook_access(df, grade_prefixes):\n",
        "    cols = []\n",
        "    for g in grade_prefixes:\n",
        "        cols.extend([c for c in df.columns if c.startswith(g) and 'Textbook' in c])\n",
        "    return df[cols].mean(axis=1) if len(cols) > 0 else pd.Series(0, index=df.index)\n",
        "\n",
        "# Create aggregated textbook access per stage\n",
        "new_cols_df = pd.DataFrame({\n",
        "    'Textbook_Access_1_4': textbook_access(df, lower_primary),\n",
        "    'Textbook_Access_5_8': textbook_access(df, upper_primary),\n",
        "    'Textbook_Access_9_10': textbook_access(df, secondary),\n",
        "    'Textbook_Access_11_12': textbook_access(df, preparatory)\n",
        "})\n",
        "\n",
        "df = pd.concat([df, new_cols_df], axis=1)\n",
        "df = df.loc[:, ~df.columns.duplicated()]  # remove duplicates\n",
        "\n",
        "# Display and visualize\n",
        "textbook_summary_cols = [c for c in new_cols_df.columns if c in df.columns]\n",
        "print(df[textbook_summary_cols].head())\n",
        "\n",
        "plt.figure(figsize=(10, 6))\n",
        "sns.boxplot(data=df[textbook_summary_cols])\n",
        "plt.title('Textbook Access Distribution by Education Level', fontsize=14, fontweight='bold')\n",
        "plt.ylabel('Access Score (0 to 1)')\n",
        "plt.xticks(rotation=15)\n",
        "plt.grid(alpha=0.3)\n",
        "plt.show()\n",
        "\n",
        "\n",
        "# ================================\n",
        "# 6Ô∏è‚É£ TRACK-BASED NATIONAL EXAMS\n",
        "# ================================\n",
        "# Subjects per track\n",
        "social_subjects = ['National_Exam_History', 'National_Exam_Geography',\n",
        "                   'National_Exam_Economics', 'National_Exam_Math_Social']\n",
        "\n",
        "natural_subjects = ['National_Exam_Biology', 'National_Exam_Chemistry',\n",
        "                    'National_Exam_Physics', 'National_Exam_Math_Natural']\n",
        "\n",
        "# Track-specific averages\n",
        "df['Social_Track_Subject_Avg']  = df[social_subjects].mean(axis=1)\n",
        "df['Natural_Track_Subject_Avg'] = df[natural_subjects].mean(axis=1)\n",
        "\n",
        "# Track-based assignment\n",
        "df['Track_Subject_Average'] = np.where(\n",
        "    df['Field_Choice'] == 0,\n",
        "    df['Social_Track_Subject_Avg'],\n",
        "    df['Natural_Track_Subject_Avg']\n",
        ")\n",
        "\n",
        "# Common subjects for all students\n",
        "common_subjects = ['National_Exam_Aptitude', 'National_Exam_English',\n",
        "                   'National_Exam_Civics_and_Ethical_Education']\n",
        "df['Common_Exam_Average'] = df[common_subjects].mean(axis=1)\n",
        "\n",
        "# Overall Track Exam Average\n",
        "df['Track_Exam_Average'] = (df['Common_Exam_Average'] + df['Track_Subject_Average']) / 2\n",
        "\n",
        "# Display new exam columns\n",
        "exam_cols = [\n",
        "    'Social_Track_Subject_Avg',\n",
        "    'Natural_Track_Subject_Avg',\n",
        "    'Track_Subject_Average',\n",
        "    'Common_Exam_Average',\n",
        "    'Track_Exam_Average'\n",
        "]\n",
        "print(\"New Aggregated National Exam Features:\")\n",
        "print(df[exam_cols].head())\n",
        "\n",
        "\n",
        "# ================================\n",
        "# 7Ô∏è‚É£ VISUALIZATION: Exam Scores\n",
        "# ================================\n",
        "sns.set_theme(style=\"whitegrid\")\n",
        "fig, axes = plt.subplots(1, 2, figsize=(16, 6))\n",
        "\n",
        "# Boxplot: Common vs Track vs Overall\n",
        "sns.boxplot(data=df[['Common_Exam_Average', 'Track_Subject_Average', 'Track_Exam_Average']],\n",
        "            ax=axes[0], palette=\"Set2\")\n",
        "axes[0].set_title('Distribution of Aggregate Exam Scores')\n",
        "axes[0].set_ylabel('Score (0-100)')\n",
        "\n",
        "# KDE: Track Exam Average by Field Choice\n",
        "for choice, label in [(0, 'Social Science'), (1, 'Natural Science')]:\n",
        "    subset = df[df['Field_Choice'] == choice]\n",
        "    sns.kdeplot(subset['Track_Exam_Average'], ax=axes[1], label=label, fill=True)\n",
        "\n",
        "axes[1].set_title('Track Exam Average: Social vs. Natural')\n",
        "axes[1].set_xlabel('Score')\n",
        "axes[1].legend()\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "4cTfhaQEIocC"
      },
      "id": "4cTfhaQEIocC",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# -----------------------------\n",
        "# Distribution of key variables\n",
        "# -----------------------------\n",
        "fig, axes = plt.subplots(2, 2, figsize=(15, 10))\n",
        "\n",
        "# Plot 1: Distribution of Total_National_Exam_Score\n",
        "if 'Total_National_Exam_Score' in df.columns:\n",
        "    axes[0, 0].hist(\n",
        "        df['Total_National_Exam_Score'].dropna(),\n",
        "        bins=30,\n",
        "        edgecolor='black',\n",
        "        alpha=0.7\n",
        "    )\n",
        "    axes[0, 0].set_title('Distribution of Total_National_Exam_Score')\n",
        "    axes[0, 0].set_xlabel('Average Score')\n",
        "    axes[0, 0].set_ylabel('Frequency')\n",
        "\n",
        "# Plot 2: Parental Involvement distribution\n",
        "if 'Parental_Involvement' in df.columns:\n",
        "    axes[0, 1].hist(\n",
        "        df['Parental_Involvement'].dropna(),\n",
        "        bins=30,\n",
        "        edgecolor='black',\n",
        "        alpha=0.7,\n",
        "        color='green'\n",
        "    )\n",
        "    axes[0, 1].set_title('Parental Involvement Distribution')\n",
        "    axes[0, 1].set_xlabel('Involvement Score (0‚Äì1)')\n",
        "    axes[0, 1].set_ylabel('Frequency')\n",
        "\n",
        "# Plot 3: Overall Average by Academic Track (BOXPLOT)\n",
        "if 'Field_Choice' in df.columns and 'Overall_Average' in df.columns:\n",
        "    track_data = df[['Field_Choice', 'Overall_Average']].dropna()\n",
        "\n",
        "    tracks = sorted(track_data['Field_Choice'].unique())\n",
        "    labels = ['Social' if t == 0 else 'Natural' for t in tracks]\n",
        "\n",
        "    box_data = [\n",
        "        track_data[track_data['Field_Choice'] == t]['Overall_Average']\n",
        "        for t in tracks\n",
        "    ]\n",
        "\n",
        "    axes[1, 0].boxplot(\n",
        "        box_data,\n",
        "        tick_labels=labels   # ‚úÖ FIXED (was labels=)\n",
        "    )\n",
        "    axes[1, 0].set_title('Overall Average by Academic Track')\n",
        "    axes[1, 0].set_ylabel('Average Score')\n",
        "\n",
        "# Plot 4: Region performance\n",
        "if 'Region' in df.columns and 'Overall_Average' in df.columns:\n",
        "    region_avg = (\n",
        "        df.groupby('Region')['Overall_Average']\n",
        "        .mean()\n",
        "        .sort_values()\n",
        "    )\n",
        "\n",
        "    axes[1, 1].barh(range(len(region_avg)), region_avg.values)\n",
        "    axes[1, 1].set_yticks(range(len(region_avg)))\n",
        "    axes[1, 1].set_yticklabels(region_avg.index)\n",
        "    axes[1, 1].set_title('Average Performance by Region')\n",
        "    axes[1, 1].set_xlabel('Average Score')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "-qkJu5SmH5gE"
      },
      "id": "-qkJu5SmH5gE",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# DROP ORIGINAL HIGH-DIMENSION COLUMNS\n",
        "drop_cols = [c for c in df.columns if c.startswith('Grade_')]\n",
        "drop_cols += [c for c in df.columns if c.startswith('National_Exam_')]\n",
        "\n",
        "df = df.drop(columns=drop_cols)\n",
        "# -------------------------------\n",
        "# 0Ô∏è‚É£ Drop leaking exam average columns\n",
        "# -------------------------------\n",
        "leak_cols = [\n",
        "    'Social_Track_Subject_Avg',\n",
        "    'Natural_Track_Subject_Avg',\n",
        "    'Track_Exam_Average',\n",
        "    'Track_Subject_Average',\n",
        "    'Common_Exam_Average',\n",
        "     'School_ID','Total_Test_Score', 'Overall_Average']\n",
        "\n",
        "df = df.drop(columns=[c for c in leak_cols if c in df.columns])\n",
        "\n",
        "# fix null value\n",
        "df['Health_Issue'] = df['Health_Issue'].fillna('No Issue')\n",
        "df['Father_Education'] = df['Father_Education'].fillna('Unknown')\n",
        "df['Mother_Education'] = df['Mother_Education'].fillna('Unknown')\n",
        "\n",
        "# FINAL CHECK\n",
        "print(df.shape)\n",
        "print(df.head())\n",
        "print(\"all columns:\",df.columns)"
      ],
      "metadata": {
        "id": "TpYIkHISvnD4"
      },
      "id": "TpYIkHISvnD4",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.info()"
      ],
      "metadata": {
        "id": "LsLbiVIyv2ld"
      },
      "id": "LsLbiVIyv2ld",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "TARGET = 'Total_National_Exam_Score'\n",
        "\n",
        "# Select numeric columns only\n",
        "num_cols = df.select_dtypes(include=['int64', 'float64']).columns\n",
        "\n",
        "# Compute correlations with target\n",
        "corr_numeric = (\n",
        "    df[num_cols]\n",
        "    .corr()[TARGET]\n",
        "    .drop(TARGET)\n",
        "    .sort_values(key=abs, ascending=False)\n",
        ")\n",
        "\n",
        "print(\"üìä Numeric Feature Correlation with Target:\")\n",
        "print(corr_numeric)\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "plt.figure(figsize=(10, 8))\n",
        "\n",
        "sns.barplot(\n",
        "    x=corr_numeric.values,\n",
        "    y=corr_numeric.index,\n",
        "    hue=corr_numeric.index,\n",
        "    palette='coolwarm',\n",
        "    legend=False\n",
        ")\n",
        "\n",
        "plt.axvline(0, color='black', linewidth=1)\n",
        "plt.title('Correlation with Total_National_Exam_Score')\n",
        "plt.xlabel('Pearson Correlation')\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "poAfjA8RwCJI"
      },
      "id": "poAfjA8RwCJI",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cat_cols = df.select_dtypes(include='object').columns.drop(TARGET, errors='ignore')\n",
        "\n",
        "cat_corr = {}\n",
        "\n",
        "for col in cat_cols:\n",
        "    means = df.groupby(col)[TARGET].mean()\n",
        "    encoded = df[col].map(means)\n",
        "    cat_corr[col] = encoded.corr(df[TARGET])\n",
        "\n",
        "cat_corr = (\n",
        "    pd.Series(cat_corr)\n",
        "    .sort_values(key=abs, ascending=False)\n",
        ")\n",
        "\n",
        "print(\"üìä Categorical Feature Association with Target:\")\n",
        "print(cat_corr)"
      ],
      "metadata": {
        "id": "m8gSneCPgT0Z"
      },
      "id": "m8gSneCPgT0Z",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Select categorical columns\n",
        "cat_cols = df.select_dtypes(include=['object', 'category']).columns\n",
        "\n",
        "# Prepare a dictionary to store info\n",
        "cat_summary = {}\n",
        "\n",
        "for col in cat_cols:\n",
        "    unique_vals = df[col].unique()\n",
        "    cat_summary[col] = {\n",
        "        'Unique_Count': len(unique_vals),\n",
        "        'Unique_Values': unique_vals\n",
        "    }\n",
        "\n",
        "# Display summary in a readable way\n",
        "print(\"Unique count and value of catagorical features:\")\n",
        "for col, info in cat_summary.items():\n",
        "    print(f\"Column: {col}\")\n",
        "    print(f\"  Unique Count : {info['Unique_Count']}\")\n",
        "    print(f\"  Unique Values: {info['Unique_Values']}\\n\")"
      ],
      "metadata": {
        "id": "Um2Ro7GCgbFz"
      },
      "id": "Um2Ro7GCgbFz",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ===========================================\n",
        "# SAFE ENHANCED CATEGORICAL ENCODING\n",
        "# ===========================================\n",
        "\n",
        "# -------------------------------\n",
        "# 0Ô∏è‚É£ Configuration\n",
        "# -------------------------------\n",
        "CURRENT_DATE = pd.Timestamp('2026-01-30')  # fixed date for Age calculation\n",
        "MAX_UNIQUE_OHE = 8  # Only one-hot encode columns with <=8 unique categories\n",
        "ALPHA = 10  # smoothing for target encoding\n",
        "\n",
        "# -------------------------------\n",
        "# 1Ô∏è‚É£ Fill missing / fix NaNs\n",
        "# -------------------------------\n",
        "if 'Health_Issue' in df.columns:\n",
        "    df['Health_Issue'] = df['Health_Issue'].fillna('No Issue')\n",
        "\n",
        "for col in ['Father_Education', 'Mother_Education']:\n",
        "    if col in df.columns:\n",
        "        df[col] = df[col].fillna('Unknown')\n",
        "\n",
        "# -------------------------------\n",
        "# 2Ô∏è‚É£ Binary encoding\n",
        "# -------------------------------\n",
        "binary_maps = {\n",
        "    'Gender': {'Male': 0, 'Female': 1},\n",
        "    'Home_Internet_Access': {'No': 0, 'Yes': 1},\n",
        "    'Electricity_Access': {'No': 0, 'Yes': 1},\n",
        "    'School_Location': {'Rural': 0, 'Urban': 1}\n",
        "}\n",
        "\n",
        "for col, mapping in binary_maps.items():\n",
        "    if col in df.columns:\n",
        "        df[col] = df[col].map(mapping)\n",
        "\n",
        "# -------------------------------\n",
        "# 3Ô∏è‚É£ Ordinal encoding (Parents Education)\n",
        "# -------------------------------\n",
        "edu_map = {'Unknown': 0, 'Primary': 1, 'High School': 2, 'College': 3, 'University': 4}\n",
        "for col in ['Father_Education', 'Mother_Education']:\n",
        "    enc_col = col + '_Encoded'\n",
        "    if col in df.columns:\n",
        "        df[enc_col] = df[col].map(edu_map)\n",
        "        df.drop(columns=[col], inplace=True)\n",
        "\n",
        "# -------------------------------\n",
        "# 4Ô∏è‚É£ Smoothed Target Encoding Function\n",
        "# -------------------------------\n",
        "def target_encode_smooth(df, col, target, alpha=ALPHA):\n",
        "    \"\"\"Smoothed target encoding\"\"\"\n",
        "    global_mean = df[target].mean()\n",
        "    stats = df.groupby(col)[target].agg(['mean', 'count'])\n",
        "    smooth = (stats['count'] * stats['mean'] + alpha * global_mean) / (stats['count'] + alpha)\n",
        "    return df[col].map(smooth).fillna(global_mean)\n",
        "\n",
        "# -------------------------------\n",
        "# 5Ô∏è‚É£ Key Feature Encoding\n",
        "# -------------------------------\n",
        "\n",
        "# REGION (Target Encoding)\n",
        "if 'Region' in df.columns:\n",
        "    df['Region_Encoded'] = target_encode_smooth(df, 'Region', TARGET)\n",
        "    df.drop(columns=['Region'], inplace=True)\n",
        "\n",
        "# SCHOOL_TYPE (Frequency + Target Encoding)\n",
        "if 'School_Type' in df.columns:\n",
        "    freq_map = df['School_Type'].value_counts(normalize=True).to_dict()\n",
        "    df['School_Type_Freq'] = df['School_Type'].map(freq_map)\n",
        "    df['School_Type_Target'] = target_encode_smooth(df, 'School_Type', TARGET)\n",
        "    df.drop(columns=['School_Type'], inplace=True)\n",
        "\n",
        "# -------------------------------\n",
        "# HEALTH_ISSUE (Binary + Target Encoding) FIXED\n",
        "# -------------------------------\n",
        "if 'Health_Issue' in df.columns:\n",
        "    # Fill missing first\n",
        "    df['Health_Issue'] = df['Health_Issue'].fillna('No Issue')\n",
        "\n",
        "    # -------------------------------\n",
        "    # 2Ô∏è‚É£ Clean string values\n",
        "    # -------------------------------\n",
        "    # Remove extra spaces and standardize capitalization\n",
        "    df['Health_Issue'] = df['Health_Issue'].astype(str).str.strip().str.title()\n",
        "\n",
        "    # -------------------------------\n",
        "    # 3Ô∏è‚É£ Define binary mapping\n",
        "    # -------------------------------\n",
        "    # No Issue ‚Üí 0, everything else ‚Üí 1\n",
        "    df['Health_Issue_Binary'] = np.where(df['Health_Issue'] == 'No Issue', 0, 1)\n",
        "\n",
        "    # -------------------------------\n",
        "    # 4Ô∏è‚É£ Convert to integer type\n",
        "    # -------------------------------\n",
        "    df['Health_Issue_Binary'] = df['Health_Issue_Binary'].astype(int)\n",
        "\n",
        "    # Target encoding\n",
        "    df['Health_Issue_Target'] = target_encode_smooth(df, 'Health_Issue', TARGET)\n",
        "\n",
        "    # Drop original column\n",
        "    df.drop(columns=['Health_Issue'], inplace=True)\n",
        "\n",
        "# -------------------------------\n",
        "# 6Ô∏è‚É£ Safe One-Hot Encoding for remaining categorical features\n",
        "# -------------------------------\n",
        "remaining_cats = df.select_dtypes(include=['object', 'category']).columns.tolist()\n",
        "\n",
        "# Only one-hot encode columns with few unique values\n",
        "safe_ohe_cols = [col for col in remaining_cats if df[col].nunique() <= MAX_UNIQUE_OHE]\n",
        "\n",
        "if safe_ohe_cols:\n",
        "    df = pd.get_dummies(df, columns=safe_ohe_cols, drop_first=True)\n",
        "\n",
        "# -------------------------------\n",
        "# 7Ô∏è‚É£ Convert Date_of_Birth ‚Üí Age\n",
        "# -------------------------------\n",
        "if 'Date_of_Birth' in df.columns:\n",
        "    df['Date_of_Birth'] = pd.to_datetime(df['Date_of_Birth'], errors='coerce')\n",
        "    df['Age'] = ((CURRENT_DATE - df['Date_of_Birth']).dt.days // 365).astype(float)\n",
        "    df.drop(columns=['Date_of_Birth'], inplace=True)\n",
        "for col in [ 'Career_Interest']:\n",
        "    if col in df.columns:\n",
        "        df[col + '_Encoded'] = target_encode_smooth(df, col, TARGET, alpha=10)\n",
        "        df.drop(columns=[col], inplace=True)\n",
        "# -------------------------------\n",
        "# 8Ô∏è‚É£ Final Safety Check\n",
        "# -------------------------------\n",
        "print(\"Safe categorical encoding completed.\")\n",
        "print(\"Remaining object columns:\", df.select_dtypes(include=['object']).columns.tolist())  # should be empty\n",
        "print(\"Final number of columns:\", df.shape[1])"
      ],
      "metadata": {
        "id": "hK5jVbCqgmbh"
      },
      "id": "hK5jVbCqgmbh",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# -------------------------------\n",
        "# üîü Drop Raw Categorical Columns\n",
        "# -------------------------------\n",
        "drop_cols = [\n",
        "    'Father_Education', 'Mother_Education','Career_Interest',\n",
        "    'Health_Issue', 'Region','Date_of_Birth',\n",
        "    'School_ID', 'School_Type'\n",
        "]\n",
        "df.drop(columns=[c for c in drop_cols if c in df.columns], inplace=True)\n",
        "\n",
        "# after remove catagorical feature\n",
        "df.head()"
      ],
      "metadata": {
        "id": "8nswGZz8gub2"
      },
      "id": "8nswGZz8gub2",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# =====================================\n",
        "#  Summary Statistics, Check skewness and detecting outlier\n",
        "# =====================================\n",
        "# ------------------------------\n",
        "# 1Ô∏è‚É£ Summary Statistics\n",
        "# ------------------------------\n",
        "print(\"Summary statistics of numeric features and target:\\n\")\n",
        "print(df.describe().T)\n",
        "\n",
        "# ------------------------------\n",
        "# 2Ô∏è‚É£ Check skewness\n",
        "# ------------------------------\n",
        "print(\"\\nSkewness of numeric features and target:\\n\")\n",
        "print(df.skew())\n",
        "\n",
        "selected_numeric_cols = [\n",
        "    \"Total_National_Exam_Score\",\n",
        "    \"Avg_Score_Preparatory\",\n",
        "    \"Textbook_Access_11_12\",\n",
        "    \"Parental_Involvement\",\n",
        "    \"Engagement_11_12\",\n",
        "    \"Engagement_1_4\",\n",
        "    \"School_Academic_Score\",\n",
        "    \"Teacher_Student_Ratio\",\n",
        "    \"School_Resources_Score\"\n",
        "]\n",
        "\n",
        "# ------------------------------\n",
        "# 3Ô∏è‚É£ Plot Histograms for selected numeric features\n",
        "# ------------------------------\n",
        "n_cols = 3  # number of columns in plot grid\n",
        "n_rows = int(np.ceil(len(selected_numeric_cols)/n_cols))\n",
        "\n",
        "plt.figure(figsize=(n_cols*5, n_rows*4))\n",
        "\n",
        "for i, col in enumerate(selected_numeric_cols, 1):\n",
        "    plt.subplot(n_rows, n_cols, i)\n",
        "    sns.histplot(df[col], kde=True, bins=30, color='skyblue')\n",
        "    plt.title(f'Distribution of {col}')\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "# ------------------------------\n",
        "# 4Ô∏è‚É£ Boxplots to detect outliers for selected features\n",
        "# ------------------------------\n",
        "plt.figure(figsize=(n_cols*5, n_rows*4))\n",
        "for i, col in enumerate(selected_numeric_cols, 1):\n",
        "    plt.subplot(n_rows, n_cols, i)\n",
        "    sns.boxplot(x=df[col], color='lightgreen')\n",
        "    plt.title(f'Boxplot of {col}')\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "4YCgJ2S9AOTI"
      },
      "id": "4YCgJ2S9AOTI",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ==============================\n",
        "# Robust Modeling Pipeline - FIXED (ONE CELL)\n",
        "# ==============================\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.preprocessing import PowerTransformer\n",
        "\n",
        "from sklearn.impute import SimpleImputer\n",
        "from sklearn.linear_model import LinearRegression, LassoCV, RidgeCV\n",
        "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor\n",
        "import xgboost as xgb\n",
        "\n",
        "from sklearn.metrics import r2_score, mean_absolute_error, mean_squared_error\n",
        "from statsmodels.stats.stattools import durbin_watson\n",
        "from scipy.stats.mstats import winsorize\n",
        "\n",
        "# ------------------------------\n",
        "# Settings\n",
        "# ------------------------------\n",
        "TARGET = 'Total_National_Exam_Score'\n",
        "TEST_SIZE = 0.2\n",
        "RANDOM_STATE = 42\n",
        "WINSOR_LIMIT = 0.005\n",
        "SKEW_THRESHOLD = 1.0\n",
        "\n",
        "# ------------------------------\n",
        "# 1Ô∏è‚É£ Prepare features and target\n",
        "# ------------------------------\n",
        "X = df.drop(columns=[TARGET])\n",
        "y = np.log1p(df[TARGET])  # log-transform target\n",
        "\n",
        "numeric_cols = X.select_dtypes(include=['float64', 'int64']).columns.tolist()\n",
        "\n",
        "# ------------------------------\n",
        "# 2Ô∏è‚É£ Train/Test Split (FIX: no leakage)\n",
        "# ------------------------------\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X, y,\n",
        "    test_size=TEST_SIZE,\n",
        "    random_state=RANDOM_STATE\n",
        ")\n",
        "\n",
        "# ------------------------------\n",
        "# 4Ô∏è‚É£ Winsorize numeric features (FIT LOGIC ON TRAIN ONLY)\n",
        "# ------------------------------\n",
        "for col in numeric_cols:\n",
        "    X_train[col] = winsorize(X_train[col], limits=(WINSOR_LIMIT, WINSOR_LIMIT))\n",
        "    X_test[col] = winsorize(X_test[col], limits=(WINSOR_LIMIT, WINSOR_LIMIT))\n",
        "\n",
        "# ------------------------------\n",
        "# 5Ô∏è‚É£ Detect skewed features using TRAIN only\n",
        "# ------------------------------\n",
        "skewed_cols = [\n",
        "    col for col in numeric_cols\n",
        "    if abs(pd.Series(X_train[col]).skew()) > SKEW_THRESHOLD\n",
        "]\n",
        "\n",
        "# ------------------------------\n",
        "# 6Ô∏è‚É£ Log-transform skewed features (SAFE)\n",
        "# ------------------------------\n",
        "for col in skewed_cols:\n",
        "    X_train[col] = np.log1p(X_train[col])\n",
        "    X_test[col] = np.log1p(X_test[col])\n",
        "\n",
        "# ------------------------------\n",
        "# 7Ô∏è‚É£ Scale features (FIX for linear models)\n",
        "# ------------------------------\n",
        "scaler = StandardScaler()\n",
        "X_train[numeric_cols] = scaler.fit_transform(X_train[numeric_cols])\n",
        "X_test[numeric_cols] = scaler.transform(X_test[numeric_cols])\n",
        "\n",
        "print(\"All columns used for modeling:\", numeric_cols)\n",
        "print(\"Log-transformed (skewed) columns:\", skewed_cols)"
      ],
      "metadata": {
        "id": "WJ9ji7nAAps3"
      },
      "id": "WJ9ji7nAAps3",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ===============================================================\n",
        "# COMPLETE REGRESSION PIPELINE: LINEAR + NON-LINEAR + COMPARISON\n",
        "# ===============================================================\n",
        "\n",
        "RANDOM_STATE = 42\n",
        "sns.set(style=\"whitegrid\")\n",
        "\n",
        "# ===============================================================\n",
        "# 1Ô∏è‚É£ LINEAR PREPROCESSING (UNCHANGED)\n",
        "# ===============================================================\n",
        "\n",
        "pt = PowerTransformer(method='yeo-johnson', standardize=True)\n",
        "X_train[numeric_cols] = pt.fit_transform(X_train[numeric_cols])\n",
        "X_test[numeric_cols]  = pt.transform(X_test[numeric_cols])\n",
        "\n",
        "scaler = StandardScaler()\n",
        "X_train[numeric_cols] = scaler.fit_transform(X_train[numeric_cols])\n",
        "X_test[numeric_cols]  = scaler.transform(X_test[numeric_cols])\n",
        "\n",
        "# ===============================================================\n",
        "# 2Ô∏è‚É£ LINEARITY & INDEPENDENCE CHECK (UNCHANGED)\n",
        "# ===============================================================\n",
        "\n",
        "def check_linearity_independence(X, y):\n",
        "    lr = LinearRegression()\n",
        "    lr.fit(X, y)\n",
        "    y_pred = lr.predict(X)\n",
        "    residuals = y - y_pred\n",
        "\n",
        "    plt.figure(figsize=(7,5))\n",
        "    sns.scatterplot(x=y_pred, y=residuals, alpha=0.5)\n",
        "    plt.axhline(0, color='red', linestyle='--')\n",
        "    plt.xlabel(\"Predicted Values\")\n",
        "    plt.ylabel(\"Residuals\")\n",
        "    plt.title(\"Residuals vs Predicted (Linearity & Homoscedasticity)\")\n",
        "    plt.show()\n",
        "\n",
        "    dw = durbin_watson(residuals)\n",
        "    print(f\"Durbin-Watson statistic: {dw:.2f} (~2-> residuals are independant)\")\n",
        "\n",
        "    return residuals\n",
        "\n",
        "_ = check_linearity_independence(X_train, y_train)\n",
        "\n",
        "# ===============================================================\n",
        "# 3Ô∏è‚É£ TRAIN & COMPARE ALL MODELS\n",
        "# ===============================================================\n",
        "\n",
        "models = {\n",
        "    \"Linear Regression\": LinearRegression(),\n",
        "    \"Lasso Regression\": LassoCV(alphas=np.logspace(-3, 1, 20), cv=5, max_iter=5000, random_state=RANDOM_STATE),\n",
        "    \"Ridge Regression\": RidgeCV(alphas=np.logspace(-3, 3, 20), cv=5),\n",
        "    \"Random Forest\": RandomForestRegressor(n_estimators=500, max_depth=10, min_samples_leaf=5,\n",
        "                                           random_state=RANDOM_STATE, n_jobs=-1),\n",
        "    \"XGBoost\": xgb.XGBRegressor(n_estimators=500, learning_rate=0.05, max_depth=5,\n",
        "                               subsample=0.8, colsample_bytree=0.8,\n",
        "                               random_state=RANDOM_STATE, n_jobs=-1),\n",
        "    \"Gradient Boosting\": GradientBoostingRegressor(n_estimators=300, learning_rate=0.05,\n",
        "                                                   max_depth=3, random_state=RANDOM_STATE)\n",
        "}\n",
        "\n",
        "results = []\n",
        "\n",
        "for name, model in models.items():\n",
        "    model.fit(X_train, y_train)\n",
        "    preds = model.predict(X_test)\n",
        "\n",
        "    results.append({\n",
        "        \"Model\": name,\n",
        "        \"R2_Score\": r2_score(y_test, preds),\n",
        "        \"MAE\": mean_absolute_error(y_test, preds),\n",
        "        \"RMSE\": np.sqrt(mean_squared_error(y_test, preds)),\n",
        "        \"Predictions\": preds,\n",
        "        \"Model_Object\": model\n",
        "    })\n",
        "\n",
        "comparison_df = pd.DataFrame(results).sort_values(\"R2_Score\", ascending=False)\n",
        "\n",
        "print(\"\\nüìä MODEL PERFORMANCE COMPARISON\")\n",
        "print(comparison_df[[\"Model\", \"R2_Score\", \"MAE\", \"RMSE\"]])\n",
        "\n",
        "# ===============================================================\n",
        "# 4Ô∏è‚É£ BEST MODEL\n",
        "# ===============================================================\n",
        "\n",
        "best_row = comparison_df.iloc[0]\n",
        "best_model_name = best_row[\"Model\"]\n",
        "best_predictions = best_row[\"Predictions\"]\n",
        "\n",
        "print(f\"\\nüèÜ BEST MODEL: {best_model_name}\")\n",
        "print(f\"R¬≤   : {best_row['R2_Score']:.4f}\")\n",
        "print(f\"MAE  : {best_row['MAE']:.4f}\")\n",
        "print(f\"RMSE : {best_row['RMSE']:.4f}\")\n",
        "\n",
        "# ===============================================================\n",
        "# 5Ô∏è‚É£ VISUALIZATION\n",
        "# ===============================================================\n",
        "\n",
        "fig = plt.figure(figsize=(20, 14))\n",
        "\n",
        "# --- R¬≤ ---\n",
        "ax1 = plt.subplot(2,3,1)\n",
        "ax1.bar(comparison_df[\"Model\"], comparison_df[\"R2_Score\"])\n",
        "ax1.set_title(\"R¬≤ Score\")\n",
        "ax1.tick_params(axis='x', rotation=45)\n",
        "ax1.grid(alpha=0.3)\n",
        "\n",
        "# --- MAE ---\n",
        "ax2 = plt.subplot(2,3,2)\n",
        "ax2.bar(comparison_df[\"Model\"], comparison_df[\"MAE\"])\n",
        "ax2.set_ylim(0, 0.15) # üëà FIX: compress error scale\n",
        "ax2.set_title(\"MAE\")\n",
        "ax2.tick_params(axis='x', rotation=45)\n",
        "ax2.grid(alpha=0.3)\n",
        "\n",
        "# --- RMSE ---\n",
        "ax3 = plt.subplot(2,3,3)\n",
        "ax3.bar(comparison_df[\"Model\"], comparison_df[\"RMSE\"])\n",
        "ax3.set_ylim(0, 0.15) # üëà FIX: compress error scale\n",
        "ax3.set_title(\"RMSE\")\n",
        "ax3.tick_params(axis='x', rotation=45)\n",
        "ax3.grid(alpha=0.3)\n",
        "\n",
        "# --- Actual vs Predicted ---\n",
        "ax4 = plt.subplot(2,3,5)\n",
        "ax4.scatter(y_test, best_predictions, alpha=0.6,\n",
        "            c=np.abs(y_test - best_predictions), cmap=\"viridis\")\n",
        "min_val = min(y_test.min(), best_predictions.min())\n",
        "max_val = max(y_test.max(), best_predictions.max())\n",
        "ax4.plot([min_val, max_val], [min_val, max_val], 'r--')\n",
        "ax4.set_title(f\"Actual vs Predicted ({best_model_name})\")\n",
        "ax4.set_xlabel(\"Actual\")\n",
        "ax4.set_ylabel(\"Predicted\")\n",
        "plt.colorbar(ax4.collections[0], ax=ax4, label=\"Absolute Error\")\n",
        "\n",
        "plt.suptitle(f\"Model Comparison | Best Model: {best_model_name}\", fontsize=18)\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "sFtlF5_wAxdV"
      },
      "id": "sFtlF5_wAxdV",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#-------------------------------\n",
        "# Overfitting check\n",
        "#-------------------------------\n",
        "\n",
        "overfit_results = []\n",
        "\n",
        "for name, model in models.items():\n",
        "    # Train\n",
        "    model.fit(X_train, y_train)\n",
        "\n",
        "    # Predictions\n",
        "    train_pred = model.predict(X_train)\n",
        "    test_pred  = model.predict(X_test)\n",
        "\n",
        "    overfit_results.append({\n",
        "        \"Model\": name,\n",
        "        \"Train_R2\": r2_score(y_train, train_pred),\n",
        "        \"Test_R2\": r2_score(y_test, test_pred),\n",
        "        \"Train_MAE\": mean_absolute_error(y_train, train_pred),\n",
        "        \"Test_MAE\": mean_absolute_error(y_test, test_pred),\n",
        "        \"R2_Gap\": r2_score(y_train, train_pred) - r2_score(y_test, test_pred)\n",
        "    })\n",
        "\n",
        "overfit_df = pd.DataFrame(overfit_results).sort_values(\"Test_R2\", ascending=False)\n",
        "\n",
        "print(\"\\nüìä OVERFITTING CHECK: TRAIN vs TEST\")\n",
        "print(overfit_df)"
      ],
      "metadata": {
        "id": "hkkDWyyKmGrF"
      },
      "id": "hkkDWyyKmGrF",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Get the best model predictions\n",
        "best_model = models[\"Gradient Boosting\"]\n",
        "best_model.fit(X_train, y_train)\n",
        "test_predictions_log = best_model.predict(X_test)\n",
        "\n",
        "# Convert back to original scale\n",
        "test_actual_original = np.expm1(y_test)  # Inverse log transformation\n",
        "test_predicted_original = np.expm1(test_predictions_log)\n",
        "\n",
        "# Create comparison DataFrame\n",
        "comparison_df = pd.DataFrame({\n",
        "    'Actual_National_Exam_Score': test_actual_original,\n",
        "    'Predicted_National_Exam_Score': test_predicted_original,\n",
        "    'Absolute_Error': np.abs(test_actual_original - test_predicted_original),\n",
        "    'Percent_Error': (np.abs(test_actual_original - test_predicted_original) / test_actual_original) * 100\n",
        "})\n",
        "\n",
        "# Add student index for reference\n",
        "comparison_df.index.name = 'Student_Index'\n",
        "\n",
        "# Display concise summary - top 20 rows\n",
        "print(\"=\" * 80)\n",
        "print(\"ACTUAL VS PREDICTED NATIONAL EXAM SCORES (First 20 Students)\")\n",
        "print(\"=\" * 80)\n",
        "print(f\"{'Student':^10} {'Actual':^15} {'Predicted':^15} {'Error':^10} {'% Error':^10}\")\n",
        "print(\"-\" * 80)\n",
        "\n",
        "for idx, row in comparison_df.head(20).iterrows():\n",
        "    print(f\"{idx:<10} {row['Actual_National_Exam_Score']:>15.2f} \"\n",
        "          f\"{row['Predicted_National_Exam_Score']:>15.2f} \"\n",
        "          f\"{row['Absolute_Error']:>10.2f} \"\n",
        "          f\"{row['Percent_Error']:>9.2f}%\")\n",
        "\n",
        "print(\"-\" * 80)\n",
        "\n",
        "# Summary statistics\n",
        "print(\"\\n\" + \"=\" * 80)\n",
        "print(\"PERFORMANCE SUMMARY (Original Scale)\")\n",
        "print(\"=\" * 80)\n",
        "print(f\"Mean Actual Score: {comparison_df['Actual_National_Exam_Score'].mean():.2f}\")\n",
        "print(f\"Mean Predicted Score: {comparison_df['Predicted_National_Exam_Score'].mean():.2f}\")\n",
        "print(f\"Mean Absolute Error: {comparison_df['Absolute_Error'].mean():.2f}\")\n",
        "print(f\"Mean Percent Error: {comparison_df['Percent_Error'].mean():.2f}%\")\n",
        "print(f\"Std Dev of Errors: {comparison_df['Absolute_Error'].std():.2f}\")\n",
        "\n",
        "# Distribution of errors\n",
        "print(\"\\n\" + \"=\" * 80)\n",
        "print(\"ERROR DISTRIBUTION ANALYSIS\")\n",
        "print(\"=\" * 80)\n",
        "print(f\"Min Error: {comparison_df['Absolute_Error'].min():.2f}\")\n",
        "print(f\"25th Percentile Error: {comparison_df['Absolute_Error'].quantile(0.25):.2f}\")\n",
        "print(f\"Median Error: {comparison_df['Absolute_Error'].median():.2f}\")\n",
        "print(f\"75th Percentile Error: {comparison_df['Absolute_Error'].quantile(0.75):.2f}\")\n",
        "print(f\"Max Error: {comparison_df['Absolute_Error'].max():.2f}\")"
      ],
      "metadata": {
        "id": "xXklgBgHmSI0"
      },
      "id": "xXklgBgHmSI0",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import (\n",
        "    classification_report,\n",
        "    confusion_matrix,\n",
        "    roc_curve,\n",
        "    auc,\n",
        "    RocCurveDisplay\n",
        ")\n",
        "from imblearn.over_sampling import SMOTE\n",
        "\n",
        "# -----------------------------\n",
        "# 1Ô∏è‚É£ Define Pass/Fail Target\n",
        "# -----------------------------\n",
        "df['Pass_Fail'] = (df['Total_National_Exam_Score'] >= 350).astype(int)\n",
        "print(\"Class distribution:\\n\", df['Pass_Fail'].value_counts())\n",
        "\n",
        "# -----------------------------\n",
        "# 2Ô∏è‚É£ Define Features and Target\n",
        "# -----------------------------\n",
        "X = df.drop(['Total_National_Exam_Score', 'Pass_Fail'], axis=1)\n",
        "y = df['Pass_Fail']\n",
        "\n",
        "# -----------------------------\n",
        "# 3Ô∏è‚É£ Train/Test Split (stratified)\n",
        "# -----------------------------\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X, y, test_size=0.2, random_state=42, stratify=y\n",
        ")\n",
        "\n",
        "# -----------------------------\n",
        "# 4Ô∏è‚É£ Handle Class Imbalance (SMOTE)\n",
        "# -----------------------------\n",
        "smote = SMOTE(random_state=42)\n",
        "X_train_res, y_train_res = smote.fit_resample(X_train, y_train)\n",
        "\n",
        "print(\"\\nAfter SMOTE, training class distribution:\")\n",
        "print(pd.Series(y_train_res).value_counts())\n",
        "\n",
        "# -----------------------------\n",
        "# 5Ô∏è‚É£ Train Random Forest Classifier\n",
        "# -----------------------------\n",
        "rf = RandomForestClassifier(\n",
        "    n_estimators=200,\n",
        "    max_depth=15,\n",
        "    random_state=42\n",
        ")\n",
        "rf.fit(X_train_res, y_train_res)\n",
        "\n",
        "# -----------------------------\n",
        "# 6Ô∏è‚É£ Make Predictions with Adjusted Threshold\n",
        "# -----------------------------\n",
        "y_probs = rf.predict_proba(X_test)[:, 1]\n",
        "\n",
        "# Adjust threshold\n",
        "threshold = 0.50\n",
        "y_pred = (y_probs >= threshold).astype(int)\n",
        "\n",
        "# -----------------------------\n",
        "# 7Ô∏è‚É£ Evaluate Model\n",
        "# -----------------------------\n",
        "print(\"\\nClassification Report:\\n\")\n",
        "print(classification_report(y_test, y_pred))\n",
        "\n",
        "cm = confusion_matrix(y_test, y_pred)\n",
        "print(\"\\nConfusion Matrix:\\n\", cm)\n",
        "\n",
        "# -----------------------------\n",
        "# 8Ô∏è‚É£ Visualize Confusion Matrix\n",
        "# -----------------------------\n",
        "plt.figure(figsize=(6,5))\n",
        "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=['Fail', 'Pass'], yticklabels=['Fail', 'Pass'])\n",
        "plt.xlabel('Predicted')\n",
        "plt.ylabel('Actual')\n",
        "plt.title('Confusion Matrix')\n",
        "plt.show()\n",
        "\n",
        "# -----------------------------\n",
        "# 9Ô∏è‚É£ ROC Curve\n",
        "# -----------------------------\n",
        "fpr, tpr, thresholds_roc = roc_curve(y_test, y_probs)\n",
        "roc_auc = auc(fpr, tpr)\n",
        "\n",
        "plt.figure(figsize=(6,5))\n",
        "plt.plot(fpr, tpr, color='darkorange', lw=2, label=f'ROC curve (AUC = {roc_auc:.3f})')\n",
        "plt.plot([0,1], [0,1], color='navy', lw=2, linestyle='--')\n",
        "plt.xlabel('False Positive Rate')\n",
        "plt.ylabel('True Positive Rate')\n",
        "plt.title('ROC Curve')\n",
        "plt.legend(loc=\"lower right\")\n",
        "plt.grid(True)\n",
        "plt.show()\n",
        "\n",
        "# -----------------------------\n",
        "# 10Ô∏è‚É£ Feature Importance\n",
        "# -----------------------------\n",
        "feature_importance = pd.Series(rf.feature_importances_, index=X.columns)\n",
        "feature_importance = feature_importance.sort_values(ascending=False)\n",
        "print(\"\\nTop 10 Features by Importance:\\n\", feature_importance.head(10))\n",
        "\n",
        "# -----------------------------\n",
        "# 11Ô∏è‚É£ Visualize Top 10 Features\n",
        "# -----------------------------\n",
        "top_features = feature_importance.head(10)\n",
        "plt.figure(figsize=(10,6))\n",
        "sns.barplot(x=top_features.values, y=top_features.index, color='skyblue')\n",
        "plt.title('Top 10 Features Influencing Pass/Fail')\n",
        "plt.xlabel('Importance Score')\n",
        "plt.ylabel('Feature')\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "# -----------------------------\n",
        "# 12Ô∏è‚É£ Probability Distribution by Class\n",
        "# -----------------------------\n",
        "plt.figure(figsize=(8,5))\n",
        "sns.histplot(y_probs[y_test==0], color='red', label='Fail', kde=True, stat=\"density\", bins=25, alpha=0.6)\n",
        "sns.histplot(y_probs[y_test==1], color='green', label='Pass', kde=True, stat=\"density\", bins=25, alpha=0.6)\n",
        "plt.axvline(threshold, color='black', linestyle='--', label=f'Threshold = {threshold}')\n",
        "plt.title('Predicted Probabilities Distribution by Class')\n",
        "plt.xlabel('Predicted Probability for Pass')\n",
        "plt.ylabel('Density')\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "2LUA9B09BBXw"
      },
      "id": "2LUA9B09BBXw",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}