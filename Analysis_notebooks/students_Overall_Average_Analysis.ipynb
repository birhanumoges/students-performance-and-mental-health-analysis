{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UtAVF1N1MTSz"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns"
      ],
      "id": "UtAVF1N1MTSz"
    },
    {
      "cell_type": "code",
      "source": [
        "# Load CSV file\n",
        "df = pd.read_csv(r\"C:/Users/DELL/Downloads/ethiopian_students_dataset.csv\")\n",
        "\n",
        "# View first 5 rows\n",
        "print(df.head())\n",
        "\n",
        "# Access a column\n",
        "print(df.columns)"
      ],
      "metadata": {
        "id": "x8yIkBIOMhVc"
      },
      "id": "x8yIkBIOMhVc",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 1. Check the basic structure\n",
        "print(\"=\"*60)\n",
        "print(\"DATA STRUCTURE ANALYSIS\")\n",
        "print(\"=\"*60)\n",
        "\n",
        "print(f\"Dataset Shape: {df.shape}\")\n",
        "print(f\"Number of students: {df.shape[0]}\")\n",
        "print(f\"Number of columns: {df.shape[1]}\")\n",
        "print(f\"Memory usage: {df.memory_usage(deep=True).sum() / 1024**2:.2f} MB\")\n",
        "\n",
        "# 2. View column categories\n",
        "print(\"\\n\" + \"=\"*60)\n",
        "print(\"COLUMN CATEGORIES\")\n",
        "print(\"=\"*60)\n",
        "\n",
        "# Group columns by type\n",
        "test_score_cols = [col for col in df.columns if 'Test_Score' in col]\n",
        "attendance_cols = [col for col in df.columns if 'Attendance' in col]\n",
        "homework_cols = [col for col in df.columns if 'Homework' in col]\n",
        "participation_cols = [col for col in df.columns if 'Participation' in col]\n",
        "textbook_cols = [col for col in df.columns if 'Textbook' in col]\n",
        "\n",
        "print(f\"Test Score columns: {len(test_score_cols)}\")\n",
        "print(f\"Attendance columns: {len(attendance_cols)}\")\n",
        "print(f\"Homework columns: {len(homework_cols)}\")\n",
        "print(f\"Participation columns: {len(participation_cols)}\")\n",
        "print(f\"Textbook columns: {len(textbook_cols)}\")\n",
        "\n",
        "# 3. Check subject coverage by grade\n",
        "print(\"\\n\" + \"=\"*60)\n",
        "print(\"SUBJECT COVERAGE BY GRADE\")\n",
        "print(\"=\"*60)\n",
        "\n",
        "for grade in range(1, 13):\n",
        "    grade_test_cols = [col for col in test_score_cols if f'Grade_{grade}_' in col]\n",
        "    if grade_test_cols:\n",
        "        subjects = list(set([col.split(f'Grade_{grade}_')[1].split('_Test')[0]\n",
        "                           for col in grade_test_cols]))\n",
        "        print(f\"Grade {grade}: {len(grade_test_cols)} subjects - {subjects}\")\n",
        "\n",
        "all_categorized_cols = set(test_score_cols + attendance_cols + homework_cols + participation_cols + textbook_cols)\n",
        "remaining_cols = [col for col in df.columns if col not in all_categorized_cols]\n",
        "\n",
        "print(\"\\n\" + \"=\"*60)\n",
        "print(\"REMAINING COLUMNS\")\n",
        "print(\"=\"*60)\n",
        "print(f\"Number of remaining columns: {len(remaining_cols)}\")\n",
        "print(\"Remaining columns (first 20):\\n\", remaining_cols[:20])\n",
        "print(\"Remaining columns (last 20):\\n\", remaining_cols[-20:])"
      ],
      "metadata": {
        "id": "nKzZezxiMlm2"
      },
      "id": "nKzZezxiMlm2",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Check for nulls per column\n",
        "print(\"==============================\")\n",
        "print(\"CHECKING FOR MISSING DATA\")\n",
        "print(\"==============================\")\n",
        "print(df.isnull().sum())\n",
        "\n",
        "# Check the percentage of missing data\n",
        "print(\"================================\")\n",
        "print(\"Percentage of missing data:\")\n",
        "print(\"--------------------------------\")\n",
        "print(df.isnull().mean() * 100)"
      ],
      "metadata": {
        "id": "cESECZqVMxsw"
      },
      "id": "cESECZqVMxsw",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 1. Get the value counts of dtypes\n",
        "dtype_counts = df.dtypes.value_counts().reset_index()\n",
        "dtype_counts.columns = ['Data Type', 'Count']\n",
        "\n",
        "# 2. Plotting with the fix\n",
        "plt.figure(figsize=(10, 6))\n",
        "\n",
        "# Fix: Assign 'Data Type' to hue and set legend=False\n",
        "sns.barplot(\n",
        "    data=dtype_counts,\n",
        "    x='Data Type',\n",
        "    y='Count',\n",
        "    hue='Data Type',\n",
        "    palette='viridis',\n",
        "    legend=False\n",
        ")\n",
        "\n",
        "plt.title('Distribution of Data Types in Student Dataset', fontsize=14)\n",
        "plt.ylabel('Number of Columns')\n",
        "plt.xlabel('Data Type')\n",
        "\n",
        "# 3. Add labels on top of bars\n",
        "for i, count in enumerate(dtype_counts['Count']):\n",
        "    plt.text(i, count + 5, str(count), ha='center', fontweight='bold')\n",
        "\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "WNQSlNVoM2qq"
      },
      "id": "WNQSlNVoM2qq",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ================================\n",
        "# 1Ô∏è‚É£ INITIAL CLEANING & ENCODING\n",
        "# ================================\n",
        "# Drop Student_ID (never used in ML)\n",
        "df = df.drop(columns=['Student_ID'], errors='ignore')\n",
        "\n",
        "# Encode Field_Choice (Social=0, Natural=1)\n",
        "df['Field_Choice'] = df['Field_Choice'].map({'Social': 0, 'Natural': 1})\n",
        "\n",
        "# Fill missing Career_Interest with \"Unknown\"\n",
        "df['Career_Interest'] = df['Career_Interest'].fillna('Unknown')\n",
        "\n",
        "\n",
        "# ================================\n",
        "# 2Ô∏è‚É£ DEFINE EDUCATION STAGES\n",
        "# ================================\n",
        "lower_primary = ['Grade_1', 'Grade_2', 'Grade_3', 'Grade_4']\n",
        "upper_primary = ['Grade_5', 'Grade_6', 'Grade_7', 'Grade_8']\n",
        "secondary     = ['Grade_9', 'Grade_10']\n",
        "preparatory   = ['Grade_11', 'Grade_12']\n",
        "\n",
        "stages = {\n",
        "    'Lower_Primary': lower_primary,\n",
        "    'Upper_Primary': upper_primary,\n",
        "    'Secondary': secondary,\n",
        "    'Preparatory': preparatory\n",
        "}\n",
        "\n",
        "\n",
        "# ================================\n",
        "# 3Ô∏è‚É£ HELPER FUNCTION TO AGGREGATE GRADES\n",
        "# ================================\n",
        "def stage_average(df, grades, metric_keywords):\n",
        "    \"\"\"\n",
        "    Compute average across all columns for a given stage and metric keywords.\n",
        "    Returns the average series and list of original columns used.\n",
        "    \"\"\"\n",
        "    cols = []\n",
        "    for g in grades:\n",
        "        for keyword in metric_keywords:\n",
        "            cols += [c for c in df.columns if c.startswith(g) and keyword.lower() in c.lower()]\n",
        "    cols = list(set(cols))\n",
        "    return df[cols].mean(axis=1), cols\n",
        "\n",
        "\n",
        "# ================================\n",
        "# 4Ô∏è‚É£ AGGREGATE TEST SCORE, ATTENDANCE, HW, PARTICIPATION\n",
        "# ================================\n",
        "metrics_dict = {\n",
        "    'Test_Score': ['Test_Score'],\n",
        "    'Attendance': ['Attendance'],\n",
        "    'HW_Completion': ['Homework_Completion'],\n",
        "    'Participation': ['Participation']\n",
        "}\n",
        "\n",
        "cols_to_drop = []\n",
        "\n",
        "for metric_name, keywords in metrics_dict.items():\n",
        "    for stage_name, grades in stages.items():\n",
        "        col_name = f'Avg_{metric_name}_{stage_name}'\n",
        "        df[col_name], original_cols = stage_average(df, grades, keywords)\n",
        "        cols_to_drop += original_cols\n",
        "\n",
        "# Drop original grade-level columns\n",
        "df.drop(columns=list(set(cols_to_drop)), inplace=True)\n",
        "\n",
        "# Columns list for display\n",
        "aggregated_cols = [f'Avg_{m}_{s}' for m in metrics_dict.keys() for s in stages.keys()]\n",
        "print(\"Aggregated averages per Education Stage (head):\")\n",
        "print(df[aggregated_cols].head())\n",
        "\n",
        "\n",
        "# ================================\n",
        "# 5Ô∏è‚É£ AGGREGATE TEXTBOOK ACCESS\n",
        "# ================================\n",
        "# Convert Yes/No ‚Üí 1/0 safely\n",
        "textbook_cols = [c for c in df.columns if 'Textbook' in c]\n",
        "for col in textbook_cols:\n",
        "    df[col] = df[col].replace({'Yes': 1, 'No': 0}).infer_objects(copy=False)\n",
        "\n",
        "# Helper function for textbook access per stage\n",
        "def textbook_access(df, grade_prefixes):\n",
        "    cols = []\n",
        "    for g in grade_prefixes:\n",
        "        cols.extend([c for c in df.columns if c.startswith(g) and 'Textbook' in c])\n",
        "    return df[cols].mean(axis=1) if len(cols) > 0 else pd.Series(0, index=df.index)\n",
        "\n",
        "# Create aggregated textbook access per stage\n",
        "new_cols_df = pd.DataFrame({\n",
        "    'Textbook_Access_1_4': textbook_access(df, lower_primary),\n",
        "    'Textbook_Access_5_8': textbook_access(df, upper_primary),\n",
        "    'Textbook_Access_9_10': textbook_access(df, secondary),\n",
        "    'Textbook_Access_11_12': textbook_access(df, preparatory)\n",
        "})\n",
        "\n",
        "df = pd.concat([df, new_cols_df], axis=1)\n",
        "df = df.loc[:, ~df.columns.duplicated()]  # remove duplicates\n",
        "\n",
        "# Display and visualize\n",
        "textbook_summary_cols = [c for c in new_cols_df.columns if c in df.columns]\n",
        "print(df[textbook_summary_cols].head())\n",
        "\n",
        "plt.figure(figsize=(10, 6))\n",
        "sns.boxplot(data=df[textbook_summary_cols])\n",
        "plt.title('Textbook Access Distribution by Education Level', fontsize=14, fontweight='bold')\n",
        "plt.ylabel('Access Score (0 to 1)')\n",
        "plt.xticks(rotation=15)\n",
        "plt.grid(alpha=0.3)\n",
        "plt.show()\n",
        "\n",
        "\n",
        "# ================================\n",
        "# 6Ô∏è‚É£ TRACK-BASED NATIONAL EXAMS\n",
        "# ================================\n",
        "# Subjects per track\n",
        "social_subjects = ['National_Exam_History', 'National_Exam_Geography',\n",
        "                   'National_Exam_Economics', 'National_Exam_Math_Social']\n",
        "\n",
        "natural_subjects = ['National_Exam_Biology', 'National_Exam_Chemistry',\n",
        "                    'National_Exam_Physics', 'National_Exam_Math_Natural']\n",
        "\n",
        "# Track-specific averages\n",
        "df['Social_Track_Subject_Avg']  = df[social_subjects].mean(axis=1)\n",
        "df['Natural_Track_Subject_Avg'] = df[natural_subjects].mean(axis=1)\n",
        "\n",
        "# Track-based assignment\n",
        "df['Track_Subject_Average'] = np.where(\n",
        "    df['Field_Choice'] == 0,\n",
        "    df['Social_Track_Subject_Avg'],\n",
        "    df['Natural_Track_Subject_Avg']\n",
        ")\n",
        "\n",
        "# Common subjects for all students\n",
        "common_subjects = ['National_Exam_Aptitude', 'National_Exam_English',\n",
        "                   'National_Exam_Civics_and_Ethical_Education']\n",
        "df['Common_Exam_Average'] = df[common_subjects].mean(axis=1)\n",
        "\n",
        "# Overall Track Exam Average\n",
        "df['Track_Exam_Average'] = (df['Common_Exam_Average'] + df['Track_Subject_Average']) / 2\n",
        "\n",
        "# Display new exam columns\n",
        "exam_cols = [\n",
        "    'Social_Track_Subject_Avg',\n",
        "    'Natural_Track_Subject_Avg',\n",
        "    'Track_Subject_Average',\n",
        "    'Common_Exam_Average',\n",
        "    'Track_Exam_Average'\n",
        "]\n",
        "print(\"New Aggregated National Exam Features:\")\n",
        "print(df[exam_cols].head())\n",
        "\n",
        "\n",
        "# ================================\n",
        "# 7Ô∏è‚É£ VISUALIZATION: Exam Scores\n",
        "# ================================\n",
        "sns.set_theme(style=\"whitegrid\")\n",
        "fig, axes = plt.subplots(1, 2, figsize=(16, 6))\n",
        "\n",
        "# Boxplot: Common vs Track vs Overall\n",
        "sns.boxplot(data=df[['Common_Exam_Average', 'Track_Subject_Average', 'Track_Exam_Average']],\n",
        "            ax=axes[0], palette=\"Set2\")\n",
        "axes[0].set_title('Distribution of Aggregate Exam Scores')\n",
        "axes[0].set_ylabel('Score (0-100)')\n",
        "\n",
        "# KDE: Track Exam Average by Field Choice\n",
        "for choice, label in [(0, 'Social Science'), (1, 'Natural Science')]:\n",
        "    subset = df[df['Field_Choice'] == choice]\n",
        "    sns.kdeplot(subset['Track_Exam_Average'], ax=axes[1], label=label, fill=True)\n",
        "\n",
        "axes[1].set_title('Track Exam Average: Social vs. Natural')\n",
        "axes[1].set_xlabel('Score')\n",
        "axes[1].legend()\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "sTn8xQmkM92M"
      },
      "id": "sTn8xQmkM92M",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# DROP ORIGINAL HIGH-DIMENSION COLUMNS\n",
        "drop_cols = [c for c in df.columns if c.startswith('Grade_')]\n",
        "drop_cols += [c for c in df.columns if c.startswith('National_Exam_')]\n",
        "\n",
        "df = df.drop(columns=drop_cols)\n",
        "# -------------------------------\n",
        "# 0Ô∏è‚É£ Drop leaking exam average columns\n",
        "# -------------------------------\n",
        "leak_cols = [\n",
        "    'Total_National_Exam_Score',\n",
        "    'Social_Track_Subject_Avg',\n",
        "    'Natural_Track_Subject_Avg',\n",
        "    'Track_Exam_Average',\n",
        "    'Track_Subject_Average',\n",
        "    'Common_Exam_Average',\n",
        "    'Avg_Score_Secondary',\n",
        "    'Avg_Score_Preparatory',\n",
        "    'Avg_Score_Lower_Primary',\n",
        "    'Avg_Score_Upper_Primary',\n",
        "    'Avg_Test_Score_Secondary',  'Avg_Test_Score_Preparatory',\n",
        "    'Avg_Test_Score_Lower_Primary',  'Avg_Test_Score_Upper_Primary',\n",
        "    'School_ID', 'Total_Test_Score']\n",
        "\n",
        "df = df.drop(columns=[c for c in leak_cols if c in df.columns])\n",
        "\n",
        "# fix null value\n",
        "df['Health_Issue'] = df['Health_Issue'].fillna('No Issue')\n",
        "df['Father_Education'] = df['Father_Education'].fillna('Unknown')\n",
        "df['Mother_Education'] = df['Mother_Education'].fillna('Unknown')\n",
        "\n",
        "# FINAL CHECK\n",
        "print(df.shape)\n",
        "print(df.head())\n",
        "print(\"all columns:\",df.columns)"
      ],
      "metadata": {
        "id": "RhyHXEjrU5Sc"
      },
      "id": "RhyHXEjrU5Sc",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "TARGET = 'Overall_Average'\n",
        "\n",
        "# Select numeric columns only\n",
        "num_cols = df.select_dtypes(include=['int64', 'float64']).columns\n",
        "\n",
        "# Compute correlations with target\n",
        "corr_numeric = (\n",
        "    df[num_cols]\n",
        "    .corr()[TARGET]\n",
        "    .drop(TARGET)\n",
        "    .sort_values(key=abs, ascending=False)\n",
        ")\n",
        "\n",
        "print(\"üìä Numeric Feature Correlation with Target:\")\n",
        "print(corr_numeric)\n",
        "\n",
        "plt.figure(figsize=(10, 8))\n",
        "\n",
        "sns.barplot(\n",
        "    x=corr_numeric.values,\n",
        "    y=corr_numeric.index,\n",
        "    hue=corr_numeric.index,\n",
        "    palette='coolwarm',\n",
        "    legend=False\n",
        ")\n",
        "\n",
        "plt.axvline(0, color='black', linewidth=1)\n",
        "plt.title('Correlation with Total_National_Exam_Score')\n",
        "plt.xlabel('Pearson Correlation')\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "qWv5UHCQVAwg"
      },
      "id": "qWv5UHCQVAwg",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cat_cols = df.select_dtypes(include='object').columns.drop(TARGET, errors='ignore')\n",
        "\n",
        "cat_corr = {}\n",
        "\n",
        "for col in cat_cols:\n",
        "    means = df.groupby(col)[TARGET].mean()\n",
        "    encoded = df[col].map(means)\n",
        "    cat_corr[col] = encoded.corr(df[TARGET])\n",
        "\n",
        "cat_corr = (\n",
        "    pd.Series(cat_corr)\n",
        "    .sort_values(key=abs, ascending=False)\n",
        ")\n",
        "\n",
        "print(\"üìä Categorical Feature Association with Target:\")\n",
        "print(cat_corr)"
      ],
      "metadata": {
        "id": "MDVdDo95VLeZ"
      },
      "id": "MDVdDo95VLeZ",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ================================\n",
        "# ALL-IN-ONE CATEGORICAL ENCODING\n",
        "# ================================\n",
        "\n",
        "# -------------------------------\n",
        "# 1Ô∏è‚É£ Fill missing / fix NaNs\n",
        "# -------------------------------\n",
        "if 'Health_Issue' in df.columns:\n",
        "    df['Health_Issue'] = df['Health_Issue'].fillna('No Issue')\n",
        "\n",
        "for col in ['Father_Education', 'Mother_Education']:\n",
        "    if col in df.columns:\n",
        "        df[col] = df[col].fillna('Unknown')\n",
        "\n",
        "# -------------------------------\n",
        "# 2Ô∏è‚É£ Binary encoding\n",
        "# -------------------------------\n",
        "binary_maps = {\n",
        "    'Gender': {'Male': 0, 'Female': 1},\n",
        "    'Home_Internet_Access': {'No': 0, 'Yes': 1},\n",
        "    'Electricity_Access': {'No': 0, 'Yes': 1},\n",
        "    'School_Location': {'Rural': 0, 'Urban': 1}\n",
        "}\n",
        "\n",
        "for col, mapping in binary_maps.items():\n",
        "    if col in df.columns:\n",
        "        df[col] = df[col].map(mapping)\n",
        "\n",
        "# -------------------------------\n",
        "# 3Ô∏è‚É£ Ordinal encoding (Parents Education)\n",
        "# -------------------------------\n",
        "edu_map = {'Unknown': 0, 'Primary': 1, 'High School': 2, 'College': 3, 'University': 4}\n",
        "for col in ['Father_Education', 'Mother_Education']:\n",
        "    enc_col = col + '_Encoded'\n",
        "    if col in df.columns:\n",
        "        df[enc_col] = df[col].map(edu_map)\n",
        "        df.drop(columns=[col], inplace=True)\n",
        "\n",
        "# -------------------------------\n",
        "# 4Ô∏è‚É£ One-Hot Encoding (moderate cardinality)\n",
        "# -------------------------------\n",
        "ohe_cols = [c for c in ['Region', 'School_Type', 'Health_Issue'] if c in df.columns]\n",
        "if ohe_cols:\n",
        "    df = pd.get_dummies(df, columns=ohe_cols, drop_first=True)\n",
        "\n",
        "# -------------------------------\n",
        "# 5Ô∏è‚É£ Target Encoding (high cardinality)\n",
        "# -------------------------------\n",
        "def target_encode_smooth(df, col, target, alpha=10):\n",
        "    global_mean = df[target].mean()\n",
        "    stats = df.groupby(col)[target].agg(['mean','count'])\n",
        "    smooth = (stats['count'] * stats['mean'] + alpha * global_mean) / (stats['count'] + alpha)\n",
        "    return df[col].map(smooth).fillna(global_mean)\n",
        "\n",
        "for col in ['School_ID', 'Career_Interest']:\n",
        "    if col in df.columns:\n",
        "        df[col + '_Encoded'] = target_encode_smooth(df, col, TARGET, alpha=10)\n",
        "        df.drop(columns=[col], inplace=True)\n",
        "\n",
        "# -------------------------------\n",
        "# Convert Date_of_Birth ‚Üí Age (numeric)\n",
        "# -------------------------------\n",
        "CURRENT_DATE = pd.Timestamp('2026-01-30')  # fixed date for reproducibility\n",
        "\n",
        "if 'Date_of_Birth' in df.columns:\n",
        "    df['Date_of_Birth'] = pd.to_datetime(df['Date_of_Birth'], errors='coerce')\n",
        "    df['Age'] = ((CURRENT_DATE - df['Date_of_Birth']).dt.days // 365).astype(float)\n",
        "    df.drop(columns=['Date_of_Birth'], inplace=True)\n",
        "\n",
        "# -------------------------------\n",
        "# 6Ô∏è‚É£ Safety check\n",
        "# -------------------------------\n",
        "print(\"Categorical encoding completed.\")\n",
        "print(\"Columns now:\", df.select_dtypes(include='object').columns.tolist())  # should be empty"
      ],
      "metadata": {
        "id": "FZ0jT6I431qy"
      },
      "id": "FZ0jT6I431qy",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# -------------------------------\n",
        "# üîü Drop Raw Categorical Columns\n",
        "# -------------------------------\n",
        "drop_cols = [\n",
        "    'Father_Education', 'Mother_Education','Career_Interest',\n",
        "    'Health_Issue', 'Region','Date_of_Birth',\n",
        "    'School_ID', 'School_Type'\n",
        "]\n",
        "df.drop(columns=[c for c in drop_cols if c in df.columns], inplace=True)"
      ],
      "metadata": {
        "id": "dhJmOFKq4GXu"
      },
      "id": "dhJmOFKq4GXu",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.info()"
      ],
      "metadata": {
        "id": "tRSl2O6X4KmC"
      },
      "id": "tRSl2O6X4KmC",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ======================================\n",
        "# 1. Imports\n",
        "# ======================================\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.pipeline import Pipeline\n",
        "\n",
        "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
        "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor\n",
        "from xgboost import XGBRegressor\n",
        "from sklearn.preprocessing import PowerTransformer, StandardScaler\n",
        "\n",
        "X = df.drop(columns=[TARGET])\n",
        "y = df[TARGET]"
      ],
      "metadata": {
        "id": "1F4Iq_ZI4Su-"
      },
      "id": "1F4Iq_ZI4Su-",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ======================================\n",
        "# 2. Split Data (Assuming X, y are defined)\n",
        "# ======================================\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X, y, test_size=0.2, random_state=42\n",
        ")\n",
        "\n",
        "# ======================================\n",
        "# 3. Identify Numeric & Categorical Columns\n",
        "# ======================================\n",
        "numeric_features = X.select_dtypes(include=[\"int64\", \"float64\"]).columns\n",
        "categorical_features = X.select_dtypes(exclude=[\"int64\", \"float64\"]).columns\n",
        "\n",
        "# ======================================\n",
        "# 4. Preprocessing\n",
        "# ======================================\n",
        "preprocessor = ColumnTransformer(\n",
        "    transformers=[\n",
        "        (\"num\", StandardScaler(), numeric_features),\n",
        "        (\"cat\", \"passthrough\", categorical_features)\n",
        "    ]\n",
        ")\n",
        "\n",
        "# ======================================\n",
        "# 5. Define Models\n",
        "# ======================================\n",
        "models = {\n",
        "    \"XGBoost\": XGBRegressor(\n",
        "        n_estimators=700,\n",
        "        max_depth=5,\n",
        "        learning_rate=0.05,\n",
        "        subsample=0.8,\n",
        "        colsample_bytree=0.8,\n",
        "        reg_alpha=1.0,\n",
        "        reg_lambda=2.0,\n",
        "        objective=\"reg:squarederror\",\n",
        "        random_state=42,\n",
        "        n_jobs=-1\n",
        "    ),\n",
        "    \"RandomForest\": RandomForestRegressor(\n",
        "        n_estimators=500,\n",
        "        max_depth=10,\n",
        "        random_state=42,\n",
        "        n_jobs=-1\n",
        "    ),\n",
        "    \"GradientBoosting\": GradientBoostingRegressor(\n",
        "        n_estimators=500,\n",
        "        learning_rate=0.05,\n",
        "        max_depth=5,\n",
        "        random_state=42\n",
        "    )\n",
        "}\n",
        "\n",
        "# ======================================\n",
        "# 6. Train, Predict, Evaluate\n",
        "# ======================================\n",
        "results = {}\n",
        "\n",
        "for name, model in models.items():\n",
        "    print(f\"\\n==== Training {name} ====\")\n",
        "    pipeline = Pipeline(steps=[\n",
        "        (\"preprocessor\", preprocessor),\n",
        "        (\"model\", model)\n",
        "    ])\n",
        "    pipeline.fit(X_train, y_train)\n",
        "\n",
        "    y_pred = pipeline.predict(X_test)\n",
        "\n",
        "    mae = mean_absolute_error(y_test, y_pred)\n",
        "    rmse = np.sqrt(mean_squared_error(y_test, y_pred))\n",
        "    r2 = r2_score(y_test, y_pred)\n",
        "\n",
        "    results[name] = {\"MAE\": mae, \"RMSE\": rmse, \"R2\": r2}\n",
        "\n",
        "    print(f\"{name} Performance:\")\n",
        "    print(f\"MAE  : {mae:.2f}\")\n",
        "    print(f\"RMSE : {rmse:.2f}\")\n",
        "    print(f\"R¬≤   : {r2:.3f}\")\n",
        "\n",
        "    # Feature Importance (only for tree-based models)\n",
        "    if name in [\"XGBoost\", \"RandomForest\", \"GradientBoosting\"]:\n",
        "        feature_names = numeric_features.tolist() + categorical_features.tolist()\n",
        "        importances = pipeline.named_steps[\"model\"].feature_importances_\n",
        "        feature_importance = pd.Series(importances, index=feature_names).sort_values(ascending=False)\n",
        "\n",
        "        print(\"\\nTop 10 Important Features:\")\n",
        "        print(feature_importance.head(10))\n",
        "\n",
        "        # Plot Feature Importance\n",
        "        plt.figure(figsize=(8, 5))\n",
        "        sns.barplot(x=feature_importance.head(10).values, y=feature_importance.head(10).index)\n",
        "        plt.title(f\"Top 10 Feature Importance - {name}\")\n",
        "        plt.xlabel(\"Importance\")\n",
        "        plt.ylabel(\"Feature\")\n",
        "        plt.show()\n",
        "\n",
        "    # Actual vs Predicted Plot\n",
        "    plt.figure(figsize=(6, 6))\n",
        "    plt.scatter(y_test, y_pred, alpha=0.4)\n",
        "    plt.plot([y_test.min(), y_test.max()], [y_test.min(), y_test.max()], \"r--\")\n",
        "    plt.xlabel(\"Actual Total Test Score\")\n",
        "    plt.ylabel(\"Predicted Total Test Score\")\n",
        "    plt.title(f\"Actual vs Predicted - {name}\")\n",
        "    plt.grid()\n",
        "    plt.show()\n",
        "\n",
        "# ======================================\n",
        "# 7. Compare All Models\n",
        "# ======================================\n",
        "comparison_df = pd.DataFrame(results).T\n",
        "print(\"\\n=== Model Comparison ===\")\n",
        "print(comparison_df.sort_values(\"R2\", ascending=False))"
      ],
      "metadata": {
        "id": "ZjoQ_KLl4X4q"
      },
      "id": "ZjoQ_KLl4X4q",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ==============================\n",
        "# STUDENT RISK / NOT-RISK PREDICTION PIPELINE\n",
        "# (FIXED THRESHOLD = 50%)\n",
        "# ==============================\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import (\n",
        "    classification_report,\n",
        "    confusion_matrix,\n",
        "    roc_auc_score,\n",
        "    roc_curve,\n",
        "    f1_score\n",
        ")\n",
        "from imblearn.over_sampling import SMOTE\n",
        "\n",
        "# -----------------------------\n",
        "# 1Ô∏è‚É£ DEFINE TARGET COLUMN\n",
        "# -----------------------------\n",
        "score_col = 'Overall_Average'   # Change if needed\n",
        "\n",
        "# -----------------------------\n",
        "# 2Ô∏è‚É£ CREATE RISK / NOT-RISK TARGET\n",
        "# Risk = 1 (score < 50), NotRisk = 0 (score >= 50)\n",
        "# -----------------------------\n",
        "df['Risk_NotRisk'] = (df[score_col] < 50).astype(int)\n",
        "\n",
        "print(\"\\nClass distribution:\")\n",
        "print(df['Risk_NotRisk'].value_counts())\n",
        "\n",
        "# -----------------------------\n",
        "# 3Ô∏è‚É£ PREPARE FEATURES\n",
        "# -----------------------------\n",
        "X = df.drop(\n",
        "    ['Risk_NotRisk', score_col, 'Total_National_Exam_Score'],\n",
        "    axis=1,\n",
        "    errors='ignore'\n",
        ")\n",
        "y = df['Risk_NotRisk']\n",
        "\n",
        "# One-hot encode categorical variables\n",
        "categorical_cols = X.select_dtypes(include=['object', 'category']).columns\n",
        "X_encoded = pd.get_dummies(X, columns=categorical_cols, drop_first=True)\n",
        "\n",
        "print(f\"\\nFeature shape: {X_encoded.shape}\")\n",
        "print(f\"Target shape: {y.shape}\")\n",
        "\n",
        "# -----------------------------\n",
        "# 4Ô∏è‚É£ TRAIN / TEST SPLIT\n",
        "# -----------------------------\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X_encoded,\n",
        "    y,\n",
        "    test_size=0.2,\n",
        "    random_state=42,\n",
        "    stratify=y\n",
        ")\n",
        "\n",
        "print(\"\\nTrain/Test split:\")\n",
        "print(\"Train size:\", X_train.shape[0])\n",
        "print(\"Test size :\", X_test.shape[0])\n",
        "\n",
        "# -----------------------------\n",
        "# 5Ô∏è‚É£ HANDLE CLASS IMBALANCE (SMOTE)\n",
        "# -----------------------------\n",
        "smote = SMOTE(random_state=42)\n",
        "X_train_res, y_train_res = smote.fit_resample(X_train, y_train)\n",
        "\n",
        "print(\"\\nAfter SMOTE:\")\n",
        "print(pd.Series(y_train_res).value_counts())\n",
        "\n",
        "# -----------------------------\n",
        "# 6Ô∏è‚É£ TRAIN RANDOM FOREST\n",
        "# -----------------------------\n",
        "rf = RandomForestClassifier(\n",
        "    n_estimators=200,\n",
        "    max_depth=15,\n",
        "    random_state=42,\n",
        "    n_jobs=-1\n",
        ")\n",
        "\n",
        "rf.fit(X_train_res, y_train_res)\n",
        "\n",
        "# -----------------------------\n",
        "# 7Ô∏è‚É£ PREDICT (FIXED THRESHOLD = 0.50)\n",
        "# -----------------------------\n",
        "FIXED_THRESHOLD = 0.50\n",
        "\n",
        "y_probs = rf.predict_proba(X_test)[:, 1]\n",
        "y_pred = (y_probs >= FIXED_THRESHOLD).astype(int)\n",
        "\n",
        "f1_fixed = f1_score(y_test, y_pred, pos_label=1)\n",
        "\n",
        "print(f\"\\nUsing fixed threshold: {FIXED_THRESHOLD}\")\n",
        "print(f\"F1-Score (Risk class): {f1_fixed:.3f}\")\n",
        "\n",
        "# -----------------------------\n",
        "# 8Ô∏è‚É£ MODEL EVALUATION\n",
        "# -----------------------------\n",
        "cm = confusion_matrix(y_test, y_pred)\n",
        "\n",
        "print(\"\\nClassification Report:\")\n",
        "print(classification_report(y_test, y_pred))\n",
        "\n",
        "print(\"Confusion Matrix:\")\n",
        "print(cm)\n",
        "\n",
        "roc_auc = roc_auc_score(y_test, y_probs)\n",
        "print(f\"ROC-AUC: {roc_auc:.3f}\")\n",
        "\n",
        "# -----------------------------\n",
        "# 9Ô∏è‚É£ VISUALIZATIONS\n",
        "# -----------------------------\n",
        "fig, axes = plt.subplots(2, 2, figsize=(14, 12))\n",
        "\n",
        "# ---- Confusion Matrix\n",
        "ax1 = axes[0, 0]\n",
        "sns.heatmap(\n",
        "    cm,\n",
        "    annot=True,\n",
        "    fmt='d',\n",
        "    cmap='Blues',\n",
        "    ax=ax1,\n",
        "    xticklabels=['Predicted NotRisk', 'Predicted Risk'],\n",
        "    yticklabels=['Actual NotRisk', 'Actual Risk']\n",
        ")\n",
        "ax1.set_title('Confusion Matrix (Threshold = 0.50)', fontweight='bold')\n",
        "\n",
        "# ---- ROC Curve\n",
        "ax2 = axes[0, 1]\n",
        "fpr, tpr, thresholds_roc = roc_curve(y_test, y_probs)\n",
        "ax2.plot(fpr, tpr, lw=2, label=f'AUC = {roc_auc:.3f}')\n",
        "ax2.plot([0, 1], [0, 1], linestyle='--', alpha=0.5)\n",
        "\n",
        "idx = np.argmin(np.abs(thresholds_roc - FIXED_THRESHOLD))\n",
        "ax2.scatter(fpr[idx], tpr[idx], s=100, label='Threshold 0.50')\n",
        "\n",
        "ax2.set_xlabel('False Positive Rate')\n",
        "ax2.set_ylabel('True Positive Rate')\n",
        "ax2.set_title('ROC Curve', fontweight='bold')\n",
        "ax2.legend()\n",
        "ax2.grid(alpha=0.3)\n",
        "\n",
        "# ---- Feature Importance\n",
        "ax3 = axes[1, 0]\n",
        "feature_importance = pd.Series(\n",
        "    rf.feature_importances_,\n",
        "    index=X_encoded.columns\n",
        ").sort_values(ascending=False)\n",
        "\n",
        "top_features = feature_importance.head(10)\n",
        "ax3.barh(top_features.index, top_features.values)\n",
        "ax3.invert_yaxis()\n",
        "ax3.set_title('Top 10 Feature Importances', fontweight='bold')\n",
        "ax3.set_xlabel('Importance')\n",
        "\n",
        "# ---- Probability Distribution\n",
        "ax4 = axes[1, 1]\n",
        "ax4.hist(y_probs[y_test == 0], bins=30, alpha=0.6, label='NotRisk')\n",
        "ax4.hist(y_probs[y_test == 1], bins=30, alpha=0.6, label='Risk')\n",
        "ax4.axvline(0.50, linestyle='--', label='Threshold 0.50')\n",
        "ax4.set_title('Predicted Probability Distribution', fontweight='bold')\n",
        "ax4.set_xlabel('Predicted Risk Probability')\n",
        "ax4.legend()\n",
        "\n",
        "plt.suptitle('Student Risk / Not-Risk Prediction (Fixed Threshold = 50%)',\n",
        "             fontsize=14, fontweight='bold')\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "# -----------------------------\n",
        "# üîü PRINT TOP FEATURES\n",
        "# -----------------------------\n",
        "print(\"\\n\" + \"=\" * 60)\n",
        "print(\"TOP 10 FEATURES INFLUENCING RISK / NOT-RISK\")\n",
        "print(\"=\" * 60)\n",
        "\n",
        "for i, (feature, importance) in enumerate(top_features.items(), 1):\n",
        "    print(f\"{i:2d}. {feature:<30} {importance:.4f}\")\n",
        "\n",
        "print(\"\\n\" + \"=\" * 60)\n",
        "print(\"PIPELINE COMPLETE ‚úî\")\n",
        "print(\"=\" * 60)"
      ],
      "metadata": {
        "id": "cU-ksb9_4egi"
      },
      "id": "cU-ksb9_4egi",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".ipynb",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.0"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}