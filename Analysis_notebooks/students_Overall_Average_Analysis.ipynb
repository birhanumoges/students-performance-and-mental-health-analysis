{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UtAVF1N1MTSz"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns"
      ],
      "id": "UtAVF1N1MTSz"
    },
    {
      "cell_type": "code",
      "source": [
        "# Load CSV file\n",
        "df = pd.read_csv(r\"C:/Users/DELL/Downloads/ethiopian_students_dataset.csv\")\n",
        "\n",
        "# View first 5 rows\n",
        "print(df.head())\n",
        "\n",
        "# Access a column\n",
        "print(df.columns)"
      ],
      "metadata": {
        "id": "x8yIkBIOMhVc"
      },
      "id": "x8yIkBIOMhVc",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 1. Check the basic structure\n",
        "print(\"=\"*60)\n",
        "print(\"DATA STRUCTURE ANALYSIS\")\n",
        "print(\"=\"*60)\n",
        "\n",
        "print(f\"Dataset Shape: {df.shape}\")\n",
        "print(f\"Number of students: {df.shape[0]}\")\n",
        "print(f\"Number of columns: {df.shape[1]}\")\n",
        "print(f\"Memory usage: {df.memory_usage(deep=True).sum() / 1024**2:.2f} MB\")\n",
        "\n",
        "# 2. View column categories\n",
        "print(\"\\n\" + \"=\"*60)\n",
        "print(\"COLUMN CATEGORIES\")\n",
        "print(\"=\"*60)\n",
        "\n",
        "# Group columns by type\n",
        "test_score_cols = [col for col in df.columns if 'Test_Score' in col]\n",
        "attendance_cols = [col for col in df.columns if 'Attendance' in col]\n",
        "homework_cols = [col for col in df.columns if 'Homework' in col]\n",
        "participation_cols = [col for col in df.columns if 'Participation' in col]\n",
        "textbook_cols = [col for col in df.columns if 'Textbook' in col]\n",
        "\n",
        "print(f\"Test Score columns: {len(test_score_cols)}\")\n",
        "print(f\"Attendance columns: {len(attendance_cols)}\")\n",
        "print(f\"Homework columns: {len(homework_cols)}\")\n",
        "print(f\"Participation columns: {len(participation_cols)}\")\n",
        "print(f\"Textbook columns: {len(textbook_cols)}\")\n",
        "\n",
        "# 3. Check subject coverage by grade\n",
        "print(\"\\n\" + \"=\"*60)\n",
        "print(\"SUBJECT COVERAGE BY GRADE\")\n",
        "print(\"=\"*60)\n",
        "\n",
        "for grade in range(1, 13):\n",
        "    grade_test_cols = [col for col in test_score_cols if f'Grade_{grade}_' in col]\n",
        "    if grade_test_cols:\n",
        "        subjects = list(set([col.split(f'Grade_{grade}_')[1].split('_Test')[0]\n",
        "                           for col in grade_test_cols]))\n",
        "        print(f\"Grade {grade}: {len(grade_test_cols)} subjects - {subjects}\")\n",
        "\n",
        "all_categorized_cols = set(test_score_cols + attendance_cols + homework_cols + participation_cols + textbook_cols)\n",
        "remaining_cols = [col for col in df.columns if col not in all_categorized_cols]\n",
        "\n",
        "print(\"\\n\" + \"=\"*60)\n",
        "print(\"REMAINING COLUMNS\")\n",
        "print(\"=\"*60)\n",
        "print(f\"Number of remaining columns: {len(remaining_cols)}\")\n",
        "print(\"Remaining columns (first 20):\\n\", remaining_cols[:20])\n",
        "print(\"Remaining columns (last 20):\\n\", remaining_cols[-20:])"
      ],
      "metadata": {
        "id": "nKzZezxiMlm2"
      },
      "id": "nKzZezxiMlm2",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Check for nulls per column\n",
        "print(\"==============================\")\n",
        "print(\"CHECKING FOR MISSING DATA\")\n",
        "print(\"==============================\")\n",
        "print(df.isnull().sum())\n",
        "\n",
        "# Check the percentage of missing data\n",
        "print(\"================================\")\n",
        "print(\"Percentage of missing data:\")\n",
        "print(\"--------------------------------\")\n",
        "print(df.isnull().mean() * 100)"
      ],
      "metadata": {
        "id": "cESECZqVMxsw"
      },
      "id": "cESECZqVMxsw",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 1. Get the value counts of dtypes\n",
        "dtype_counts = df.dtypes.value_counts().reset_index()\n",
        "dtype_counts.columns = ['Data Type', 'Count']\n",
        "\n",
        "# 2. Plotting with the fix\n",
        "plt.figure(figsize=(10, 6))\n",
        "\n",
        "# Fix: Assign 'Data Type' to hue and set legend=False\n",
        "sns.barplot(\n",
        "    data=dtype_counts,\n",
        "    x='Data Type',\n",
        "    y='Count',\n",
        "    hue='Data Type',\n",
        "    palette='viridis',\n",
        "    legend=False\n",
        ")\n",
        "\n",
        "plt.title('Distribution of Data Types in Student Dataset', fontsize=14)\n",
        "plt.ylabel('Number of Columns')\n",
        "plt.xlabel('Data Type')\n",
        "\n",
        "# 3. Add labels on top of bars\n",
        "for i, count in enumerate(dtype_counts['Count']):\n",
        "    plt.text(i, count + 5, str(count), ha='center', fontweight='bold')\n",
        "\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "WNQSlNVoM2qq"
      },
      "id": "WNQSlNVoM2qq",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ================================\n",
        "# 1Ô∏è‚É£ INITIAL CLEANING & ENCODING\n",
        "# ================================\n",
        "# Drop Student_ID (never used in ML)\n",
        "df = df.drop(columns=['Student_ID'], errors='ignore')\n",
        "\n",
        "# Encode Field_Choice (Social=0, Natural=1)\n",
        "df['Field_Choice'] = df['Field_Choice'].map({'Social': 0, 'Natural': 1})\n",
        "\n",
        "# Fill missing Career_Interest with \"Unknown\"\n",
        "df['Career_Interest'] = df['Career_Interest'].fillna('Unknown')\n",
        "\n",
        "\n",
        "# ================================\n",
        "# 2Ô∏è‚É£ DEFINE EDUCATION STAGES\n",
        "# ================================\n",
        "lower_primary = ['Grade_1', 'Grade_2', 'Grade_3', 'Grade_4']\n",
        "upper_primary = ['Grade_5', 'Grade_6', 'Grade_7', 'Grade_8']\n",
        "secondary     = ['Grade_9', 'Grade_10']\n",
        "preparatory   = ['Grade_11', 'Grade_12']\n",
        "\n",
        "stages = {\n",
        "    'Lower_Primary': lower_primary,\n",
        "    'Upper_Primary': upper_primary,\n",
        "    'Secondary': secondary,\n",
        "    'Preparatory': preparatory\n",
        "}\n",
        "\n",
        "\n",
        "# ================================\n",
        "# 3Ô∏è‚É£ HELPER FUNCTION TO AGGREGATE GRADES\n",
        "# ================================\n",
        "def stage_average(df, grades, metric_keywords):\n",
        "    \"\"\"\n",
        "    Compute average across all columns for a given stage and metric keywords.\n",
        "    Returns the average series and list of original columns used.\n",
        "    \"\"\"\n",
        "    cols = []\n",
        "    for g in grades:\n",
        "        for keyword in metric_keywords:\n",
        "            cols += [c for c in df.columns if c.startswith(g) and keyword.lower() in c.lower()]\n",
        "    cols = list(set(cols))\n",
        "    return df[cols].mean(axis=1), cols\n",
        "\n",
        "\n",
        "# ================================\n",
        "# 4Ô∏è‚É£ AGGREGATE TEST SCORE, ATTENDANCE, HW, PARTICIPATION\n",
        "# ================================\n",
        "metrics_dict = {\n",
        "    'Test_Score': ['Test_Score'],\n",
        "    'Attendance': ['Attendance'],\n",
        "    'HW_Completion': ['Homework_Completion'],\n",
        "    'Participation': ['Participation']\n",
        "}\n",
        "\n",
        "cols_to_drop = []\n",
        "\n",
        "for metric_name, keywords in metrics_dict.items():\n",
        "    for stage_name, grades in stages.items():\n",
        "        col_name = f'Avg_{metric_name}_{stage_name}'\n",
        "        df[col_name], original_cols = stage_average(df, grades, keywords)\n",
        "        cols_to_drop += original_cols\n",
        "\n",
        "# Drop original grade-level columns\n",
        "df.drop(columns=list(set(cols_to_drop)), inplace=True)\n",
        "\n",
        "# Columns list for display\n",
        "aggregated_cols = [f'Avg_{m}_{s}' for m in metrics_dict.keys() for s in stages.keys()]\n",
        "print(\"Aggregated averages per Education Stage (head):\")\n",
        "print(df[aggregated_cols].head())\n",
        "\n",
        "\n",
        "# ================================\n",
        "# 5Ô∏è‚É£ AGGREGATE TEXTBOOK ACCESS\n",
        "# ================================\n",
        "# Convert Yes/No ‚Üí 1/0 safely\n",
        "textbook_cols = [c for c in df.columns if 'Textbook' in c]\n",
        "for col in textbook_cols:\n",
        "    df[col] = df[col].replace({'Yes': 1, 'No': 0}).infer_objects(copy=False)\n",
        "\n",
        "# Helper function for textbook access per stage\n",
        "def textbook_access(df, grade_prefixes):\n",
        "    cols = []\n",
        "    for g in grade_prefixes:\n",
        "        cols.extend([c for c in df.columns if c.startswith(g) and 'Textbook' in c])\n",
        "    return df[cols].mean(axis=1) if len(cols) > 0 else pd.Series(0, index=df.index)\n",
        "\n",
        "# Create aggregated textbook access per stage\n",
        "new_cols_df = pd.DataFrame({\n",
        "    'Textbook_Access_1_4': textbook_access(df, lower_primary),\n",
        "    'Textbook_Access_5_8': textbook_access(df, upper_primary),\n",
        "    'Textbook_Access_9_10': textbook_access(df, secondary),\n",
        "    'Textbook_Access_11_12': textbook_access(df, preparatory)\n",
        "})\n",
        "\n",
        "df = pd.concat([df, new_cols_df], axis=1)\n",
        "df = df.loc[:, ~df.columns.duplicated()]  # remove duplicates\n",
        "\n",
        "# Display and visualize\n",
        "textbook_summary_cols = [c for c in new_cols_df.columns if c in df.columns]\n",
        "print(df[textbook_summary_cols].head())\n",
        "\n",
        "plt.figure(figsize=(10, 6))\n",
        "sns.boxplot(data=df[textbook_summary_cols])\n",
        "plt.title('Textbook Access Distribution by Education Level', fontsize=14, fontweight='bold')\n",
        "plt.ylabel('Access Score (0 to 1)')\n",
        "plt.xticks(rotation=15)\n",
        "plt.grid(alpha=0.3)\n",
        "plt.show()\n",
        "\n",
        "\n",
        "# ================================\n",
        "# 6Ô∏è‚É£ TRACK-BASED NATIONAL EXAMS\n",
        "# ================================\n",
        "# Subjects per track\n",
        "social_subjects = ['National_Exam_History', 'National_Exam_Geography',\n",
        "                   'National_Exam_Economics', 'National_Exam_Math_Social']\n",
        "\n",
        "natural_subjects = ['National_Exam_Biology', 'National_Exam_Chemistry',\n",
        "                    'National_Exam_Physics', 'National_Exam_Math_Natural']\n",
        "\n",
        "# Track-specific averages\n",
        "df['Social_Track_Subject_Avg']  = df[social_subjects].mean(axis=1)\n",
        "df['Natural_Track_Subject_Avg'] = df[natural_subjects].mean(axis=1)\n",
        "\n",
        "# Track-based assignment\n",
        "df['Track_Subject_Average'] = np.where(\n",
        "    df['Field_Choice'] == 0,\n",
        "    df['Social_Track_Subject_Avg'],\n",
        "    df['Natural_Track_Subject_Avg']\n",
        ")\n",
        "\n",
        "# Common subjects for all students\n",
        "common_subjects = ['National_Exam_Aptitude', 'National_Exam_English',\n",
        "                   'National_Exam_Civics_and_Ethical_Education']\n",
        "df['Common_Exam_Average'] = df[common_subjects].mean(axis=1)\n",
        "\n",
        "# Overall Track Exam Average\n",
        "df['Track_Exam_Average'] = (df['Common_Exam_Average'] + df['Track_Subject_Average']) / 2\n",
        "\n",
        "# Display new exam columns\n",
        "exam_cols = [\n",
        "    'Social_Track_Subject_Avg',\n",
        "    'Natural_Track_Subject_Avg',\n",
        "    'Track_Subject_Average',\n",
        "    'Common_Exam_Average',\n",
        "    'Track_Exam_Average'\n",
        "]\n",
        "print(\"New Aggregated National Exam Features:\")\n",
        "print(df[exam_cols].head())\n",
        "\n",
        "\n",
        "# ================================\n",
        "# 7Ô∏è‚É£ VISUALIZATION: Exam Scores\n",
        "# ================================\n",
        "sns.set_theme(style=\"whitegrid\")\n",
        "fig, axes = plt.subplots(1, 2, figsize=(16, 6))\n",
        "\n",
        "# Boxplot: Common vs Track vs Overall\n",
        "sns.boxplot(data=df[['Common_Exam_Average', 'Track_Subject_Average', 'Track_Exam_Average']],\n",
        "            ax=axes[0], palette=\"Set2\")\n",
        "axes[0].set_title('Distribution of Aggregate Exam Scores')\n",
        "axes[0].set_ylabel('Score (0-100)')\n",
        "\n",
        "# KDE: Track Exam Average by Field Choice\n",
        "for choice, label in [(0, 'Social Science'), (1, 'Natural Science')]:\n",
        "    subset = df[df['Field_Choice'] == choice]\n",
        "    sns.kdeplot(subset['Track_Exam_Average'], ax=axes[1], label=label, fill=True)\n",
        "\n",
        "axes[1].set_title('Track Exam Average: Social vs. Natural')\n",
        "axes[1].set_xlabel('Score')\n",
        "axes[1].legend()\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "sTn8xQmkM92M"
      },
      "id": "sTn8xQmkM92M",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# DROP ORIGINAL HIGH-DIMENSION COLUMNS\n",
        "drop_cols = [c for c in df.columns if c.startswith('Grade_')]\n",
        "drop_cols += [c for c in df.columns if c.startswith('National_Exam_')]\n",
        "\n",
        "df = df.drop(columns=drop_cols)\n",
        "# -------------------------------\n",
        "# 0Ô∏è‚É£ Drop leaking exam average columns\n",
        "# -------------------------------\n",
        "leak_cols = [\n",
        "    'Total_National_Exam_Score',\n",
        "    'Social_Track_Subject_Avg',\n",
        "    'Natural_Track_Subject_Avg',\n",
        "    'Track_Exam_Average',\n",
        "    'Track_Subject_Average',\n",
        "    'Common_Exam_Average',\n",
        "    'Avg_Score_Secondary',\n",
        "    'Avg_Score_Preparatory',\n",
        "    'Avg_Score_Lower_Primary',\n",
        "    'Avg_Score_Upper_Primary',\n",
        "    'Avg_Test_Score_Secondary',  'Avg_Test_Score_Preparatory',\n",
        "    'Avg_Test_Score_Lower_Primary',  'Avg_Test_Score_Upper_Primary',\n",
        "    'School_ID', 'Total_Test_Score']\n",
        "\n",
        "df = df.drop(columns=[c for c in leak_cols if c in df.columns])\n",
        "\n",
        "# fix null value\n",
        "df['Health_Issue'] = df['Health_Issue'].fillna('No Issue')\n",
        "df['Father_Education'] = df['Father_Education'].fillna('Unknown')\n",
        "df['Mother_Education'] = df['Mother_Education'].fillna('Unknown')\n",
        "\n",
        "# FINAL CHECK\n",
        "print(df.shape)\n",
        "print(df.head())\n",
        "print(\"all columns:\",df.columns)"
      ],
      "metadata": {
        "id": "RhyHXEjrU5Sc"
      },
      "id": "RhyHXEjrU5Sc",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "TARGET = 'Overall_Average'\n",
        "\n",
        "# Select numeric columns only\n",
        "num_cols = df.select_dtypes(include=['int64', 'float64']).columns\n",
        "\n",
        "# Compute correlations with target\n",
        "corr_numeric = (\n",
        "    df[num_cols]\n",
        "    .corr()[TARGET]\n",
        "    .drop(TARGET)\n",
        "    .sort_values(key=abs, ascending=False)\n",
        ")\n",
        "\n",
        "print(\"üìä Numeric Feature Correlation with Target:\")\n",
        "print(corr_numeric)\n",
        "\n",
        "plt.figure(figsize=(10, 8))\n",
        "\n",
        "sns.barplot(\n",
        "    x=corr_numeric.values,\n",
        "    y=corr_numeric.index,\n",
        "    hue=corr_numeric.index,\n",
        "    palette='coolwarm',\n",
        "    legend=False\n",
        ")\n",
        "\n",
        "plt.axvline(0, color='black', linewidth=1)\n",
        "plt.title('Correlation with Total_National_Exam_Score')\n",
        "plt.xlabel('Pearson Correlation')\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "qWv5UHCQVAwg"
      },
      "id": "qWv5UHCQVAwg",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cat_cols = df.select_dtypes(include='object').columns.drop(TARGET, errors='ignore')\n",
        "\n",
        "cat_corr = {}\n",
        "\n",
        "for col in cat_cols:\n",
        "    means = df.groupby(col)[TARGET].mean()\n",
        "    encoded = df[col].map(means)\n",
        "    cat_corr[col] = encoded.corr(df[TARGET])\n",
        "\n",
        "cat_corr = (\n",
        "    pd.Series(cat_corr)\n",
        "    .sort_values(key=abs, ascending=False)\n",
        ")\n",
        "\n",
        "print(\"üìä Categorical Feature Association with Target:\")\n",
        "print(cat_corr)"
      ],
      "metadata": {
        "id": "MDVdDo95VLeZ"
      },
      "id": "MDVdDo95VLeZ",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ===========================================\n",
        "# SAFE ENHANCED CATEGORICAL ENCODING WITH K-FOLD TARGET ENCODING\n",
        "# ===========================================\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import KFold\n",
        "\n",
        "# -------------------------------\n",
        "# 0Ô∏è‚É£ Configuration\n",
        "# -------------------------------\n",
        "CURRENT_DATE = pd.Timestamp('2026-01-30')\n",
        "MAX_UNIQUE_OHE = 8\n",
        "ALPHA = 10\n",
        "N_SPLITS = 5  # number of folds for K-Fold target encoding\n",
        "\n",
        "# TARGET variable name (adjust if needed)\n",
        "TARGET = 'Overall_Average'   # or Total_National_Exam_Score\n",
        "\n",
        "# -------------------------------\n",
        "# 1Ô∏è‚É£ Fill missing values\n",
        "# -------------------------------\n",
        "if 'Health_Issue' in df.columns:\n",
        "    df['Health_Issue'] = df['Health_Issue'].fillna('No Issue')\n",
        "\n",
        "for col in ['Father_Education', 'Mother_Education']:\n",
        "    if col in df.columns:\n",
        "        df[col] = df[col].fillna('Unknown')\n",
        "\n",
        "# -------------------------------\n",
        "# 2Ô∏è‚É£ Binary encoding (Yes/No features)\n",
        "# -------------------------------\n",
        "binary_maps = {\n",
        "    'Gender': {'Male': 0, 'Female': 1},\n",
        "    'Home_Internet_Access': {'No': 0, 'Yes': 1},\n",
        "    'Electricity_Access': {'No': 0, 'Yes': 1},\n",
        "    'School_Location': {'Rural': 0, 'Urban': 1}\n",
        "}\n",
        "\n",
        "for col, mapping in binary_maps.items():\n",
        "    if col in df.columns:\n",
        "        df[col] = df[col].map(mapping)\n",
        "\n",
        "# -------------------------------\n",
        "# 3Ô∏è‚É£ Ordinal encoding (Parents Education)\n",
        "# -------------------------------\n",
        "edu_map = {\n",
        "    'Unknown': 0,\n",
        "    'Primary': 1,\n",
        "    'High School': 2,\n",
        "    'College': 3,\n",
        "    'University': 4\n",
        "}\n",
        "\n",
        "for col in ['Father_Education', 'Mother_Education']:\n",
        "    if col in df.columns:\n",
        "        df[col + '_Encoded'] = df[col].map(edu_map)\n",
        "        df.drop(columns=[col], inplace=True)\n",
        "\n",
        "# -------------------------------\n",
        "# 4Ô∏è‚É£ K-Fold Target Encoding Function\n",
        "# -------------------------------\n",
        "def kfold_target_encode(df, col, target, n_splits=N_SPLITS, alpha=ALPHA, random_state=42):\n",
        "    \"\"\"\n",
        "    K-Fold Target Encoding with smoothing.\n",
        "    Returns a Series of encoded values.\n",
        "    \"\"\"\n",
        "    df_encoded = pd.Series(index=df.index, dtype=float)\n",
        "    kf = KFold(n_splits=n_splits, shuffle=True, random_state=random_state)\n",
        "    global_mean = df[target].mean()\n",
        "\n",
        "    for train_idx, val_idx in kf.split(df):\n",
        "        train_data, val_data = df.iloc[train_idx], df.iloc[val_idx]\n",
        "        stats = train_data.groupby(col)[target].agg(['mean', 'count'])\n",
        "        smooth = (stats['count'] * stats['mean'] + alpha * global_mean) / (stats['count'] + alpha)\n",
        "        df_encoded.iloc[val_idx] = df.iloc[val_idx][col].map(smooth).fillna(global_mean)\n",
        "\n",
        "    return df_encoded\n",
        "\n",
        "# -------------------------------\n",
        "# 5Ô∏è‚É£ HEALTH ISSUE ‚Äî Binary + Severity + K-Fold Target\n",
        "# -------------------------------\n",
        "if 'Health_Issue' in df.columns:\n",
        "    df['Health_Issue'] = df['Health_Issue'].astype(str).str.strip().str.title()\n",
        "\n",
        "    # Binary flag\n",
        "    df['Health_Issue_Flag'] = np.where(df['Health_Issue'] == 'No Issue', 0, 1)\n",
        "\n",
        "    # Severity\n",
        "    severity_map = {\n",
        "        'No Issue': 0,\n",
        "        'Dental Problems': 1,\n",
        "        'Vision Issues': 1,\n",
        "        'Hearing Issues': 1,\n",
        "        'Anemia': 2,\n",
        "        'Parasitic Infections': 2,\n",
        "        'Respiratory Issues': 2,\n",
        "        'Malnutrition': 2,\n",
        "        'Physical Disability': 3,\n",
        "        'Chronic Illness': 3\n",
        "    }\n",
        "    df['Health_Issue_Severity'] = df['Health_Issue'].map(severity_map).fillna(1).astype(int)\n",
        "\n",
        "    # K-Fold Target Encoding\n",
        "    df['Health_Issue_Target'] = kfold_target_encode(df, 'Health_Issue', TARGET)\n",
        "\n",
        "    df.drop(columns=['Health_Issue'], inplace=True)\n",
        "\n",
        "# -------------------------------\n",
        "# 6Ô∏è‚É£ Region (K-Fold Target Encoding)\n",
        "# -------------------------------\n",
        "if 'Region' in df.columns:\n",
        "    df['Region_Encoded'] = kfold_target_encode(df, 'Region', TARGET)\n",
        "    df.drop(columns=['Region'], inplace=True)\n",
        "\n",
        "# -------------------------------\n",
        "# 7Ô∏è‚É£ School Type (Frequency + K-Fold Target Encoding)\n",
        "# -------------------------------\n",
        "if 'School_Type' in df.columns:\n",
        "    freq_map = df['School_Type'].value_counts(normalize=True).to_dict()\n",
        "    df['School_Type_Freq'] = df['School_Type'].map(freq_map)\n",
        "    df['School_Type_Target'] = kfold_target_encode(df, 'School_Type', TARGET)\n",
        "    df.drop(columns=['School_Type'], inplace=True)\n",
        "\n",
        "# -------------------------------\n",
        "# 8Ô∏è‚É£ Career Interest (K-Fold Target Encoding)\n",
        "# -------------------------------\n",
        "if 'Career_Interest' in df.columns:\n",
        "    df['Career_Interest_Encoded'] = kfold_target_encode(df, 'Career_Interest', TARGET)\n",
        "    df.drop(columns=['Career_Interest'], inplace=True)\n",
        "\n",
        "# -------------------------------\n",
        "# 9Ô∏è‚É£ Safe One-Hot Encoding (low-cardinality)\n",
        "# -------------------------------\n",
        "remaining_cats = df.select_dtypes(include=['object', 'category']).columns.tolist()\n",
        "safe_ohe_cols = [col for col in remaining_cats if df[col].nunique() <= MAX_UNIQUE_OHE]\n",
        "\n",
        "if safe_ohe_cols:\n",
        "    df = pd.get_dummies(df, columns=safe_ohe_cols, drop_first=True)\n",
        "\n",
        "# -------------------------------\n",
        "# üîü Date_of_Birth ‚Üí Age\n",
        "# -------------------------------\n",
        "if 'Date_of_Birth' in df.columns:\n",
        "    df['Date_of_Birth'] = pd.to_datetime(df['Date_of_Birth'], errors='coerce')\n",
        "    df['Age'] = ((CURRENT_DATE - df['Date_of_Birth']).dt.days // 365).astype(float)\n",
        "    df.drop(columns=['Date_of_Birth'], inplace=True)\n",
        "\n",
        "# -------------------------------\n",
        "# 1Ô∏è‚É£1Ô∏è‚É£ Final Safety Check\n",
        "# -------------------------------\n",
        "print(\"‚úÖ Safe categorical encoding with K-Fold target encoding completed\")\n",
        "print(\"Remaining object columns:\", df.select_dtypes(include=['object']).columns.tolist())\n",
        "print(\"Final number of columns:\", df.shape[1])"
      ],
      "metadata": {
        "id": "FZ0jT6I431qy"
      },
      "id": "FZ0jT6I431qy",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# -------------------------------\n",
        "# üîü Drop Raw Categorical Columns\n",
        "# -------------------------------\n",
        "drop_cols = [\n",
        "    'Father_Education', 'Mother_Education','Career_Interest',\n",
        "    'Health_Issue', 'Region','Date_of_Birth', 'School_Type'\n",
        "]\n",
        "df.drop(columns=[c for c in drop_cols if c in df.columns], inplace=True)"
      ],
      "metadata": {
        "id": "dhJmOFKq4GXu"
      },
      "id": "dhJmOFKq4GXu",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Get numeric columns that exist in df\n",
        "numeric_cols = df.select_dtypes(include='number').columns\n",
        "\n",
        "# Optional: compute correlation with target if you want top features\n",
        "target_corr = df.corr()[TARGET]  # replace 'Target' with your actual target column\n",
        "top_features = target_corr.abs().sort_values(ascending=False).head(23).index\n",
        "\n",
        "# Make sure only columns present in df are selected\n",
        "top_features = [c for c in top_features if c in df.columns]\n",
        "\n",
        "# Plot heatmap\n",
        "plt.figure(figsize=(12,12))\n",
        "sns.heatmap(df[top_features].corr(), annot=True, fmt=\".2f\", cmap=\"coolwarm\")\n",
        "plt.title(\"Correlation of Top 20 Features (existing columns)\", fontsize=14)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "8lQy4mCWLwh4"
      },
      "id": "8lQy4mCWLwh4",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# -----------------------------\n",
        "# Helper function: get grade-level columns safely due to high VIF of features\n",
        "# -----------------------------\n",
        "def get_grade_columns(df, keywords):\n",
        "    \"\"\"\n",
        "    Returns a DataFrame of all columns containing any of the keywords.\n",
        "    If no columns found, returns a dummy column of zeros to avoid errors.\n",
        "    \"\"\"\n",
        "    cols = [c for c in df.columns if any(k in c for k in keywords)]\n",
        "    if not cols:\n",
        "        return pd.DataFrame(0, index=df.index, columns=['dummy'])\n",
        "    return df[cols]\n",
        "\n",
        "# -----------------------------\n",
        "# Create composite features\n",
        "# -----------------------------\n",
        "\"\"\"df['Overall_Test_Score_Avg'] = df[['Avg_Test_Score_Preparatory',\n",
        "                                   'Avg_Test_Score_Lower_Primary',\n",
        "                                   'Avg_Test_Score_Upper_Primary',\n",
        "                                   'Avg_Test_Score_Secondary']].mean(axis=1)\"\"\"\n",
        "\n",
        "df['Overall_Textbook_Access_Composite'] = df[['Textbook_Access_1_4', 'Textbook_Access_5_8',\n",
        "                                      'Textbook_Access_9_10', 'Textbook_Access_11_12']].mean(axis=1)\n",
        "\n",
        "#df['Academic_Growth_Primary_to_Secondary'] = df['Avg_Test_Score_Secondary'] - df['Avg_Test_Score_Lower_Primary']\n",
        "\n",
        "# -----------------------------\n",
        "# Overall engagement averages\n",
        "# -----------------------------\n",
        "# -----------------------------\n",
        "# Create overall averages (explicit columns)\n",
        "# -----------------------------\n",
        "\n",
        "# Attendance columns\n",
        "attendance_cols = [\n",
        "    'Avg_Attendance_Lower_Primary',\n",
        "    'Avg_Attendance_Upper_Primary',\n",
        "    'Avg_Attendance_Secondary',\n",
        "    'Avg_Attendance_Preparatory'\n",
        "]\n",
        "\n",
        "df['Overall_Avg_Attendance'] = df[attendance_cols].mean(axis=1)\n",
        "\n",
        "# Homework columns\n",
        "homework_cols = [\n",
        "    'Avg_HW_Completion_Lower_Primary',\n",
        "    'Avg_HW_Completion_Upper_Primary',\n",
        "    'Avg_HW_Completion_Secondary',\n",
        "    'Avg_HW_Completion_Preparatory'\n",
        "]\n",
        "\n",
        "df['Overall_Avg_Homework'] = df[homework_cols].mean(axis=1)\n",
        "\n",
        "# Participation columns\n",
        "participation_cols = [\n",
        "    'Avg_Participation_Lower_Primary',\n",
        "    'Avg_Participation_Upper_Primary',\n",
        "    'Avg_Participation_Secondary',\n",
        "    'Avg_Participation_Preparatory'\n",
        "]\n",
        "\n",
        "df['Overall_Avg_Participation'] = df[participation_cols].mean(axis=1)\n",
        "\n",
        "# -----------------------------\n",
        "# Composite engagement score (weighted)\n",
        "# -----------------------------\n",
        "# Select engagement columns\n",
        "engagement_cols = ['Overall_Avg_Attendance', 'Overall_Avg_Homework', 'Overall_Avg_Participation']\n",
        "\n",
        "# Apply PCA with 1 component\n",
        "df['Overall_Engagement_Score'] = PCA(n_components=1).fit_transform(df[engagement_cols])\n",
        "\n",
        "# Optional: scale 0‚Äì100\n",
        "df['Overall_Engagement_Score'] = 100 * (df['Overall_Engagement_Score'] - df['Overall_Engagement_Score'].min()) / (\n",
        "    df['Overall_Engagement_Score'].max() - df['Overall_Engagement_Score'].min()\n",
        ")\n",
        "\n",
        "# -----------------------------\n",
        "# Quick overview\n",
        "# -----------------------------\n",
        "print(\"\\nCreated overall averages:\")\n",
        "for col in ['Overall_Avg_Attendance', 'Overall_Avg_Homework','Overall_Textbook_Access_Composite', 'Overall_Avg_Participation', 'Overall_Engagement_Score']:\n",
        "    print(f\"- {col}: {df[col].mean():.2f}\")"
      ],
      "metadata": {
        "id": "sY5FIG5dL1iu"
      },
      "id": "sY5FIG5dL1iu",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# DROP ORIGINAL HIGH-DIMENSION COLUMNS\n",
        "\n",
        "drop_cols = []\n",
        "\n",
        "# Test Scores\n",
        "drop_cols += [c for c in df.columns if c.startswith('Avg_Test_Score_')]\n",
        "\n",
        "# Textbook Access\n",
        "drop_cols += [c for c in df.columns if c.startswith('Textbook_Access_')]\n",
        "\n",
        "# Attendance, Participation, Homework\n",
        "drop_cols += [c for c in df.columns if c.startswith('Avg_Attendance_')]\n",
        "drop_cols += [c for c in df.columns if c.startswith('Avg_Participation_')]\n",
        "drop_cols += [c for c in df.columns if c.startswith('Avg_HW_Completion_')]\n",
        "\n",
        "# Drop safely\n",
        "df = df.drop(columns=drop_cols, errors='ignore')\n",
        "\n",
        "print(f\"Dropped {len(drop_cols)} original aggregated columns.\")"
      ],
      "metadata": {
        "id": "bD5zanXQL6iP"
      },
      "id": "bD5zanXQL6iP",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.info()"
      ],
      "metadata": {
        "id": "tRSl2O6X4KmC"
      },
      "id": "tRSl2O6X4KmC",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ======================================\n",
        "# 1. Imports\n",
        "# ======================================\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.pipeline import Pipeline\n",
        "\n",
        "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
        "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor\n",
        "from xgboost import XGBRegressor\n",
        "from sklearn.preprocessing import PowerTransformer, StandardScaler\n",
        "\n",
        "X = df.drop(columns=[TARGET])\n",
        "y = df[TARGET]"
      ],
      "metadata": {
        "id": "1F4Iq_ZI4Su-"
      },
      "id": "1F4Iq_ZI4Su-",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ==========================================================\n",
        "# COMPLETE REGRESSION PIPELINE WITH BEST MODEL SELECTION\n",
        "# ==========================================================\n",
        "\n",
        "# ======================================\n",
        "# 1. Split Data (Assuming X, y are defined)\n",
        "# ======================================\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X, y, test_size=0.2, random_state=42\n",
        ")\n",
        "\n",
        "# ======================================\n",
        "# 2. Identify Numeric & Categorical Columns\n",
        "# ======================================\n",
        "numeric_features = X.select_dtypes(include=[\"int64\", \"float64\"]).columns\n",
        "categorical_features = X.select_dtypes(exclude=[\"int64\", \"float64\"]).columns\n",
        "\n",
        "# ======================================\n",
        "# 3. Preprocessing\n",
        "# ======================================\n",
        "preprocessor = ColumnTransformer(\n",
        "    transformers=[\n",
        "        (\"num\", StandardScaler(), numeric_features),\n",
        "        (\"cat\", \"passthrough\", categorical_features)\n",
        "    ]\n",
        ")\n",
        "\n",
        "# ======================================\n",
        "# 4. Define Models (Optimized for Speed)\n",
        "# ======================================\n",
        "models = {\n",
        "    \"LinearRegression\": LinearRegression(),\n",
        "\n",
        "    \"XGBoost\": XGBRegressor(\n",
        "        n_estimators=300,\n",
        "        max_depth=5,\n",
        "        learning_rate=0.05,\n",
        "        subsample=0.8,\n",
        "        colsample_bytree=0.8,\n",
        "        objective=\"reg:squarederror\",\n",
        "        random_state=42,\n",
        "        n_jobs=-1\n",
        "    ),\n",
        "\n",
        "    \"RandomForest\": RandomForestRegressor(\n",
        "        n_estimators=200,\n",
        "        max_depth=10,\n",
        "        random_state=42,\n",
        "        n_jobs=-1\n",
        "    ),\n",
        "\n",
        "    \"GradientBoosting\": GradientBoostingRegressor(\n",
        "        n_estimators=200,\n",
        "        learning_rate=0.05,\n",
        "        max_depth=5,\n",
        "        random_state=42\n",
        "    )\n",
        "}\n",
        "\n",
        "# ======================================\n",
        "# 5. Train, Predict, Evaluate\n",
        "# ======================================\n",
        "results = {}\n",
        "pipelines = {}\n",
        "\n",
        "for name, model in models.items():\n",
        "    print(f\"\\n==============================\")\n",
        "    print(f\"Training {name}\")\n",
        "    print(\"==============================\")\n",
        "\n",
        "    pipeline = Pipeline(steps=[\n",
        "        (\"preprocessor\", preprocessor),\n",
        "        (\"model\", model)\n",
        "    ])\n",
        "\n",
        "    pipeline.fit(X_train, y_train)\n",
        "    pipelines[name] = pipeline\n",
        "\n",
        "    # Predictions\n",
        "    y_train_pred = pipeline.predict(X_train)\n",
        "    y_test_pred = pipeline.predict(X_test)\n",
        "\n",
        "    # Metrics\n",
        "    mae = mean_absolute_error(y_test, y_test_pred)\n",
        "    rmse = np.sqrt(mean_squared_error(y_test, y_test_pred))\n",
        "    r2 = r2_score(y_test, y_test_pred)\n",
        "\n",
        "    results[name] = {\"MAE\": mae, \"RMSE\": rmse, \"R2\": r2}\n",
        "\n",
        "    print(f\"Testing Performance:\")\n",
        "    print(f\"MAE  : {mae:.2f}\")\n",
        "    print(f\"RMSE : {rmse:.2f}\")\n",
        "    print(f\"R¬≤   : {r2:.4f}\")\n",
        "\n",
        "    # ======================================\n",
        "    # Feature Importance (Tree Models Only)\n",
        "    # ======================================\n",
        "    if name in [\"XGBoost\", \"RandomForest\", \"GradientBoosting\"]:\n",
        "\n",
        "        feature_names = numeric_features.tolist() + categorical_features.tolist()\n",
        "        importances = pipeline.named_steps[\"model\"].feature_importances_\n",
        "\n",
        "        feature_importance = pd.Series(\n",
        "            importances,\n",
        "            index=feature_names\n",
        "        ).sort_values(ascending=False)\n",
        "\n",
        "        print(\"\\nTop 10 Important Features:\")\n",
        "        print(feature_importance.head(10))\n",
        "\n",
        "        # Plot\n",
        "        plt.figure(figsize=(8, 5))\n",
        "        sns.barplot(\n",
        "            x=feature_importance.head(10).values,\n",
        "            y=feature_importance.head(10).index\n",
        "        )\n",
        "        plt.title(f\"Top 10 Feature Importance - {name}\")\n",
        "        plt.xlabel(\"Importance\")\n",
        "        plt.ylabel(\"Feature\")\n",
        "        plt.show()\n",
        "\n",
        "    # ======================================\n",
        "    # Actual vs Predicted Plot\n",
        "    # ======================================\n",
        "    plt.figure(figsize=(6, 6))\n",
        "    plt.scatter(y_test, y_test_pred, alpha=0.4)\n",
        "    plt.plot(\n",
        "        [y_test.min(), y_test.max()],\n",
        "        [y_test.min(), y_test.max()],\n",
        "        \"r--\"\n",
        "    )\n",
        "    plt.xlabel(\"Actual Total Test Score\")\n",
        "    plt.ylabel(\"Predicted Total Test Score\")\n",
        "    plt.title(f\"Actual vs Predicted - {name}\")\n",
        "    plt.grid()\n",
        "    plt.show()\n",
        "\n",
        "# ======================================\n",
        "# 6. Compare All Models\n",
        "# ======================================\n",
        "comparison_df = pd.DataFrame(results).T\n",
        "\n",
        "print(\"\\n=====================================\")\n",
        "print(\"MODEL COMPARISON\")\n",
        "print(\"=====================================\")\n",
        "print(comparison_df.sort_values(\"R2\", ascending=False))\n",
        "\n",
        "# ======================================\n",
        "# 7. Select Best Model (Based on R¬≤)\n",
        "# ======================================\n",
        "best_model_name = comparison_df[\"R2\"].idxmax()\n",
        "best_pipeline = pipelines[best_model_name]\n",
        "\n",
        "print(\"\\n=====================================\")\n",
        "print(f\"BEST MODEL: {best_model_name}\")\n",
        "print(\"=====================================\")\n",
        "\n",
        "# Training R¬≤\n",
        "y_train_best = best_pipeline.predict(X_train)\n",
        "train_r2 = r2_score(y_train, y_train_best)\n",
        "\n",
        "# Testing R¬≤\n",
        "y_test_best = best_pipeline.predict(X_test)\n",
        "test_r2 = r2_score(y_test, y_test_best)\n",
        "\n",
        "print(f\"Training R¬≤ : {train_r2:.4f}\")\n",
        "print(f\"Testing  R¬≤ : {test_r2:.4f}\")\n",
        "\n",
        "# ======================================\n",
        "#  5-Fold Cross Validation (CV)\n",
        "# ======================================\n",
        "cv_scores = cross_val_score(\n",
        "    best_pipeline,\n",
        "    X_train,\n",
        "    y_train,\n",
        "    cv=5,\n",
        "    scoring=\"r2\",\n",
        "    n_jobs=-1\n",
        ")\n",
        "\n",
        "cv_mean = cv_scores.mean()\n",
        "cv_std = cv_scores.std()\n",
        "\n",
        "print(\"\\n=====================================\")\n",
        "print(\"CROSS VALIDATION (5-FOLD)\")\n",
        "print(\"=====================================\")\n",
        "print(\"CV Scores :\", cv_scores)\n",
        "print(f\"Mean CV R¬≤ : {cv_mean:.4f}\")\n",
        "print(f\"Std CV     : {cv_std:.4f}\")\n",
        "\n",
        "# ======================================\n",
        "# 10. Compare CV vs Test\n",
        "# ======================================\n",
        "difference = abs(test_r2 - cv_mean)\n",
        "\n",
        "print(\"\\n=====================================\")\n",
        "print(\"GENERALIZATION CHECK\")\n",
        "print(\"=====================================\")\n",
        "print(f\"Difference (Test - CV) : {difference:.4f}\")\n",
        "\n",
        "if difference < 0.01:\n",
        "    print(\"‚úÖ Excellent Generalization (Very Low Overfitting)\")\n",
        "elif difference < 0.05:\n",
        "    print(\" Moderate Overfitting\")\n",
        "else:\n",
        "    print(\" High Overfitting Detected\")"
      ],
      "metadata": {
        "id": "ZjoQ_KLl4X4q"
      },
      "id": "ZjoQ_KLl4X4q",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"\\n=====================================\")\n",
        "print(\"MODEL COMPARISON\")\n",
        "print(\"=====================================\")\n",
        "print(comparison_df.sort_values(\"R2\", ascending=False))\n",
        "\n",
        "# ======================================\n",
        "# 7. Select Best Model\n",
        "# ======================================\n",
        "best_model_name = comparison_df[\"R2\"].idxmax()\n",
        "best_pipeline = pipelines[best_model_name]\n",
        "\n",
        "print(\"\\n=====================================\")\n",
        "print(f\"BEST MODEL: {best_model_name}\")\n",
        "print(\"=====================================\")\n",
        "\n",
        "# ======================================\n",
        "# 8. Training & Testing R¬≤\n",
        "# ======================================\n",
        "y_train_best = best_pipeline.predict(X_train)\n",
        "y_test_best = best_pipeline.predict(X_test)\n",
        "\n",
        "train_r2 = r2_score(y_train, y_train_best)\n",
        "test_r2 = r2_score(y_test, y_test_best)\n",
        "\n",
        "print(f\"Training R¬≤ : {train_r2:.4f}\")\n",
        "print(f\"Testing  R¬≤ : {test_r2:.4f}\")\n",
        "\n",
        "# ======================================\n",
        "# 9. 5-Fold Cross Validation (CV)\n",
        "# ======================================\n",
        "cv_scores = cross_val_score(\n",
        "    best_pipeline,\n",
        "    X_train,\n",
        "    y_train,\n",
        "    cv=5,\n",
        "    scoring=\"r2\",\n",
        "    n_jobs=-1\n",
        ")\n",
        "\n",
        "cv_mean = cv_scores.mean()\n",
        "cv_std = cv_scores.std()\n",
        "\n",
        "print(\"\\n=====================================\")\n",
        "print(\"CROSS VALIDATION (5-FOLD)\")\n",
        "print(\"=====================================\")\n",
        "print(\"CV Scores :\", cv_scores)\n",
        "print(f\"Mean CV R¬≤ : {cv_mean:.4f}\")\n",
        "print(f\"Std CV     : {cv_std:.4f}\")\n",
        "\n",
        "# ======================================\n",
        "# 10. Compare CV vs Test\n",
        "# ======================================\n",
        "difference = abs(test_r2 - cv_mean)\n",
        "\n",
        "print(\"\\n=====================================\")\n",
        "print(\"GENERALIZATION CHECK\")\n",
        "print(\"=====================================\")\n",
        "print(f\"Difference (Test - CV) : {difference:.4f}\")\n",
        "\n",
        "if difference < 0.01:\n",
        "    print(\"‚úÖ Excellent Generalization (Very Low Overfitting)\")\n",
        "elif difference < 0.05:\n",
        "    print(\" Moderate Overfitting\")\n",
        "else:\n",
        "    print(\" High Overfitting Detected\")"
      ],
      "metadata": {
        "id": "SSRDb0KsGovz"
      },
      "id": "SSRDb0KsGovz",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ==============================\n",
        "# STUDENT RISK / NOT-RISK PREDICTION PIPELINE\n",
        "# (FIXED THRESHOLD = 50%)\n",
        "# ==============================\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import shap\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
        "from sklearn.metrics import (\n",
        "    classification_report,\n",
        "    confusion_matrix,\n",
        "    roc_auc_score,\n",
        "    roc_curve,\n",
        "    f1_score\n",
        ")\n",
        "from imblearn.over_sampling import SMOTE\n",
        "\n",
        "# -----------------------------\n",
        "# 1Ô∏è‚É£ DEFINE TARGET COLUMN\n",
        "# -----------------------------\n",
        "score_col = 'Overall_Average'\n",
        "\n",
        "# -----------------------------\n",
        "# 2Ô∏è‚É£ CREATE RISK / NOT-RISK TARGET\n",
        "# -----------------------------\n",
        "df['Risk_NotRisk'] = (df[score_col] < 50).astype(int)\n",
        "\n",
        "print(\"\\nClass distribution:\")\n",
        "print(df['Risk_NotRisk'].value_counts())\n",
        "\n",
        "# -----------------------------\n",
        "# 3Ô∏è‚É£ PREPARE FEATURES\n",
        "# -----------------------------\n",
        "X = df.drop(\n",
        "    ['Risk_NotRisk', score_col, 'Total_National_Exam_Score'],\n",
        "    axis=1,\n",
        "    errors='ignore'\n",
        ")\n",
        "y = df['Risk_NotRisk']\n",
        "\n",
        "categorical_cols = X.select_dtypes(include=['object', 'category']).columns\n",
        "X_encoded = pd.get_dummies(X, columns=categorical_cols, drop_first=True)\n",
        "\n",
        "print(f\"\\nFeature shape: {X_encoded.shape}\")\n",
        "print(f\"Target shape: {y.shape}\")\n",
        "\n",
        "# -----------------------------\n",
        "# 4Ô∏è‚É£ TRAIN / TEST SPLIT\n",
        "# -----------------------------\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X_encoded,\n",
        "    y,\n",
        "    test_size=0.2,\n",
        "    random_state=42,\n",
        "    stratify=y\n",
        ")\n",
        "\n",
        "# -----------------------------\n",
        "# 5Ô∏è‚É£ HANDLE CLASS IMBALANCE (SMOTE)\n",
        "# -----------------------------\n",
        "smote = SMOTE(random_state=42)\n",
        "X_train_res, y_train_res = smote.fit_resample(X_train, y_train)\n",
        "\n",
        "print(\"\\nAfter SMOTE:\")\n",
        "print(pd.Series(y_train_res).value_counts())\n",
        "# -----------------------------\n",
        "# 6Ô∏è‚É£ TRAIN MODELS\n",
        "# -----------------------------\n",
        "rf = RandomForestClassifier(\n",
        "    n_estimators=500,\n",
        "    max_depth=10,\n",
        "    random_state=42,\n",
        "    n_jobs=-1\n",
        ")\n",
        "\n",
        "gb = GradientBoostingClassifier(\n",
        "    n_estimators=500,\n",
        "    learning_rate=0.05,\n",
        "    max_depth=5,\n",
        "    random_state=42\n",
        ")\n",
        "\n",
        "rf.fit(X_train_res, y_train_res)\n",
        "gb.fit(X_train_res, y_train_res)\n",
        "\n",
        "# -----------------------------\n",
        "# 7Ô∏è‚É£ EVALUATE BOTH MODELS\n",
        "# -----------------------------\n",
        "FIXED_THRESHOLD = 0.50\n",
        "models = {\n",
        "    \"Random Forest\": rf,\n",
        "    \"Gradient Boosting\": gb\n",
        "}\n",
        "\n",
        "results = {}\n",
        "\n",
        "print(\"\\n\" + \"=\" * 70)\n",
        "print(\"CLASSIFICATION REPORTS (FIXED THRESHOLD = 0.50)\")\n",
        "print(\"=\" * 70)\n",
        "\n",
        "for name, model in models.items():\n",
        "    probs = model.predict_proba(X_test)[:, 1]\n",
        "    preds = (probs >= FIXED_THRESHOLD).astype(int)\n",
        "\n",
        "    roc_auc = roc_auc_score(y_test, probs)\n",
        "    f1 = f1_score(y_test, preds, pos_label=1)\n",
        "\n",
        "    results[name] = {\n",
        "        \"model\": model,\n",
        "        \"roc_auc\": roc_auc,\n",
        "        \"f1\": f1\n",
        "    }\n",
        "\n",
        "    print(f\"\\n--- {name} ---\")\n",
        "    print(f\"ROC-AUC : {roc_auc:.3f}\")\n",
        "    print(f\"F1-Score: {f1:.3f}\")\n",
        "    print(\"\\nClassification Report:\")\n",
        "    print(classification_report(y_test, preds))\n",
        "\n",
        "# -----------------------------\n",
        "# 8Ô∏è‚É£ SELECT BEST MODEL (ROC-AUC)\n",
        "# -----------------------------\n",
        "best_model_name = max(results, key=lambda x: results[x][\"roc_auc\"])\n",
        "best_model = results[best_model_name][\"model\"]\n",
        "\n",
        "print(\"\\n\" + \"=\" * 70)\n",
        "print(\"BEST MODEL SELECTED:\", best_model_name)\n",
        "print(\"ROC-AUC:\", results[best_model_name][\"roc_auc\"])\n",
        "print(\"F1-Score:\", results[best_model_name][\"f1\"])\n",
        "print(\"=\" * 70)\n",
        "\n",
        "# -----------------------------\n",
        "# 9Ô∏è‚É£ PREDICT WITH BEST MODEL\n",
        "# -----------------------------\n",
        "y_probs = best_model.predict_proba(X_test)[:, 1]\n",
        "y_pred = (y_probs >= FIXED_THRESHOLD).astype(int)\n",
        "\n",
        "cm = confusion_matrix(y_test, y_pred)\n",
        "roc_auc = roc_auc_score(y_test, y_probs)\n",
        "\n",
        "# -----------------------------\n",
        "# üîü VISUALIZATIONS (BEST MODEL)\n",
        "# -----------------------------\n",
        "fig, axes = plt.subplots(2, 2, figsize=(14, 12))\n",
        "\n",
        "# Confusion Matrix\n",
        "sns.heatmap(\n",
        "    cm,\n",
        "    annot=True,\n",
        "    fmt='d',\n",
        "    cmap='Blues',\n",
        "    ax=axes[0, 0],\n",
        "    xticklabels=['Predicted NotRisk', 'Predicted Risk'],\n",
        "    yticklabels=['Actual NotRisk', 'Actual Risk']\n",
        ")\n",
        "axes[0, 0].set_title(f'Confusion Matrix ({best_model_name})')\n",
        "\n",
        "# ROC Curve\n",
        "fpr, tpr, thresholds = roc_curve(y_test, y_probs)\n",
        "axes[0, 1].plot(fpr, tpr, label=f'AUC = {roc_auc:.3f}')\n",
        "axes[0, 1].plot([0, 1], [0, 1], '--')\n",
        "axes[0, 1].axvline(0.5, linestyle='--')\n",
        "axes[0, 1].set_title('ROC Curve')\n",
        "axes[0, 1].legend()\n",
        "axes[0, 1].grid(alpha=0.3)\n",
        "\n",
        "# Feature Importance\n",
        "feature_importance = pd.Series(\n",
        "    best_model.feature_importances_,\n",
        "    index=X_encoded.columns\n",
        ").sort_values(ascending=False)\n",
        "\n",
        "top_features = feature_importance.head(10)\n",
        "\n",
        "axes[1, 0].barh(top_features.index, top_features.values)\n",
        "axes[1, 0].invert_yaxis()\n",
        "axes[1, 0].set_title('Top 10 Feature Importances')\n",
        "\n",
        "# Probability Distribution\n",
        "axes[1, 1].hist(y_probs[y_test == 0], bins=30, alpha=0.6, label='NotRisk')\n",
        "axes[1, 1].hist(y_probs[y_test == 1], bins=30, alpha=0.6, label='Risk')\n",
        "axes[1, 1].axvline(0.50, linestyle='--', label='Threshold 0.50')\n",
        "axes[1, 1].set_title('Predicted Probability Distribution')\n",
        "axes[1, 1].legend()\n",
        "\n",
        "plt.suptitle(\n",
        "    f'Student Risk Prediction ‚Äì Best Model: {best_model_name}',\n",
        "    fontsize=14,\n",
        "    fontweight='bold'\n",
        ")\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "# -----------------------------\n",
        "# üîü PRINT TOP FEATURES\n",
        "# -----------------------------\n",
        "print(\"\\nTOP 10 FEATURES (BEST MODEL)\")\n",
        "print(\"=\" * 60)\n",
        "\n",
        "for i, (feature, importance) in enumerate(top_features.items(), 1):\n",
        "    print(f\"{i:2d}. {feature:<30} {importance:.4f}\")\n",
        "\n",
        "# =====================================================\n",
        "# 1Ô∏è‚É£1Ô∏è‚É£ SHAP EXPLAINABILITY (BEST MODEL ONLY)\n",
        "# =====================================================\n",
        "print(\"\\n\" + \"=\" * 70)\n",
        "print(\"SHAP EXPLANATION (GLOBAL & LOCAL)\")\n",
        "print(\"=\" * 70)\n",
        "\n",
        "# TreeExplainer for tree-based models\n",
        "explainer = shap.TreeExplainer(best_model)\n",
        "\n",
        "# Use a sample for speed & stability\n",
        "X_shap = X_test.sample(min(500, len(X_test)), random_state=42)\n",
        "\n",
        "shap_values = explainer.shap_values(X_shap)\n",
        "\n",
        "# ---- Global SHAP Summary (Bar)\n",
        "shap.summary_plot(\n",
        "    shap_values,\n",
        "    X_shap,\n",
        "    plot_type=\"bar\",\n",
        "    show=False\n",
        ")\n",
        "plt.title(\"Global Feature Importance (SHAP)\")\n",
        "plt.show()\n",
        "\n",
        "# ---- Global SHAP Summary (Beeswarm)\n",
        "shap.summary_plot(\n",
        "    shap_values,\n",
        "    X_shap,\n",
        "    show=False\n",
        ")\n",
        "plt.title(\"SHAP Beeswarm Plot\")\n",
        "plt.show()\n",
        "\n",
        "# -----------------------------\n",
        "# LOCAL SHAP EXPLANATION (WORKING)\n",
        "# -----------------------------\n",
        "\n",
        "sample_row = X_shap.iloc[[0]]   # keep DataFrame\n",
        "\n",
        "shap_values_single = explainer(sample_row)\n",
        "\n",
        "shap.plots.waterfall(\n",
        "    shap_values_single[0],\n",
        "    max_display=10\n",
        ")\n",
        "\n",
        "print(\"\\nPIPELINE COMPLETE ‚úî (MODEL + SHAP)\")"
      ],
      "metadata": {
        "id": "cU-ksb9_4egi"
      },
      "id": "cU-ksb9_4egi",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".ipynb",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.0"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}