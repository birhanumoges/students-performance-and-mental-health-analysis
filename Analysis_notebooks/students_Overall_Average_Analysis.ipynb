{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UtAVF1N1MTSz"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns"
      ],
      "id": "UtAVF1N1MTSz"
    },
    {
      "cell_type": "code",
      "source": [
        "# Load CSV file\n",
        "df = pd.read_csv(r\"C:/Users/DELL/Downloads/ethiopian_students_dataset.csv\")\n",
        "\n",
        "# View first 5 rows\n",
        "print(df.head())\n",
        "\n",
        "# Access a column\n",
        "print(df.columns)"
      ],
      "metadata": {
        "id": "x8yIkBIOMhVc"
      },
      "id": "x8yIkBIOMhVc",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 1. Check the basic structure\n",
        "print(\"=\"*60)\n",
        "print(\"DATA STRUCTURE ANALYSIS\")\n",
        "print(\"=\"*60)\n",
        "\n",
        "print(f\"Dataset Shape: {df.shape}\")\n",
        "print(f\"Number of students: {df.shape[0]}\")\n",
        "print(f\"Number of columns: {df.shape[1]}\")\n",
        "print(f\"Memory usage: {df.memory_usage(deep=True).sum() / 1024**2:.2f} MB\")\n",
        "\n",
        "# 2. View column categories\n",
        "print(\"\\n\" + \"=\"*60)\n",
        "print(\"COLUMN CATEGORIES\")\n",
        "print(\"=\"*60)\n",
        "\n",
        "# Group columns by type\n",
        "test_score_cols = [col for col in df.columns if 'Test_Score' in col]\n",
        "attendance_cols = [col for col in df.columns if 'Attendance' in col]\n",
        "homework_cols = [col for col in df.columns if 'Homework' in col]\n",
        "participation_cols = [col for col in df.columns if 'Participation' in col]\n",
        "textbook_cols = [col for col in df.columns if 'Textbook' in col]\n",
        "\n",
        "print(f\"Test Score columns: {len(test_score_cols)}\")\n",
        "print(f\"Attendance columns: {len(attendance_cols)}\")\n",
        "print(f\"Homework columns: {len(homework_cols)}\")\n",
        "print(f\"Participation columns: {len(participation_cols)}\")\n",
        "print(f\"Textbook columns: {len(textbook_cols)}\")\n",
        "\n",
        "# 3. Check subject coverage by grade\n",
        "print(\"\\n\" + \"=\"*60)\n",
        "print(\"SUBJECT COVERAGE BY GRADE\")\n",
        "print(\"=\"*60)\n",
        "\n",
        "for grade in range(1, 13):\n",
        "    grade_test_cols = [col for col in test_score_cols if f'Grade_{grade}_' in col]\n",
        "    if grade_test_cols:\n",
        "        subjects = list(set([col.split(f'Grade_{grade}_')[1].split('_Test')[0]\n",
        "                           for col in grade_test_cols]))\n",
        "        print(f\"Grade {grade}: {len(grade_test_cols)} subjects - {subjects}\")\n",
        "\n",
        "all_categorized_cols = set(test_score_cols + attendance_cols + homework_cols + participation_cols + textbook_cols)\n",
        "remaining_cols = [col for col in df.columns if col not in all_categorized_cols]\n",
        "\n",
        "print(\"\\n\" + \"=\"*60)\n",
        "print(\"REMAINING COLUMNS\")\n",
        "print(\"=\"*60)\n",
        "print(f\"Number of remaining columns: {len(remaining_cols)}\")\n",
        "print(\"Remaining columns (first 20):\\n\", remaining_cols[:20])\n",
        "print(\"Remaining columns (last 20):\\n\", remaining_cols[-20:])"
      ],
      "metadata": {
        "id": "nKzZezxiMlm2"
      },
      "id": "nKzZezxiMlm2",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Check for nulls per column\n",
        "print(\"==============================\")\n",
        "print(\"CHECKING FOR MISSING DATA\")\n",
        "print(\"==============================\")\n",
        "print(df.isnull().sum())\n",
        "\n",
        "# Check the percentage of missing data\n",
        "print(\"================================\")\n",
        "print(\"Percentage of missing data:\")\n",
        "print(\"--------------------------------\")\n",
        "print(df.isnull().mean() * 100)"
      ],
      "metadata": {
        "id": "cESECZqVMxsw"
      },
      "id": "cESECZqVMxsw",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "# 1. Get the value counts of dtypes\n",
        "dtype_counts = df.dtypes.value_counts().reset_index()\n",
        "dtype_counts.columns = ['Data Type', 'Count']\n",
        "\n",
        "# 2. Plotting with the fix\n",
        "plt.figure(figsize=(10, 6))\n",
        "\n",
        "# Fix: Assign 'Data Type' to hue and set legend=False\n",
        "sns.barplot(\n",
        "    data=dtype_counts,\n",
        "    x='Data Type',\n",
        "    y='Count',\n",
        "    hue='Data Type',\n",
        "    palette='viridis',\n",
        "    legend=False\n",
        ")\n",
        "\n",
        "plt.title('Distribution of Data Types in Student Dataset', fontsize=14)\n",
        "plt.ylabel('Number of Columns')\n",
        "plt.xlabel('Data Type')\n",
        "\n",
        "# 3. Add labels on top of bars\n",
        "for i, count in enumerate(dtype_counts['Count']):\n",
        "    plt.text(i, count + 5, str(count), ha='center', fontweight='bold')\n",
        "\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "WNQSlNVoM2qq"
      },
      "id": "WNQSlNVoM2qq",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Drop ID (never use in ML)\n",
        "df = df.drop(columns=['Student_ID'], errors='ignore')\n",
        "\n",
        "#  Encode Field_Choice (VERY IMPORTANT)\n",
        "df['Field_Choice'] = df['Field_Choice'].map({\n",
        "    'Social': 0,\n",
        "    'Natural': 1\n",
        "})\n",
        "\n",
        "# HANDLE CAREER_INTEREST\n",
        "# Fill missing with \"Unknown\"\n",
        "df['Career_Interest'] = df['Career_Interest'].fillna('Unknown')"
      ],
      "metadata": {
        "id": "sTn8xQmkM92M"
      },
      "id": "sTn8xQmkM92M",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# AGGREGATE GRADES INTO EDUCATION STAGES\n",
        "# Define grade groups\n",
        "lower_primary = ['Grade_1', 'Grade_2', 'Grade_3', 'Grade_4']\n",
        "upper_primary = ['Grade_5', 'Grade_6', 'Grade_7', 'Grade_8']\n",
        "secondary = ['Grade_9', 'Grade_10']\n",
        "preparatory = ['Grade_11', 'Grade_12']\n",
        "\n",
        "# Helper function to compute average test score\n",
        "def stage_average(df, grades):\n",
        "    cols = []\n",
        "    for g in grades:\n",
        "        cols += [c for c in df.columns if c.startswith(g) and c.endswith('_Test_Score')]\n",
        "    return df[cols].mean(axis=1)\n",
        "\n",
        "# Create aggregated academic scores\n",
        "df['Avg_Score_Lower_Primary'] = stage_average(df, lower_primary)\n",
        "df['Avg_Score_Upper_Primary'] = stage_average(df, upper_primary)\n",
        "df['Avg_Score_Secondary'] = stage_average(df, secondary)\n",
        "df['Avg_Score_Preparatory'] = stage_average(df, preparatory)\n",
        "\n",
        "# Select only the newly created columns and view the first 5 rows\n",
        "textbook_summary_cols = [\n",
        "    'Avg_Score_Lower_Primary',\n",
        "    'Avg_Score_Upper_Primary',\n",
        "    'Avg_Score_Secondary',\n",
        "    'Avg_Score_Preparatory'\n",
        "]\n",
        "\n",
        "print(\"Aggeregated average Scores(1-4,5-8,9&10 and 11&12) per Education Level (Head):\")\n",
        "print(df[textbook_summary_cols].head())\n",
        "\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Visualizing the distribution of the four new columns\n",
        "plt.figure(figsize=(10, 6))\n",
        "sns.boxplot(data=df[textbook_summary_cols])\n",
        "plt.title('Aggeregated average Distribution by Education Level')\n",
        "plt.ylabel('Aggeregated average score')\n",
        "plt.xticks(rotation=15)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "rYFqsO8oNC_G"
      },
      "id": "rYFqsO8oNC_G",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# CREATE ENGAGEMENT SCORES\n",
        "# Helper function for engagement\n",
        "def engagement_score(df, grades):\n",
        "    attendance = []\n",
        "    homework = []\n",
        "    participation = []\n",
        "\n",
        "    for g in grades:\n",
        "        attendance += [c for c in df.columns if c.startswith(g) and 'Attendance' in c]\n",
        "        homework += [c for c in df.columns if c.startswith(g) and 'Homework' in c]\n",
        "        participation += [c for c in df.columns if c.startswith(g) and 'Participation' in c]\n",
        "\n",
        "    return df[attendance + homework + participation].mean(axis=1)\n",
        "\n",
        "# Create engagement features\n",
        "df['Engagement_1_4'] = engagement_score(df, lower_primary)\n",
        "df['Engagement_5_8'] = engagement_score(df, upper_primary)\n",
        "df['Engagement_9_10'] = engagement_score(df, secondary)\n",
        "df['Engagement_11_12'] = engagement_score(df, preparatory)\n",
        "\n",
        "# -------------------------------\n",
        "# Combine all Engagement scores into one overall column\n",
        "# -------------------------------\n",
        "engagement_cols = [\n",
        "    'Engagement_1_4',\n",
        "    'Engagement_5_8',\n",
        "    'Engagement_9_10',\n",
        "    'Engagement_11_12'\n",
        "]\n",
        "\"\"\"\n",
        "# Create overall engagement column\n",
        "df['Engagement_All'] = df[engagement_cols].mean(axis=1)\n",
        "\n",
        "# Check the first 5 rows\n",
        "print(\"Overall Engagement Scores (Head):\")\n",
        "print(df[['Engagement_All']].head())\n",
        "\n",
        "# Optional: Visualize the overall engagement\n",
        "plt.figure(figsize=(8, 5))\n",
        "sns.histplot(df['Engagement_All'], kde=True, bins=20)\n",
        "plt.title('Overall Engagement Score Distribution')\n",
        "plt.xlabel('Engagement Score (0 to 1)')\n",
        "plt.ylabel('Count')\n",
        "plt.show()\n",
        "\"\"\"\n",
        "print(\"Engagement(attendance,homework,participation) Scores per Education Level (Head):\")\n",
        "print(df[engagement_cols].head())\n",
        "\n",
        "# Visualizing the distribution of the four new columns\n",
        "plt.figure(figsize=(10, 6))\n",
        "sns.boxplot(data=df[engagement_cols])\n",
        "plt.title('Engagement(attendance,homework,participation) Distribution by Education Level')\n",
        "plt.ylabel('Average of enggegment')\n",
        "plt.xticks(rotation=15)\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "0FPf1mGvNJ7g"
      },
      "id": "0FPf1mGvNJ7g",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "# --------------------------------------------------\n",
        "# 1Ô∏è‚É£ Pandas future-proof setting\n",
        "# --------------------------------------------------\n",
        "pd.set_option('future.no_silent_downcasting', True)\n",
        "\n",
        "# --------------------------------------------------\n",
        "# 2Ô∏è‚É£ Convert Yes/No ‚Üí 1/0 SAFELY\n",
        "# --------------------------------------------------\n",
        "textbook_cols = [c for c in df.columns if 'Textbook' in c]\n",
        "\n",
        "for col in textbook_cols:\n",
        "    df[col] = (\n",
        "        df[col]\n",
        "        .replace({'Yes': 1, 'No': 0})\n",
        "        .infer_objects(copy=False)\n",
        "    )\n",
        "\n",
        "# --------------------------------------------------\n",
        "# 3Ô∏è‚É£ Textbook access function\n",
        "# --------------------------------------------------\n",
        "def textbook_access(df, grade_prefixes):\n",
        "    cols = []\n",
        "    for g in grade_prefixes:\n",
        "        cols.extend([c for c in df.columns if c.startswith(g) and 'Textbook' in c])\n",
        "    return df[cols].mean(axis=1) if len(cols) > 0 else pd.Series(0, index=df.index)\n",
        "\n",
        "# --------------------------------------------------\n",
        "# 4Ô∏è‚É£ Create summary columns (NO fragmentation)\n",
        "# --------------------------------------------------\n",
        "new_cols_df = pd.DataFrame({\n",
        "    'Textbook_Access_1_4': textbook_access(df, lower_primary),\n",
        "    'Textbook_Access_5_8': textbook_access(df, upper_primary),\n",
        "    'Textbook_Access_9_10': textbook_access(df, secondary),\n",
        "    'Textbook_Access_11_12': textbook_access(df, preparatory)\n",
        "})\n",
        "\n",
        "df = pd.concat([df, new_cols_df], axis=1)\n",
        "\n",
        "# --------------------------------------------------\n",
        "# 5Ô∏è‚É£ REMOVE duplicate columns (CRITICAL FIX)\n",
        "# --------------------------------------------------\n",
        "df = df.loc[:, ~df.columns.duplicated()]\n",
        "\n",
        "# --------------------------------------------------\n",
        "# 6Ô∏è‚É£ Select valid summary columns SAFELY\n",
        "# --------------------------------------------------\n",
        "textbook_summary_cols = [\n",
        "    c for c in new_cols_df.columns\n",
        "    if c in df.columns and df[c].notna().any()\n",
        "]\n",
        "\n",
        "print(df[textbook_summary_cols].head().to_string(index=False))\n",
        "\n",
        "# --------------------------------------------------\n",
        "# 7Ô∏è‚É£ Visualization (NO warnings, NO errors)\n",
        "# --------------------------------------------------\n",
        "plt.figure(figsize=(10, 6))\n",
        "sns.boxplot(data=df[textbook_summary_cols])\n",
        "plt.title('Textbook Access Distribution by Education Level', fontsize=14, fontweight='bold')\n",
        "plt.ylabel('Access Score (0 to 1)')\n",
        "plt.xticks(rotation=15)\n",
        "plt.grid(alpha=0.3)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "BOSDpTAqNRAE"
      },
      "id": "BOSDpTAqNRAE",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# HANDLE TRACK-BASED NATIONAL EXAMS (CRITICAL PART)\n",
        "# Social Science track exam score\n",
        "social_subjects = [\n",
        "    'National_Exam_History',\n",
        "    'National_Exam_Geography',\n",
        "    'National_Exam_Economics',\n",
        "    'National_Exam_Math_Social'\n",
        "]\n",
        "\n",
        "natural_subjects = [\n",
        "    'National_Exam_Biology',\n",
        "    'National_Exam_Chemistry',\n",
        "    'National_Exam_Physics',\n",
        "    'National_Exam_Math_Natural'\n",
        "]\n",
        "\n",
        "df['Social_Track_Subject_Avg'] = df[social_subjects].mean(axis=1)\n",
        "df['Natural_Track_Subject_Avg'] = df[natural_subjects].mean(axis=1)\n",
        "\n",
        "\n",
        "df['Track_Subject_Average'] = np.where(\n",
        "    df['Field_Choice'] == 0,\n",
        "    df['Social_Track_Subject_Avg'],\n",
        "    df['Natural_Track_Subject_Avg']\n",
        ")\n",
        "\n",
        "common_subjects = [\n",
        "    'National_Exam_Aptitude',\n",
        "    'National_Exam_English',\n",
        "    'National_Exam_Civics_and_Ethical_Education'\n",
        "]\n",
        "\n",
        "df['Common_Exam_Average'] = df[common_subjects].mean(axis=1)\n",
        "\n",
        "df['Track_Exam_Average'] = (\n",
        "    df['Common_Exam_Average'] + df['Track_Subject_Average']\n",
        ") / 2\n",
        "\n",
        "# --- VISUALIZATION ---\n",
        "\n",
        "# Set style\n",
        "sns.set_theme(style=\"whitegrid\")\n",
        "fig, axes = plt.subplots(1, 2, figsize=(16, 6))\n",
        "\n",
        "# Visualization 1: Comparison of Common vs. Track Performance\n",
        "sns.boxplot(data=df[['Common_Exam_Average', 'Track_Subject_Average', 'Track_Exam_Average']],\n",
        "            ax=axes[0], palette=\"Set2\")\n",
        "axes[0].set_title('Distribution of Aggregate Exam Scores')\n",
        "axes[0].set_ylabel('Score (0-100)')\n",
        "\n",
        "# Visualization 2: Final Performance by Field Choice (Density)\n",
        "for choice, label in [(0, 'Social Science'), (1, 'Natural Science')]:\n",
        "    subset = df[df['Field_Choice'] == choice]\n",
        "    sns.kdeplot(subset['Track_Exam_Average'], ax=axes[1], label=label, fill=True)\n",
        "\n",
        "axes[1].set_title('Track Exam Average: Social vs. Natural')\n",
        "axes[1].set_xlabel('Score')\n",
        "axes[1].legend()\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "# 4. Show the Head (FIXED)\n",
        "exam_cols = [\n",
        "    'Social_Track_Subject_Avg',\n",
        "    'Natural_Track_Subject_Avg',\n",
        "    'Track_Subject_Average',\n",
        "    'Common_Exam_Average',\n",
        "    'Track_Exam_Average'\n",
        "]\n",
        "\n",
        "print(\"New Aggregated National Exam Features:\")\n",
        "print(df[exam_cols].head())"
      ],
      "metadata": {
        "id": "CkY_p3RnNYqw"
      },
      "id": "CkY_p3RnNYqw",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# DROP ORIGINAL HIGH-DIMENSION COLUMNS\n",
        "drop_cols = [c for c in df.columns if c.startswith('Grade_')]\n",
        "drop_cols += [c for c in df.columns if c.startswith('National_Exam_')]\n",
        "\n",
        "df = df.drop(columns=drop_cols)\n",
        "# -------------------------------\n",
        "# 0Ô∏è‚É£ Drop leaking exam average columns\n",
        "# -------------------------------\n",
        "leak_cols = [\n",
        "    'Social_Track_Subject_Avg',\n",
        "    'Natural_Track_Subject_Avg',\n",
        "    'Track_Exam_Average',\n",
        "    'Track_Subject_Average',\n",
        "    'Common_Exam_Average',\n",
        "    'Avg_Score_Secondary',\n",
        "    'Avg_Score_Preparatory',\n",
        "    'Avg_Score_Lower_Primary',\n",
        "    'Avg_Score_Upper_Primary',\n",
        "    'School_ID', 'Total_Test_Score','\"Total_National_Exam_Score\",']\n",
        "\n",
        "df = df.drop(columns=[c for c in leak_cols if c in df.columns])\n",
        "\n",
        "# fix null value\n",
        "df['Health_Issue'] = df['Health_Issue'].fillna('No Issue')\n",
        "df['Father_Education'] = df['Father_Education'].fillna('Unknown')\n",
        "df['Mother_Education'] = df['Mother_Education'].fillna('Unknown')\n",
        "\n",
        "# FINAL CHECK\n",
        "print(df.shape)\n",
        "print(df.head())\n",
        "print(\"all columns:\",df.columns)"
      ],
      "metadata": {
        "id": "RhyHXEjrU5Sc"
      },
      "id": "RhyHXEjrU5Sc",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "TARGET = 'Overall_Average'\n",
        "\n",
        "# Select numeric columns only\n",
        "num_cols = df.select_dtypes(include=['int64', 'float64']).columns\n",
        "\n",
        "# Compute correlations with target\n",
        "corr_numeric = (\n",
        "    df[num_cols]\n",
        "    .corr()[TARGET]\n",
        "    .drop(TARGET)\n",
        "    .sort_values(key=abs, ascending=False)\n",
        ")\n",
        "\n",
        "print(\"üìä Numeric Feature Correlation with Target:\")\n",
        "print(corr_numeric)\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "plt.figure(figsize=(10, 8))\n",
        "\n",
        "sns.barplot(\n",
        "    x=corr_numeric.values,\n",
        "    y=corr_numeric.index,\n",
        "    hue=corr_numeric.index,\n",
        "    palette='coolwarm',\n",
        "    legend=False\n",
        ")\n",
        "\n",
        "plt.axvline(0, color='black', linewidth=1)\n",
        "plt.title('Correlation with Total_National_Exam_Score')\n",
        "plt.xlabel('Pearson Correlation')\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "qWv5UHCQVAwg"
      },
      "id": "qWv5UHCQVAwg",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cat_cols = df.select_dtypes(include='object').columns.drop(TARGET, errors='ignore')\n",
        "\n",
        "cat_corr = {}\n",
        "\n",
        "for col in cat_cols:\n",
        "    means = df.groupby(col)[TARGET].mean()\n",
        "    encoded = df[col].map(means)\n",
        "    cat_corr[col] = encoded.corr(df[TARGET])\n",
        "\n",
        "cat_corr = (\n",
        "    pd.Series(cat_corr)\n",
        "    .sort_values(key=abs, ascending=False)\n",
        ")\n",
        "\n",
        "print(\"üìä Categorical Feature Association with Target:\")\n",
        "print(cat_corr)"
      ],
      "metadata": {
        "id": "MDVdDo95VLeZ"
      },
      "id": "MDVdDo95VLeZ",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".ipynb",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.0"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}