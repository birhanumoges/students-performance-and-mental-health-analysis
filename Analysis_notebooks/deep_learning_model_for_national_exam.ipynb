{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "93XWF5RMIEej"
      },
      "source": [
        "# Deep Learning model for national exam analysis\n",
        "\n",
        "This notebook analyzes student performance.\n",
        "\n",
        "**Author:** Birhanu Moges\n"
      ],
      "id": "93XWF5RMIEej"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KgPz5R9sIEek"
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt"
      ],
      "execution_count": null,
      "outputs": [],
      "id": "KgPz5R9sIEek"
    },
    {
      "cell_type": "code",
      "source": [
        "# Load CSV file\n",
        "df = pd.read_csv(r\"C:/Users/DELL/project/ethiopian_students_dataset.csv\")\n",
        "\n",
        "# View first 5 rows\n",
        "print(df.head())\n",
        "\n",
        "# Access a column\n",
        "print(df.columns)"
      ],
      "metadata": {
        "id": "e6tvf-EGItFs"
      },
      "id": "e6tvf-EGItFs",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"=\"*60)\n",
        "print(\"üìä DATASET OVERVIEW\")\n",
        "print(\"=\"*60)\n",
        "print(\"Shape:\", df.shape)\n",
        "print(\"\\nData Types & Missing Values:\")\n",
        "df.info()\n",
        "\n",
        "print(\"\\n\" + \"=\"*60)\n",
        "print(\"üìà DESCRIPTIVE STATISTICS (NUMERIC)\")\n",
        "print(\"=\"*60)\n",
        "display(df.describe().T)"
      ],
      "metadata": {
        "id": "csS1VQI8JhsK"
      },
      "id": "csS1VQI8JhsK",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 1. Get the value counts of dtypes\n",
        "dtype_counts = df.dtypes.value_counts().reset_index()\n",
        "dtype_counts.columns = ['Data Type', 'Count']\n",
        "\n",
        "# 2. Plotting with the fix\n",
        "plt.figure(figsize=(10, 6))\n",
        "\n",
        "# Fix: Assign 'Data Type' to hue and set legend=False\n",
        "sns.barplot(\n",
        "    data=dtype_counts,\n",
        "    x='Data Type',\n",
        "    y='Count',\n",
        "    hue='Data Type',\n",
        "    palette='viridis',\n",
        "    legend=False\n",
        ")\n",
        "\n",
        "plt.title('Distribution of Data Types in Student Dataset', fontsize=14)\n",
        "plt.ylabel('Number of Columns')\n",
        "plt.xlabel('Data Type')\n",
        "\n",
        "# 3. Add labels on top of bars\n",
        "for i, count in enumerate(dtype_counts['Count']):\n",
        "    plt.text(i, count + 5, str(count), ha='center', fontweight='bold')\n",
        "\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "gTSBhvq7I1pY"
      },
      "id": "gTSBhvq7I1pY",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ================================\n",
        "# 1Ô∏è‚É£ INITIAL CLEANING & ENCODING\n",
        "# ================================\n",
        "# Drop Student_ID (never used in ML)\n",
        "df = df.drop(columns=['Student_ID'], errors='ignore')\n",
        "\n",
        "# Encode Field_Choice (Social=0, Natural=1)\n",
        "df['Field_Choice'] = df['Field_Choice'].map({'Social': 0, 'Natural': 1})\n",
        "\n",
        "# Fill missing Career_Interest with \"Unknown\"\n",
        "df['Career_Interest'] = df['Career_Interest'].fillna('Unknown')\n",
        "\n",
        "\n",
        "# ================================\n",
        "# 2Ô∏è‚É£ DEFINE EDUCATION STAGES\n",
        "# ================================\n",
        "lower_primary = ['Grade_1', 'Grade_2', 'Grade_3', 'Grade_4']\n",
        "upper_primary = ['Grade_5', 'Grade_6', 'Grade_7', 'Grade_8']\n",
        "secondary     = ['Grade_9', 'Grade_10']\n",
        "preparatory   = ['Grade_11', 'Grade_12']\n",
        "\n",
        "stages = {\n",
        "    'Lower_Primary': lower_primary,\n",
        "    'Upper_Primary': upper_primary,\n",
        "    'Secondary': secondary,\n",
        "    'Preparatory': preparatory\n",
        "}\n",
        "\n",
        "\n",
        "# ================================\n",
        "# 3Ô∏è‚É£ HELPER FUNCTION TO AGGREGATE GRADES\n",
        "# ================================\n",
        "def stage_average(df, grades, metric_keywords):\n",
        "    \"\"\"\n",
        "    Compute average across all columns for a given stage and metric keywords.\n",
        "    Returns the average series and list of original columns used.\n",
        "    \"\"\"\n",
        "    cols = []\n",
        "    for g in grades:\n",
        "        for keyword in metric_keywords:\n",
        "            cols += [c for c in df.columns if c.startswith(g) and keyword.lower() in c.lower()]\n",
        "    cols = list(set(cols))\n",
        "    return df[cols].mean(axis=1), cols\n",
        "\n",
        "\n",
        "# ================================\n",
        "# 4Ô∏è‚É£ AGGREGATE TEST SCORE, ATTENDANCE, HW, PARTICIPATION\n",
        "# ================================\n",
        "metrics_dict = {\n",
        "    'Test_Score': ['Test_Score'],\n",
        "    'Attendance': ['Attendance'],\n",
        "    'HW_Completion': ['Homework_Completion'],\n",
        "    'Participation': ['Participation']\n",
        "}\n",
        "\n",
        "cols_to_drop = []\n",
        "\n",
        "for metric_name, keywords in metrics_dict.items():\n",
        "    for stage_name, grades in stages.items():\n",
        "        col_name = f'Avg_{metric_name}_{stage_name}'\n",
        "        df[col_name], original_cols = stage_average(df, grades, keywords)\n",
        "        cols_to_drop += original_cols\n",
        "\n",
        "# Drop original grade-level columns\n",
        "df.drop(columns=list(set(cols_to_drop)), inplace=True)\n",
        "\n",
        "# Columns list for display\n",
        "aggregated_cols = [f'Avg_{m}_{s}' for m in metrics_dict.keys() for s in stages.keys()]\n",
        "print(\"Aggregated averages per Education Stage (head):\")\n",
        "print(df[aggregated_cols].head())\n",
        "\n",
        "\n",
        "# ================================\n",
        "# 5Ô∏è‚É£ AGGREGATE TEXTBOOK ACCESS\n",
        "# ================================\n",
        "# Convert Yes/No ‚Üí 1/0 safely\n",
        "textbook_cols = [c for c in df.columns if 'Textbook' in c]\n",
        "for col in textbook_cols:\n",
        "    df[col] = df[col].replace({'Yes': 1, 'No': 0}).infer_objects(copy=False)\n",
        "\n",
        "# Helper function for textbook access per stage\n",
        "def textbook_access(df, grade_prefixes):\n",
        "    cols = []\n",
        "    for g in grade_prefixes:\n",
        "        cols.extend([c for c in df.columns if c.startswith(g) and 'Textbook' in c])\n",
        "    return df[cols].mean(axis=1) if len(cols) > 0 else pd.Series(0, index=df.index)\n",
        "\n",
        "# Create aggregated textbook access per stage\n",
        "new_cols_df = pd.DataFrame({\n",
        "    'Textbook_Access_1_4': textbook_access(df, lower_primary),\n",
        "    'Textbook_Access_5_8': textbook_access(df, upper_primary),\n",
        "    'Textbook_Access_9_10': textbook_access(df, secondary),\n",
        "    'Textbook_Access_11_12': textbook_access(df, preparatory)\n",
        "})\n",
        "\n",
        "df = pd.concat([df, new_cols_df], axis=1)\n",
        "df = df.loc[:, ~df.columns.duplicated()]  # remove duplicates\n",
        "\n",
        "# Display and visualize\n",
        "textbook_summary_cols = [c for c in new_cols_df.columns if c in df.columns]\n",
        "print(df[textbook_summary_cols].head())\n",
        "\n",
        "plt.figure(figsize=(10, 6))\n",
        "sns.boxplot(data=df[textbook_summary_cols])\n",
        "plt.title('Textbook Access Distribution by Education Level', fontsize=14, fontweight='bold')\n",
        "plt.ylabel('Access Score (0 to 1)')\n",
        "plt.xticks(rotation=15)\n",
        "plt.grid(alpha=0.3)\n",
        "plt.show()\n",
        "\n",
        "\n",
        "# ================================\n",
        "# 6Ô∏è‚É£ TRACK-BASED NATIONAL EXAMS\n",
        "# ================================\n",
        "# Subjects per track\n",
        "social_subjects = ['National_Exam_History', 'National_Exam_Geography',\n",
        "                   'National_Exam_Economics', 'National_Exam_Math_Social']\n",
        "\n",
        "natural_subjects = ['National_Exam_Biology', 'National_Exam_Chemistry',\n",
        "                    'National_Exam_Physics', 'National_Exam_Math_Natural']\n",
        "\n",
        "# Track-specific averages\n",
        "df['Social_Track_Subject_Avg']  = df[social_subjects].mean(axis=1)\n",
        "df['Natural_Track_Subject_Avg'] = df[natural_subjects].mean(axis=1)\n",
        "\n",
        "# Track-based assignment\n",
        "df['Track_Subject_Average'] = np.where(\n",
        "    df['Field_Choice'] == 0,\n",
        "    df['Social_Track_Subject_Avg'],\n",
        "    df['Natural_Track_Subject_Avg']\n",
        ")\n",
        "\n",
        "# Common subjects for all students\n",
        "common_subjects = ['National_Exam_Aptitude', 'National_Exam_English',\n",
        "                   'National_Exam_Civics_and_Ethical_Education']\n",
        "df['Common_Exam_Average'] = df[common_subjects].mean(axis=1)\n",
        "\n",
        "# Overall Track Exam Average\n",
        "df['Track_Exam_Average'] = (df['Common_Exam_Average'] + df['Track_Subject_Average']) / 2\n",
        "\n",
        "# Display new exam columns\n",
        "exam_cols = [\n",
        "    'Social_Track_Subject_Avg',\n",
        "    'Natural_Track_Subject_Avg',\n",
        "    'Track_Subject_Average',\n",
        "    'Common_Exam_Average',\n",
        "    'Track_Exam_Average'\n",
        "]\n",
        "print(\"New Aggregated National Exam Features:\")\n",
        "print(df[exam_cols].head())\n",
        "\n",
        "\n",
        "# ================================\n",
        "# 7Ô∏è‚É£ VISUALIZATION: Exam Scores\n",
        "# ================================\n",
        "sns.set_theme(style=\"whitegrid\")\n",
        "fig, axes = plt.subplots(1, 2, figsize=(16, 6))\n",
        "\n",
        "# Boxplot: Common vs Track vs Overall\n",
        "sns.boxplot(data=df[['Common_Exam_Average', 'Track_Subject_Average', 'Track_Exam_Average']],\n",
        "            ax=axes[0], palette=\"Set2\")\n",
        "axes[0].set_title('Distribution of Aggregate Exam Scores')\n",
        "axes[0].set_ylabel('Score (0-100)')\n",
        "\n",
        "# KDE: Track Exam Average by Field Choice\n",
        "for choice, label in [(0, 'Social Science'), (1, 'Natural Science')]:\n",
        "    subset = df[df['Field_Choice'] == choice]\n",
        "    sns.kdeplot(subset['Track_Exam_Average'], ax=axes[1], label=label, fill=True)\n",
        "\n",
        "axes[1].set_title('Track Exam Average: Social vs. Natural')\n",
        "axes[1].set_xlabel('Score')\n",
        "axes[1].legend()\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "tnl8OEnxKSNa"
      },
      "id": "tnl8OEnxKSNa",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# DROP ORIGINAL HIGH-DIMENSION COLUMNS\n",
        "drop_cols = [c for c in df.columns if c.startswith('Grade_')]\n",
        "drop_cols += [c for c in df.columns if c.startswith('National_Exam_')]\n",
        "\n",
        "df = df.drop(columns=drop_cols)\n",
        "# -------------------------------\n",
        "# 0Ô∏è‚É£ Drop leaking exam average columns\n",
        "# -------------------------------\n",
        "leak_cols = [\n",
        "    'Social_Track_Subject_Avg',\n",
        "    'Natural_Track_Subject_Avg',\n",
        "    'Track_Exam_Average',\n",
        "    'Track_Subject_Average',\n",
        "    'Common_Exam_Average',\n",
        "     'School_ID','Total_Test_Score','Overall_Average']\n",
        "\n",
        "df = df.drop(columns=[c for c in leak_cols if c in df.columns])\n",
        "\n",
        "# fix null value\n",
        "df['Health_Issue'] = df['Health_Issue'].fillna('No Issue')\n",
        "df['Father_Education'] = df['Father_Education'].fillna('Unknown')\n",
        "df['Mother_Education'] = df['Mother_Education'].fillna('Unknown')\n",
        "\n",
        "# FINAL CHECK\n",
        "print(df.shape)\n",
        "print(df.head())\n",
        "print(\"all columns:\",df.columns)\n",
        "\n",
        "# Find duplicates\n",
        "duplicates = df[df.duplicated()]"
      ],
      "metadata": {
        "id": "VKEWfO30KYRs"
      },
      "id": "VKEWfO30KYRs",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Select categorical columns\n",
        "cat_cols = df.select_dtypes(include=['object', 'category']).columns\n",
        "\n",
        "# Prepare a dictionary to store info\n",
        "cat_summary = {}\n",
        "\n",
        "for col in cat_cols:\n",
        "    unique_vals = df[col].unique()\n",
        "    cat_summary[col] = {\n",
        "        'Unique_Count': len(unique_vals),\n",
        "        'Unique_Values': unique_vals\n",
        "    }\n",
        "\n",
        "# Display summary in a readable way\n",
        "print(\"Unique count and value of catagorical features:\")\n",
        "for col, info in cat_summary.items():\n",
        "    print(f\"Column: {col}\")\n",
        "    print(f\"  Unique Count : {info['Unique_Count']}\")\n",
        "    print(f\"  Unique Values: {info['Unique_Values']}\\n\")"
      ],
      "metadata": {
        "id": "f_AQVcv5KnMD"
      },
      "id": "f_AQVcv5KnMD",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df['Date_of_Birth'] = pd.to_datetime(df['Date_of_Birth'])\n",
        "\n",
        "df['Birth_Year'] = df['Date_of_Birth'].dt.year\n",
        "df['Birth_Month'] = df['Date_of_Birth'].dt.month\n",
        "df['Birth_Day'] = df['Date_of_Birth'].dt.day\n",
        "\n",
        "df.drop(columns=['Date_of_Birth'], inplace=True)"
      ],
      "metadata": {
        "id": "tsm7_sE8KsfX"
      },
      "id": "tsm7_sE8KsfX",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "binary_cols = [\n",
        "    'Gender',\n",
        "    'Home_Internet_Access',\n",
        "    'Electricity_Access',\n",
        "    'School_Location'\n",
        "]\n",
        "\n",
        "binary_map = {\n",
        "    'Yes': 1, 'No': 0,\n",
        "    'Male': 1, 'Female': 0,\n",
        "    'Urban': 1, 'Rural': 0\n",
        "}\n",
        "\n",
        "for col in binary_cols:\n",
        "    df[col] = df[col].map(binary_map)"
      ],
      "metadata": {
        "id": "LDq5uvC-Kzng"
      },
      "id": "LDq5uvC-Kzng",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import LabelEncoder\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.layers import Input, Embedding, Flatten, Concatenate, Dense\n",
        "\n",
        "embedding_cols = [\n",
        "    'Region',\n",
        "    'Health_Issue',\n",
        "    'Father_Education',\n",
        "    'Mother_Education',\n",
        "    'School_Type',\n",
        "    'Career_Interest'\n",
        "]\n",
        "label_encoders = {}\n",
        "\n",
        "for col in embedding_cols:\n",
        "    le = LabelEncoder()\n",
        "    df[col] = le.fit_transform(df[col])\n",
        "    label_encoders[col] = le"
      ],
      "metadata": {
        "id": "XG-oxnPAK6b1"
      },
      "id": "XG-oxnPAK6b1",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.info()"
      ],
      "metadata": {
        "id": "QxeGD-TLLKMZ"
      },
      "id": "QxeGD-TLLKMZ",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
        "\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.layers import Input, Embedding, Flatten, Dense, Concatenate, Dropout\n",
        "from tensorflow.keras.models import Model\n",
        "\n",
        "target = 'Total_National_Exam_Score'\n",
        "\n",
        "X = df.drop(columns=[target])\n",
        "y = df[target].values\n",
        "\n",
        "numerical_cols = X.select_dtypes(include=['float64', 'int64']) \\\n",
        "                  .columns.difference(embedding_cols)\n",
        "\n",
        "scaler = StandardScaler()\n",
        "X[numerical_cols] = scaler.fit_transform(X[numerical_cols])\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X, y, test_size=0.2, random_state=42\n",
        ")"
      ],
      "metadata": {
        "id": "y7vFIk6ULSHh"
      },
      "id": "y7vFIk6ULSHh",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "inputs = []\n",
        "embeddings = []\n",
        "\n",
        "for col in embedding_cols:\n",
        "    n_unique = df[col].nunique()\n",
        "    embed_dim = min(50, (n_unique + 1) // 2)\n",
        "\n",
        "    inp = Input(shape=(1,), name=col)\n",
        "    emb = Embedding(\n",
        "        input_dim=n_unique + 1,\n",
        "        output_dim=embed_dim,\n",
        "        name=f\"{col}_embedding\"\n",
        "    )(inp)\n",
        "    emb = Flatten()(emb)\n",
        "\n",
        "    inputs.append(inp)\n",
        "    embeddings.append(emb)"
      ],
      "metadata": {
        "id": "jMAyWTyYmq7F"
      },
      "id": "jMAyWTyYmq7F",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "numerical_cols = (\n",
        "    X.select_dtypes(include=['float64', 'int64'])\n",
        "     .columns\n",
        "     .difference(embedding_cols)\n",
        ")\n",
        "num_input = Input(shape=(len(numerical_cols),), name=\"numerical\")\n",
        "inputs.append(num_input)\n",
        "\n",
        "print(\"Numerical columns:\", numerical_cols)\n",
        "print(\"Number of numerical features:\", len(numerical_cols))"
      ],
      "metadata": {
        "id": "Kf9-9q2cnByD"
      },
      "id": "Kf9-9q2cnByD",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.layers import BatchNormalization\n",
        "\n",
        "x = Concatenate()(embeddings + [num_input])\n",
        "\n",
        "x = Dense(256, activation='relu')(x)\n",
        "x = BatchNormalization()(x)\n",
        "x = Dropout(0.3)(x)\n",
        "\n",
        "x = Dense(128, activation='relu')(x)\n",
        "x = Dropout(0.3)(x)\n",
        "\n",
        "x = Dense(64, activation='relu')(x)\n",
        "\n",
        "output = Dense(1, activation='linear')(x)\n",
        "\n",
        "model = Model(inputs=inputs, outputs=output)"
      ],
      "metadata": {
        "id": "-Rl6i4GhnG56"
      },
      "id": "-Rl6i4GhnG56",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(\n",
        "    optimizer=tf.keras.optimizers.Adam(learning_rate=0.001),\n",
        "    loss=tf.keras.losses.Huber(),\n",
        "    metrics=['mae']\n",
        ")"
      ],
      "metadata": {
        "id": "-MEiuNI_nMGM"
      },
      "id": "-MEiuNI_nMGM",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def prepare_inputs(dataframe):\n",
        "    inputs = {}\n",
        "    for col in embedding_cols:\n",
        "        inputs[col] = dataframe[col].values\n",
        "    inputs['numerical'] = dataframe[numerical_cols].values\n",
        "    return inputs"
      ],
      "metadata": {
        "id": "JtDaHMOTnQkb"
      },
      "id": "JtDaHMOTnQkb",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_inputs = prepare_inputs(X_train)\n",
        "test_inputs = prepare_inputs(X_test)"
      ],
      "metadata": {
        "id": "veinu3mPnVoo"
      },
      "id": "veinu3mPnVoo",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3",
      "language": "python"
    },
    "language_info": {
      "name": "python",
      "version": "3.10"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}