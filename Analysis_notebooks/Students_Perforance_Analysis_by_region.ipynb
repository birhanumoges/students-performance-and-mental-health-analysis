{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BCkJxcXsDZpY"
      },
      "source": [
        "# Students Performance Analysis by Region\n",
        "This notebook analyzes student performance by region."
      ],
      "id": "BCkJxcXsDZpY"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hd2TRLQ_DZpZ"
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns"
      ],
      "execution_count": null,
      "outputs": [],
      "id": "hd2TRLQ_DZpZ"
    },
    {
      "cell_type": "code",
      "source": [
        "# Load CSV file\n",
        "df = pd.read_csv(r\"C:/Users/DELL/Downloads/ethiopian_students_dataset.csv\")\n",
        "\n",
        "# View first 5 rows\n",
        "print(df.head())\n",
        "\n",
        "# Access a column\n",
        "print(df.columns)"
      ],
      "metadata": {
        "id": "a-LSnq5IECou"
      },
      "id": "a-LSnq5IECou",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 1. Get the value counts of dtypes\n",
        "dtype_counts = df.dtypes.value_counts().reset_index()\n",
        "dtype_counts.columns = ['Data Type', 'Count']\n",
        "\n",
        "# 2. Plotting with the fix\n",
        "plt.figure(figsize=(10, 6))\n",
        "\n",
        "# Fix: Assign 'Data Type' to hue and set legend=False\n",
        "sns.barplot(\n",
        "    data=dtype_counts,\n",
        "    x='Data Type',\n",
        "    y='Count',\n",
        "    hue='Data Type',\n",
        "    palette='viridis',\n",
        "    legend=False\n",
        ")\n",
        "\n",
        "plt.title('Distribution of Data Types in Student Dataset', fontsize=14)\n",
        "plt.ylabel('Number of Columns')\n",
        "plt.xlabel('Data Type')\n",
        "\n",
        "# 3. Add labels on top of bars\n",
        "for i, count in enumerate(dtype_counts['Count']):\n",
        "    plt.text(i, count + 5, str(count), ha='center', fontweight='bold')\n",
        "\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "Gn7nFWh5ENMe"
      },
      "id": "Gn7nFWh5ENMe",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ================================\n",
        "# 1Ô∏è‚É£ INITIAL CLEANING & ENCODING\n",
        "# ================================\n",
        "# Drop Student_ID (never used in ML)\n",
        "df = df.drop(columns=['Student_ID'], errors='ignore')\n",
        "\n",
        "# Encode Field_Choice (Social=0, Natural=1)\n",
        "df['Field_Choice'] = df['Field_Choice'].map({'Social': 0, 'Natural': 1})\n",
        "\n",
        "# Fill missing Career_Interest with \"Unknown\"\n",
        "df['Career_Interest'] = df['Career_Interest'].fillna('Unknown')\n",
        "\n",
        "\n",
        "# ================================\n",
        "# 2Ô∏è‚É£ DEFINE EDUCATION STAGES\n",
        "# ================================\n",
        "lower_primary = ['Grade_1', 'Grade_2', 'Grade_3', 'Grade_4']\n",
        "upper_primary = ['Grade_5', 'Grade_6', 'Grade_7', 'Grade_8']\n",
        "secondary     = ['Grade_9', 'Grade_10']\n",
        "preparatory   = ['Grade_11', 'Grade_12']\n",
        "\n",
        "stages = {\n",
        "    'Lower_Primary': lower_primary,\n",
        "    'Upper_Primary': upper_primary,\n",
        "    'Secondary': secondary,\n",
        "    'Preparatory': preparatory\n",
        "}\n",
        "\n",
        "\n",
        "# ================================\n",
        "# 3Ô∏è‚É£ HELPER FUNCTION TO AGGREGATE GRADES\n",
        "# ================================\n",
        "def stage_average(df, grades, metric_keywords):\n",
        "    \"\"\"\n",
        "    Compute average across all columns for a given stage and metric keywords.\n",
        "    Returns the average series and list of original columns used.\n",
        "    \"\"\"\n",
        "    cols = []\n",
        "    for g in grades:\n",
        "        for keyword in metric_keywords:\n",
        "            cols += [c for c in df.columns if c.startswith(g) and keyword.lower() in c.lower()]\n",
        "    cols = list(set(cols))\n",
        "    return df[cols].mean(axis=1), cols\n",
        "\n",
        "\n",
        "# ================================\n",
        "# 4Ô∏è‚É£ AGGREGATE TEST SCORE, ATTENDANCE, HW, PARTICIPATION\n",
        "# ================================\n",
        "metrics_dict = {\n",
        "    'Test_Score': ['Test_Score'],\n",
        "    'Attendance': ['Attendance'],\n",
        "    'HW_Completion': ['Homework_Completion'],\n",
        "    'Participation': ['Participation']\n",
        "}\n",
        "\n",
        "cols_to_drop = []\n",
        "\n",
        "for metric_name, keywords in metrics_dict.items():\n",
        "    for stage_name, grades in stages.items():\n",
        "        col_name = f'Avg_{metric_name}_{stage_name}'\n",
        "        df[col_name], original_cols = stage_average(df, grades, keywords)\n",
        "        cols_to_drop += original_cols\n",
        "\n",
        "# Drop original grade-level columns\n",
        "df.drop(columns=list(set(cols_to_drop)), inplace=True)\n",
        "\n",
        "# Columns list for display\n",
        "aggregated_cols = [f'Avg_{m}_{s}' for m in metrics_dict.keys() for s in stages.keys()]\n",
        "print(\"Aggregated averages per Education Stage (head):\")\n",
        "print(df[aggregated_cols].head())\n",
        "\n",
        "\n",
        "# ================================\n",
        "# 5Ô∏è‚É£ AGGREGATE TEXTBOOK ACCESS\n",
        "# ================================\n",
        "# Convert Yes/No ‚Üí 1/0 safely\n",
        "textbook_cols = [c for c in df.columns if 'Textbook' in c]\n",
        "for col in textbook_cols:\n",
        "    df[col] = df[col].replace({'Yes': 1, 'No': 0}).infer_objects(copy=False)\n",
        "\n",
        "# Helper function for textbook access per stage\n",
        "def textbook_access(df, grade_prefixes):\n",
        "    cols = []\n",
        "    for g in grade_prefixes:\n",
        "        cols.extend([c for c in df.columns if c.startswith(g) and 'Textbook' in c])\n",
        "    return df[cols].mean(axis=1) if len(cols) > 0 else pd.Series(0, index=df.index)\n",
        "\n",
        "# Create aggregated textbook access per stage\n",
        "new_cols_df = pd.DataFrame({\n",
        "    'Textbook_Access_1_4': textbook_access(df, lower_primary),\n",
        "    'Textbook_Access_5_8': textbook_access(df, upper_primary),\n",
        "    'Textbook_Access_9_10': textbook_access(df, secondary),\n",
        "    'Textbook_Access_11_12': textbook_access(df, preparatory)\n",
        "})\n",
        "\n",
        "df = pd.concat([df, new_cols_df], axis=1)\n",
        "df = df.loc[:, ~df.columns.duplicated()]  # remove duplicates\n",
        "\n",
        "# Display and visualize\n",
        "textbook_summary_cols = [c for c in new_cols_df.columns if c in df.columns]\n",
        "print(df[textbook_summary_cols].head())\n",
        "\n",
        "plt.figure(figsize=(10, 6))\n",
        "sns.boxplot(data=df[textbook_summary_cols])\n",
        "plt.title('Textbook Access Distribution by Education Level', fontsize=14, fontweight='bold')\n",
        "plt.ylabel('Access Score (0 to 1)')\n",
        "plt.xticks(rotation=15)\n",
        "plt.grid(alpha=0.3)\n",
        "plt.show()\n",
        "\n",
        "\n",
        "# ================================\n",
        "# 6Ô∏è‚É£ TRACK-BASED NATIONAL EXAMS\n",
        "# ================================\n",
        "# Subjects per track\n",
        "social_subjects = ['National_Exam_History', 'National_Exam_Geography',\n",
        "                   'National_Exam_Economics', 'National_Exam_Math_Social']\n",
        "\n",
        "natural_subjects = ['National_Exam_Biology', 'National_Exam_Chemistry',\n",
        "                    'National_Exam_Physics', 'National_Exam_Math_Natural']\n",
        "\n",
        "# Track-specific averages\n",
        "df['Social_Track_Subject_Avg']  = df[social_subjects].mean(axis=1)\n",
        "df['Natural_Track_Subject_Avg'] = df[natural_subjects].mean(axis=1)\n",
        "\n",
        "# Track-based assignment\n",
        "df['Track_Subject_Average'] = np.where(\n",
        "    df['Field_Choice'] == 0,\n",
        "    df['Social_Track_Subject_Avg'],\n",
        "    df['Natural_Track_Subject_Avg']\n",
        ")\n",
        "\n",
        "# Common subjects for all students\n",
        "common_subjects = ['National_Exam_Aptitude', 'National_Exam_English',\n",
        "                   'National_Exam_Civics_and_Ethical_Education']\n",
        "df['Common_Exam_Average'] = df[common_subjects].mean(axis=1)\n",
        "\n",
        "# Overall Track Exam Average\n",
        "df['Track_Exam_Average'] = (df['Common_Exam_Average'] + df['Track_Subject_Average']) / 2\n",
        "\n",
        "# Display new exam columns\n",
        "exam_cols = [\n",
        "    'Social_Track_Subject_Avg',\n",
        "    'Natural_Track_Subject_Avg',\n",
        "    'Track_Subject_Average',\n",
        "    'Common_Exam_Average',\n",
        "    'Track_Exam_Average'\n",
        "]\n",
        "print(\"New Aggregated National Exam Features:\")\n",
        "print(df[exam_cols].head())\n",
        "\n",
        "\n",
        "# ================================\n",
        "# 7Ô∏è‚É£ VISUALIZATION: Exam Scores\n",
        "# ================================\n",
        "sns.set_theme(style=\"whitegrid\")\n",
        "fig, axes = plt.subplots(1, 2, figsize=(16, 6))\n",
        "\n",
        "# Boxplot: Common vs Track vs Overall\n",
        "sns.boxplot(data=df[['Common_Exam_Average', 'Track_Subject_Average', 'Track_Exam_Average']],\n",
        "            ax=axes[0], palette=\"Set2\")\n",
        "axes[0].set_title('Distribution of Aggregate Exam Scores')\n",
        "axes[0].set_ylabel('Score (0-100)')\n",
        "\n",
        "# KDE: Track Exam Average by Field Choice\n",
        "for choice, label in [(0, 'Social Science'), (1, 'Natural Science')]:\n",
        "    subset = df[df['Field_Choice'] == choice]\n",
        "    sns.kdeplot(subset['Track_Exam_Average'], ax=axes[1], label=label, fill=True)\n",
        "\n",
        "axes[1].set_title('Track Exam Average: Social vs. Natural')\n",
        "axes[1].set_xlabel('Score')\n",
        "axes[1].legend()\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "irLJVzqJEb-l"
      },
      "id": "irLJVzqJEb-l",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# DROP ORIGINAL HIGH-DIMENSION COLUMNS\n",
        "drop_cols = [c for c in df.columns if c.startswith('Grade_')]\n",
        "drop_cols += [c for c in df.columns if c.startswith('National_Exam_')]\n",
        "\n",
        "df = df.drop(columns=drop_cols)\n",
        "# -------------------------------\n",
        "# 0Ô∏è‚É£ Drop leaking exam average columns\n",
        "# -------------------------------\n",
        "leak_cols = [\n",
        "    'Social_Track_Subject_Avg',\n",
        "    'Natural_Track_Subject_Avg',\n",
        "    'Track_Exam_Average',\n",
        "    'Track_Subject_Average',\n",
        "    'Common_Exam_Average',\n",
        "     'School_ID']\n",
        "\n",
        "df = df.drop(columns=[c for c in leak_cols if c in df.columns])\n",
        "\n",
        "# fix null value\n",
        "df['Health_Issue'] = df['Health_Issue'].fillna('No Issue')\n",
        "df['Father_Education'] = df['Father_Education'].fillna('Unknown')\n",
        "df['Mother_Education'] = df['Mother_Education'].fillna('Unknown')\n",
        "\n",
        "# FINAL CHECK\n",
        "print(df.shape)\n",
        "print(df.head())\n",
        "print(\"all columns:\",df.columns)\n",
        "\n",
        "# Find duplicates\n",
        "duplicates = df[df.duplicated()]"
      ],
      "metadata": {
        "id": "77-4qt2D8GSF"
      },
      "id": "77-4qt2D8GSF",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ================================\n",
        "# ALL-IN-ONE CATEGORICAL ENCODING\n",
        "# ================================\n",
        "# -------------------------------\n",
        "# 1Ô∏è‚É£ Fill missing / fix NaNs\n",
        "# -------------------------------\n",
        "if 'Health_Issue' in df.columns:\n",
        "    df['Health_Issue'] = df['Health_Issue'].fillna('No Issue')\n",
        "\n",
        "for col in ['Father_Education', 'Mother_Education']:\n",
        "    if col in df.columns:\n",
        "        df[col] = df[col].fillna('Unknown')\n",
        "\n",
        "# -------------------------------\n",
        "# 2Ô∏è‚É£ Binary encoding\n",
        "# -------------------------------\n",
        "binary_maps = {\n",
        "    'Gender': {'Male': 0, 'Female': 1},\n",
        "    'Home_Internet_Access': {'No': 0, 'Yes': 1},\n",
        "    'Electricity_Access': {'No': 0, 'Yes': 1},\n",
        "    'School_Location': {'Rural': 0, 'Urban': 1}\n",
        "}\n",
        "\n",
        "for col, mapping in binary_maps.items():\n",
        "    if col in df.columns:\n",
        "        df[col] = df[col].map(mapping)\n",
        "\n",
        "# -------------------------------\n",
        "# 3Ô∏è‚É£ Ordinal encoding (Parents Education)\n",
        "# -------------------------------\n",
        "edu_map = {'Unknown': 0, 'Primary': 1, 'High School': 2, 'College': 3, 'University': 4}\n",
        "for col in ['Father_Education', 'Mother_Education']:\n",
        "    enc_col = col + '_Encoded'\n",
        "    if col in df.columns:\n",
        "        df[enc_col] = df[col].map(edu_map)\n",
        "        df.drop(columns=[col], inplace=True)\n",
        "\n",
        "# -------------------------------\n",
        "# 4Ô∏è‚É£ One-Hot Encoding (moderate cardinality)\n",
        "# -------------------------------\n",
        "ohe_cols = [c for c in [ 'School_Type', 'Health_Issue'] if c in df.columns]\n",
        "if ohe_cols:\n",
        "    df = pd.get_dummies(df, columns=ohe_cols, drop_first=True)\n",
        "\n",
        "# -------------------------------\n",
        "# Convert Date_of_Birth ‚Üí Age (numeric)\n",
        "# -------------------------------\n",
        "CURRENT_DATE = pd.Timestamp('2026-01-30')  # fixed date for reproducibility\n",
        "\n",
        "if 'Date_of_Birth' in df.columns:\n",
        "    df['Date_of_Birth'] = pd.to_datetime(df['Date_of_Birth'], errors='coerce')\n",
        "    df['Age'] = ((CURRENT_DATE - df['Date_of_Birth']).dt.days // 365).astype(float)\n",
        "    df.drop(columns=['Date_of_Birth'], inplace=True)\n",
        "\n",
        "# -------------------------------\n",
        "# 6Ô∏è‚É£ Safety check\n",
        "# -------------------------------\n",
        "print(\"Categorical encoding completed.\")\n",
        "print(\"Columns now:\", df.select_dtypes(include='object').columns.tolist())  # should be empty"
      ],
      "metadata": {
        "id": "A1CHs1hAF_ib"
      },
      "id": "A1CHs1hAF_ib",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# -------------------------------\n",
        "# üîü Drop Raw Categorical Columns\n",
        "# -------------------------------\n",
        "drop_cols = [\n",
        "    'Father_Education', 'Mother_Education','Career_Interest',\n",
        "    'Health_Issue', 'Date_of_Birth',\n",
        "    'School_ID', 'School_Type',\n",
        "]\n",
        "df.drop(columns=[c for c in drop_cols if c in df.columns], inplace=True)"
      ],
      "metadata": {
        "id": "6Gg3j29cGIVM"
      },
      "id": "6Gg3j29cGIVM",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "cluster_df = df[cluster_features]\n",
        "#2Ô∏è‚É£ Compute correlation matrix\n",
        "corr_matrix = cluster_df.corr()\n",
        "\n",
        "plt.figure(figsize=(12, 10))\n",
        "sns.heatmap(corr_matrix, annot=True, fmt=\".2f\", cmap=\"coolwarm\", cbar=True)\n",
        "plt.title(\"Correlation Matrix - Selected Cluster Features\", fontsize=16)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "OqEOPImo9-oQ"
      },
      "id": "OqEOPImo9-oQ",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# -----------------------------\n",
        "# Helper function: get grade-level columns safely due to high VIF of features\n",
        "# -----------------------------\n",
        "def get_grade_columns(df, keywords):\n",
        "    \"\"\"\n",
        "    Returns a DataFrame of all columns containing any of the keywords.\n",
        "    If no columns found, returns a dummy column of zeros to avoid errors.\n",
        "    \"\"\"\n",
        "    cols = [c for c in df.columns if any(k in c for k in keywords)]\n",
        "    if not cols:\n",
        "        return pd.DataFrame(0, index=df.index, columns=['dummy'])\n",
        "    return df[cols]\n",
        "\n",
        "# -----------------------------\n",
        "# Create composite features\n",
        "# -----------------------------\n",
        "df['Overall_Test_Score_Avg'] = df[['Avg_Test_Score_Preparatory',\n",
        "                                   'Avg_Test_Score_Lower_Primary',\n",
        "                                   'Avg_Test_Score_Upper_Primary',\n",
        "                                   'Avg_Test_Score_Secondary']].mean(axis=1)\n",
        "\n",
        "df['Overall_Textbook_Access_Composite'] = df[['Textbook_Access_1_4', 'Textbook_Access_5_8',\n",
        "                                      'Textbook_Access_9_10', 'Textbook_Access_11_12']].mean(axis=1)\n",
        "\n",
        "df['Academic_Growth_Primary_to_Secondary'] = df['Avg_Test_Score_Secondary'] - df['Avg_Test_Score_Lower_Primary']\n",
        "\n",
        "# -----------------------------\n",
        "# Overall engagement averages\n",
        "# -----------------------------\n",
        "# -----------------------------\n",
        "# Create overall averages (explicit columns)\n",
        "# -----------------------------\n",
        "\n",
        "# Attendance columns\n",
        "attendance_cols = [\n",
        "    'Avg_Attendance_Lower_Primary',\n",
        "    'Avg_Attendance_Upper_Primary',\n",
        "    'Avg_Attendance_Secondary',\n",
        "    'Avg_Attendance_Preparatory'\n",
        "]\n",
        "\n",
        "df['Overall_Avg_Attendance'] = df[attendance_cols].mean(axis=1)\n",
        "\n",
        "# Homework columns\n",
        "homework_cols = [\n",
        "    'Avg_HW_Completion_Lower_Primary',\n",
        "    'Avg_HW_Completion_Upper_Primary',\n",
        "    'Avg_HW_Completion_Secondary',\n",
        "    'Avg_HW_Completion_Preparatory'\n",
        "]\n",
        "\n",
        "df['Overall_Avg_Homework'] = df[homework_cols].mean(axis=1)\n",
        "\n",
        "# Participation columns\n",
        "participation_cols = [\n",
        "    'Avg_Participation_Lower_Primary',\n",
        "    'Avg_Participation_Upper_Primary',\n",
        "    'Avg_Participation_Secondary',\n",
        "    'Avg_Participation_Preparatory'\n",
        "]\n",
        "\n",
        "df['Overall_Avg_Participation'] = df[participation_cols].mean(axis=1)\n",
        "\n",
        "# -----------------------------\n",
        "# Composite engagement score (weighted)\n",
        "# -----------------------------\n",
        "df['Overall_Engagement_Score'] = (\n",
        "    df['Overall_Avg_Attendance'] * 0.4 +\n",
        "    df['Overall_Avg_Homework'] * 0.3 +\n",
        "    df['Overall_Avg_Participation'] * 0.3\n",
        ")\n",
        "\n",
        "# -----------------------------\n",
        "# Quick overview\n",
        "# -----------------------------\n",
        "print(\"\\nCreated overall averages:\")\n",
        "for col in ['Overall_Avg_Attendance', 'Overall_Avg_Homework','Overall_Textbook_Access_Composite', 'Overall_Avg_Participation', 'Overall_Engagement_Score']:\n",
        "    print(f\"- {col}: {df[col].mean():.2f}\")"
      ],
      "metadata": {
        "id": "VSqKiuNw9F2b"
      },
      "id": "VSqKiuNw9F2b",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# DROP ORIGINAL HIGH-DIMENSION COLUMNS\n",
        "\n",
        "drop_cols = []\n",
        "\n",
        "# Test Scores\n",
        "drop_cols += [c for c in df.columns if c.startswith('Avg_Test_Score_')]\n",
        "\n",
        "# Textbook Access\n",
        "drop_cols += [c for c in df.columns if c.startswith('Textbook_Access_')]\n",
        "\n",
        "# Attendance, Participation, Homework\n",
        "drop_cols += [c for c in df.columns if c.startswith('Avg_Attendance_')]\n",
        "drop_cols += [c for c in df.columns if c.startswith('Avg_Participation_')]\n",
        "drop_cols += [c for c in df.columns if c.startswith('Avg_HW_Completion_')]\n",
        "\n",
        "# Drop safely\n",
        "df = df.drop(columns=drop_cols, errors='ignore')\n",
        "\n",
        "print(f\"Dropped {len(drop_cols)} original aggregated columns.\")"
      ],
      "metadata": {
        "id": "zYwp-fXh9YyE"
      },
      "id": "zYwp-fXh9YyE",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#=======================================================\n",
        "# Not Remove rows with any outlier becuase it is necesary\n",
        "#=======================================================\n",
        "numeric_cols = df.select_dtypes(include=['float64', 'int64']).columns.tolist()\n",
        "# Calculate Q1, Q3, and IQR\n",
        "Q1 = df[numeric_cols].quantile(0.25)\n",
        "Q3 = df[numeric_cols].quantile(0.75)\n",
        "IQR = Q3 - Q1\n",
        "\n",
        "# Detect outliers\n",
        "outliers = ((df[numeric_cols] < (Q1 - 1.5 * IQR)) | (df[numeric_cols] > (Q3 + 1.5 * IQR)))\n",
        "\n",
        "# Count of outliers per column\n",
        "outlier_counts = outliers.sum()\n",
        "print(\"Outliers per column:\\n\", outlier_counts)\n"
      ],
      "metadata": {
        "id": "wsqNvawoGORX"
      },
      "id": "wsqNvawoGORX",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ==============================================\n",
        "# COMPLETE STUDENT PERFORMANCE CLUSTERING PIPELINE\n",
        "# ==============================================\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.cluster import MiniBatchKMeans\n",
        "from sklearn.metrics import silhouette_score\n",
        "from sklearn.decomposition import PCA\n",
        "\n",
        "# ----------------------------\n",
        "# 1Ô∏è‚É£ Define clustering features\n",
        "# ----------------------------\n",
        "cluster_features = [\n",
        "    'Total_National_Exam_Score',\n",
        "    'Overall_Test_Score_Avg',\n",
        "    'Overall_Avg_Attendance',\n",
        "    'Overall_Avg_Homework',\n",
        "    'Overall_Avg_Participation',\n",
        "    'Overall_Engagement_Score',\n",
        "    'Overall_Textbook_Access_Composite'\n",
        "    'School_Resources_Score',\n",
        "    'School_Academic_Score',\n",
        "    'Teacher_Student_Ratio',\n",
        "    'Student_to_Resources_Ratio',\n",
        "    'Parental_Involvement',\n",
        "    'School_Location',\n",
        "]\n",
        "\n",
        "# ----------------------------\n",
        "# 2Ô∏è‚É£ Ensure boolean columns are numeric\n",
        "# ----------------------------\n",
        "bool_cols = ['School_Type_NGO-operated', 'School_Type_Private', 'School_Type_Public']\n",
        "for col in bool_cols:\n",
        "    if df[col].dtype == 'bool':\n",
        "        df[col] = df[col].astype(int)\n",
        "\n",
        "# ----------------------------\n",
        "# 3Ô∏è‚É£ Standardize features\n",
        "# ----------------------------\n",
        "scaler = StandardScaler()\n",
        "X_scaled = scaler.fit_transform(df[cluster_features])\n",
        "\n",
        "# ----------------------------\n",
        "# 4Ô∏è‚É£ Run MiniBatchKMeans\n",
        "# ----------------------------\n",
        "optimal_k = 3\n",
        "kmeans = MiniBatchKMeans(n_clusters=optimal_k, batch_size=8192, random_state=42)\n",
        "df['Performance_Cluster'] = kmeans.fit_predict(X_scaled)\n",
        "\n",
        "# ----------------------------\n",
        "# 5Ô∏è‚É£ Map clusters to labels\n",
        "# High = highest exam scores, Low = lowest\n",
        "# ----------------------------\n",
        "cluster_order = (\n",
        "    df.groupby('Performance_Cluster')['Total_National_Exam_Score']\n",
        "      .mean()\n",
        "      .sort_values(ascending=False)\n",
        "      .index\n",
        ")\n",
        "\n",
        "label_map = {\n",
        "    cluster_order[0]: 'High',\n",
        "    cluster_order[1]: 'Medium',\n",
        "    cluster_order[2]: 'Low'\n",
        "}\n",
        "\n",
        "df['Performance_Label'] = df['Performance_Cluster'].map(label_map)\n",
        "\n",
        "print(\"\\nüè∑Ô∏è CLUSTER ‚Üí LABEL MAPPING:\")\n",
        "for k, v in label_map.items():\n",
        "    print(f\"Cluster {k} ‚Üí {v}\")\n",
        "\n",
        "# ----------------------------\n",
        "# 6Ô∏è‚É£ Cluster sizes\n",
        "# ----------------------------\n",
        "print(\"\\nüì¶ CLUSTER SIZES:\\n\")\n",
        "print(df['Performance_Label'].value_counts())\n",
        "\n",
        "# ----------------------------\n",
        "# 7Ô∏è‚É£ Compute Silhouette Score\n",
        "# ----------------------------\n",
        "sil_score = silhouette_score(X_scaled, df['Performance_Cluster'])\n",
        "print(f\"\\n‚úÖ Silhouette Score for {optimal_k} clusters: {sil_score:.4f}\")\n",
        "\n",
        "# ----------------------------\n",
        "# 8Ô∏è‚É£ Cluster profiles\n",
        "# ----------------------------\n",
        "cluster_profile = df.groupby('Performance_Cluster')[cluster_features].mean()\n",
        "print(\"\\nCLUSTER PROFILES:\\n\")\n",
        "print(cluster_profile)\n",
        "\n",
        "# ----------------------------\n",
        "# 9Ô∏è‚É£ Cluster sizes (raw)\n",
        "# ----------------------------\n",
        "cluster_sizes = df['Performance_Cluster'].value_counts().sort_index()\n",
        "print(\"\\nCLUSTER SIZES (RAW):\\n\")\n",
        "print(cluster_sizes)\n",
        "\n",
        "# ----------------------------\n",
        "# üîπ 10Ô∏è‚É£ Regional Distribution of Clusters\n",
        "# ----------------------------\n",
        "if 'Region' in df.columns:\n",
        "    region_cluster_pct = (\n",
        "        df.groupby(['Region', 'Performance_Cluster'])\n",
        "          .size()\n",
        "          .groupby(level=0)\n",
        "          .apply(lambda x: x / x.sum())\n",
        "          .unstack()\n",
        "    )\n",
        "\n",
        "    plt.figure(figsize=(12,6))\n",
        "    sns.heatmap(region_cluster_pct, annot=True, fmt=\".2f\", cmap=\"Blues\")\n",
        "    plt.title(\"Regional Distribution of Performance Clusters\")\n",
        "    plt.show()\n",
        "\n",
        "# ----------------------------\n",
        "# üîπ 11Ô∏è‚É£ Regional Risk Map (% Low Performance)\n",
        "# ----------------------------\n",
        "if 'Region' in df.columns:\n",
        "    regional_risk = (\n",
        "        df.groupby('Region')['Performance_Label']\n",
        "          .apply(lambda x: (x == 'Low').mean() * 100)\n",
        "          .sort_values(ascending=False)\n",
        "    )\n",
        "\n",
        "    print(\"\\nüó∫Ô∏è REGIONAL RISK (% LOW PERFORMANCE):\\n\")\n",
        "    print(regional_risk)\n",
        "\n",
        "    plt.figure(figsize=(12,6))\n",
        "    sns.barplot(\n",
        "        x=regional_risk.index,\n",
        "        y=regional_risk.values,\n",
        "        color='brown'\n",
        "    )\n",
        "    plt.xticks(rotation=45, ha='right')\n",
        "    plt.ylabel(\"Low Performance (%)\")\n",
        "    plt.title(\"Regional Risk: % of Low-Performing Students\")\n",
        "    plt.show()\n",
        "\n",
        "# ----------------------------\n",
        "# üîπ 12Ô∏è‚É£ PCA Visualization of clusters\n",
        "# ----------------------------\n",
        "pca = PCA(n_components=2)\n",
        "X_pca = pca.fit_transform(X_scaled)\n",
        "\n",
        "plt.figure(figsize=(8,6))\n",
        "sns.scatterplot(\n",
        "    x=X_pca[:,0],\n",
        "    y=X_pca[:,1],\n",
        "    hue=df['Performance_Label'],\n",
        "    palette={'High':'green','Medium':'orange','Low':'red'},\n",
        "    alpha=0.6\n",
        ")\n",
        "plt.title(\"PCA View of Students (Full Dataset)\")\n",
        "plt.xlabel(\"PCA 1\")\n",
        "plt.ylabel(\"PCA 2\")\n",
        "plt.show()\n",
        "\n",
        "print(\"\\n‚úÖ Clustering + labeling aligned correctly.\")"
      ],
      "metadata": {
        "id": "SP9YZY4TGbmU"
      },
      "id": "SP9YZY4TGbmU",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.10"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}