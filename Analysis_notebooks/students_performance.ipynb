{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6d8ad119",
      "metadata": {
        "id": "6d8ad119"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.impute import SimpleImputer\n",
        "\n",
        "# Read the saved data\n",
        "print(\"=\" * 70)\n",
        "print(\"READING SAVED DATA\")\n",
        "print(\"=\" * 70)\n",
        "\n",
        "try:\n",
        "    df = pd.read_csv('students_dataset.csv')\n",
        "    print(f\"✅ Dataset loaded successfully!\")\n",
        "    print(f\" Shape: {df.shape}\")\n",
        "    print(f\" Columns: {len(df.columns)}\")\n",
        "    print(f\" Total records: {len(df)}\")\n",
        "except FileNotFoundError:\n",
        "    print(\" File 'students_dataset.csv' not found.\")\n",
        "    exit()\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 1. Check the basic structure\n",
        "print(\"=\"*60)\n",
        "print(\"DATA STRUCTURE ANALYSIS\")\n",
        "print(\"=\"*60)\n",
        "\n",
        "print(f\"Dataset Shape: {df.shape}\")\n",
        "print(f\"Number of students: {df.shape[0]}\")\n",
        "print(f\"Number of columns: {df.shape[1]}\")\n",
        "print(f\"Memory usage: {df.memory_usage(deep=True).sum() / 1024**2:.2f} MB\")\n",
        "\n",
        "# 2. View column categories\n",
        "print(\"\\n\" + \"=\"*60)\n",
        "print(\"COLUMN CATEGORIES\")\n",
        "print(\"=\"*60)\n",
        "\n",
        "# Group columns by type\n",
        "test_score_cols = [col for col in df.columns if 'Test_Score' in col]\n",
        "attendance_cols = [col for col in df.columns if 'Attendance' in col]\n",
        "homework_cols = [col for col in df.columns if 'Homework' in col]\n",
        "participation_cols = [col for col in df.columns if 'Participation' in col]\n",
        "textbook_cols = [col for col in df.columns if 'Textbook' in col]\n",
        "\n",
        "print(f\"Test Score columns: {len(test_score_cols)}\")\n",
        "print(f\"Attendance columns: {len(attendance_cols)}\")\n",
        "print(f\"Homework columns: {len(homework_cols)}\")\n",
        "print(f\"Participation columns: {len(participation_cols)}\")\n",
        "print(f\"Textbook columns: {len(textbook_cols)}\")\n",
        "\n",
        "# 3. Check subject coverage by grade\n",
        "print(\"\\n\" + \"=\"*60)\n",
        "print(\"SUBJECT COVERAGE BY GRADE\")\n",
        "print(\"=\"*60)\n",
        "\n",
        "for grade in range(1, 13):\n",
        "    grade_test_cols = [col for col in test_score_cols if f'Grade_{grade}_' in col]\n",
        "    if grade_test_cols:\n",
        "        subjects = list(set([col.split(f'Grade_{grade}_')[1].split('_Test')[0]\n",
        "                           for col in grade_test_cols]))\n",
        "        print(f\"Grade {grade}: {len(grade_test_cols)} subjects - {subjects}\")\n",
        "\n",
        "all_categorized_cols = set(test_score_cols + attendance_cols + homework_cols + participation_cols + textbook_cols)\n",
        "remaining_cols = [col for col in df.columns if col not in all_categorized_cols]\n",
        "\n",
        "print(\"\\n\" + \"=\"*60)\n",
        "print(\"REMAINING COLUMNS\")\n",
        "print(\"=\"*60)\n",
        "print(f\"Number of remaining columns: {len(remaining_cols)}\")\n",
        "print(\"Remaining columns (first 20):\\n\", remaining_cols[:20])\n",
        "print(\"Remaining columns (last 20):\\n\", remaining_cols[-20:])"
      ],
      "metadata": {
        "id": "znCaQByysCrC"
      },
      "id": "znCaQByysCrC",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Check for nulls per column\n",
        "print(\"==============================\")\n",
        "print(\"CHECKING FOR MISSING DATA\")\n",
        "print(\"==============================\")\n",
        "print(df.isnull().sum())\n",
        "\n",
        "# Check the percentage of missing data\n",
        "print(\"================================\")\n",
        "print(\"Percentage of missing data:\")\n",
        "print(\"--------------------------------\")\n",
        "print(df.isnull().mean() * 100)"
      ],
      "metadata": {
        "id": "DRgDluFtsTxQ"
      },
      "id": "DRgDluFtsTxQ",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"--------------------------------\")\n",
        "print(\"Check data types of all columns\")\n",
        "print(\"--------------------------------\")\n",
        "print(df.dtypes)\n",
        "\n",
        "# To see a count of how many columns you have for each type\n",
        "print(df.dtypes.value_counts())\n",
        "\n",
        "# Select only numeric columns (float and int)\n",
        "numeric_cols = df.select_dtypes(include=['number']).columns\n",
        "print(f\"Numeric Columns: {list(numeric_cols)}\")\n",
        "\n",
        "# Select only categorical/object columns\n",
        "categorical_cols = df.select_dtypes(include=['object', 'category']).columns\n",
        "print(f\"Categorical Columns: {list(categorical_cols)}\")\n",
        "\n",
        "#column name of one subject(maths)\n",
        "one_column= [col for col in df.columns if 'Grade_12' in col and 'Math' in col]\n",
        "#number of column is one subject (maths)\n",
        "print(\"number of column in one subject is:\",len(one_column))\n",
        "print(one_column)"
      ],
      "metadata": {
        "id": "3_zQLXyxseLx"
      },
      "id": "3_zQLXyxseLx",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "# 1. Get the value counts of dtypes\n",
        "dtype_counts = df.dtypes.value_counts().reset_index()\n",
        "dtype_counts.columns = ['Data Type', 'Count']\n",
        "\n",
        "# 2. Plotting with the fix\n",
        "plt.figure(figsize=(10, 6))\n",
        "\n",
        "# Fix: Assign 'Data Type' to hue and set legend=False\n",
        "sns.barplot(\n",
        "    data=dtype_counts,\n",
        "    x='Data Type',\n",
        "    y='Count',\n",
        "    hue='Data Type',\n",
        "    palette='viridis',\n",
        "    legend=False\n",
        ")\n",
        "\n",
        "plt.title('Distribution of Data Types in Student Dataset', fontsize=14)\n",
        "plt.ylabel('Number of Columns')\n",
        "plt.xlabel('Data Type')\n",
        "\n",
        "# 3. Add labels on top of bars\n",
        "for i, count in enumerate(dtype_counts['Count']):\n",
        "    plt.text(i, count + 5, str(count), ha='center', fontweight='bold')\n",
        "\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "IH_0GAI8sw6o"
      },
      "id": "IH_0GAI8sw6o",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 1. Check for inconsistent scales\n",
        "print(\"\\n\" + \"=\"*60)\n",
        "print(\"SCALE CONSISTENCY CHECK\")\n",
        "print(\"=\"*60)\n",
        "\n",
        "# Test scores should be on similar scale (0-100 typically)\n",
        "sample_test_scores = test_score_cols[:10]  # Check first 10 test score columns\n",
        "\n",
        "for col in sample_test_scores:\n",
        "    if col in df.columns:\n",
        "        min_val = df[col].min()\n",
        "        max_val = df[col].max()\n",
        "        mean_val = df[col].mean()\n",
        "        print(f\"{col:50} Min: {min_val:6.2f} Max: {max_val:6.2f} Mean: {mean_val:6.2f}\")\n",
        "\n",
        "# 2. Check for impossible values\n",
        "print(\"\\n\" + \"=\"*60)\n",
        "print(\"DATA VALIDATION CHECKS\")\n",
        "print(\"=\"*60)\n",
        "\n",
        "# Check if any test scores are outside reasonable range (0-100)\n",
        "for grade in [9, 10, 11, 12]:  # Check upper grades first\n",
        "    grade_cols = [col for col in test_score_cols if f'Grade_{grade}_' in col]\n",
        "    for col in grade_cols[:3]:  # Check first 3 subjects per grade\n",
        "        if col in df.columns:\n",
        "            invalid_count = ((df[col] < 0) | (df[col] > 100)).sum()\n",
        "            if invalid_count > 0:\n",
        "                print(f\"WARNING: {col} has {invalid_count} values outside 0-100 range\")\n",
        "\n",
        "# 3. Check attendance, homework, participation scales\n",
        "# These are likely percentages (0-100) or proportions (0-1)\n",
        "print(\"\\nChecking behavioral data scales...\")\n",
        "sample_attendance = attendance_cols[0] if attendance_cols else None\n",
        "if sample_attendance and sample_attendance in df.columns:\n",
        "    att_min = df[sample_attendance].min()\n",
        "    att_max = df[sample_attendance].max()\n",
        "    print(f\"Attendance sample ({sample_attendance}): {att_min:.2f} to {att_max:.2f}\")\n",
        "\n",
        "    # Determine scale\n",
        "    if att_max > 1:\n",
        "        print(\"Likely scale: 0-100 (percentage)\")\n",
        "        # We may need to normalize to 0-1 for consistency\n",
        "    else:\n",
        "        print(\"Likely scale: 0-1 (proportion)\")"
      ],
      "metadata": {
        "id": "7Y4vEdBvtagI"
      },
      "id": "7Y4vEdBvtagI",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "# -----------------------------\n",
        "# Distribution of key variables\n",
        "# -----------------------------\n",
        "fig, axes = plt.subplots(2, 2, figsize=(15, 10))\n",
        "\n",
        "# Plot 1: Distribution of Total_National_Exam_Score\n",
        "if 'Total_National_Exam_Score' in df.columns:\n",
        "    axes[0, 0].hist(\n",
        "        df['Total_National_Exam_Score'].dropna(),\n",
        "        bins=30,\n",
        "        edgecolor='black',\n",
        "        alpha=0.7\n",
        "    )\n",
        "    axes[0, 0].set_title('Distribution of Total_National_Exam_Score')\n",
        "    axes[0, 0].set_xlabel('Average Score')\n",
        "    axes[0, 0].set_ylabel('Frequency')\n",
        "\n",
        "# Plot 2: Parental Involvement distribution\n",
        "if 'Parental_Involvement' in df.columns:\n",
        "    axes[0, 1].hist(\n",
        "        df['Parental_Involvement'].dropna(),\n",
        "        bins=30,\n",
        "        edgecolor='black',\n",
        "        alpha=0.7,\n",
        "        color='green'\n",
        "    )\n",
        "    axes[0, 1].set_title('Parental Involvement Distribution')\n",
        "    axes[0, 1].set_xlabel('Involvement Score (0–1)')\n",
        "    axes[0, 1].set_ylabel('Frequency')\n",
        "\n",
        "# Plot 3: Overall Average by Academic Track (BOXPLOT)\n",
        "if 'Field_Choice' in df.columns and 'Overall_Average' in df.columns:\n",
        "    track_data = df[['Field_Choice', 'Overall_Average']].dropna()\n",
        "\n",
        "    tracks = sorted(track_data['Field_Choice'].unique())\n",
        "    labels = ['Social' if t == 0 else 'Natural' for t in tracks]\n",
        "\n",
        "    box_data = [\n",
        "        track_data[track_data['Field_Choice'] == t]['Overall_Average']\n",
        "        for t in tracks\n",
        "    ]\n",
        "\n",
        "    axes[1, 0].boxplot(\n",
        "        box_data,\n",
        "        tick_labels=labels   # ✅ FIXED (was labels=)\n",
        "    )\n",
        "    axes[1, 0].set_title('Overall Average by Academic Track')\n",
        "    axes[1, 0].set_ylabel('Average Score')\n",
        "\n",
        "# Plot 4: Region performance\n",
        "if 'Region' in df.columns and 'Overall_Average' in df.columns:\n",
        "    region_avg = (\n",
        "        df.groupby('Region')['Overall_Average']\n",
        "        .mean()\n",
        "        .sort_values()\n",
        "    )\n",
        "\n",
        "    axes[1, 1].barh(range(len(region_avg)), region_avg.values)\n",
        "    axes[1, 1].set_yticks(range(len(region_avg)))\n",
        "    axes[1, 1].set_yticklabels(region_avg.index)\n",
        "    axes[1, 1].set_title('Average Performance by Region')\n",
        "    axes[1, 1].set_xlabel('Average Score')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "-qkJu5SmH5gE"
      },
      "id": "-qkJu5SmH5gE",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Drop ID (never use in ML)\n",
        "df = df.drop(columns=['Student_ID'], errors='ignore')\n",
        "\n",
        "#  Encode Field_Choice (VERY IMPORTANT)\n",
        "df['Field_Choice'] = df['Field_Choice'].map({\n",
        "    'Social': 0,\n",
        "    'Natural': 1\n",
        "})\n",
        "\n",
        "# HANDLE CAREER_INTEREST\n",
        "# Fill missing with \"Unknown\"\n",
        "df['Career_Interest'] = df['Career_Interest'].fillna('Unknown')"
      ],
      "metadata": {
        "id": "4cTfhaQEIocC"
      },
      "id": "4cTfhaQEIocC",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}